{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIQXZNvBNglc",
        "outputId": "cc9d0553-d650-46e7-ff41-34a42ec95412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Multi_Country_GDP_Prediction'...\n",
            "remote: Enumerating objects: 646, done.\u001b[K\n",
            "remote: Counting objects: 100% (114/114), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 646 (delta 57), reused 79 (delta 37), pack-reused 532 (from 1)\u001b[K\n",
            "Receiving objects: 100% (646/646), 282.53 MiB | 23.15 MiB/s, done.\n",
            "Resolving deltas: 100% (364/364), done.\n",
            "Updating files: 100% (529/529), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/danyQe/Multi_Country_GDP_Prediction.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/Multi_Country_GDP_Prediction/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H37ZQk8KOa8R",
        "outputId": "6b625e09-4c43-4d0e-9aef-842a52dd33f5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting absl-py==2.1.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 1))\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting accelerate==0.30.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 2))\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting aiohttp==3.9.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 3))\n",
            "  Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting aiosignal==1.3.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 4))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 5)) (0.7.0)\n",
            "Collecting anyio==4.4.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 6))\n",
            "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting asttokens==2.4.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 7))\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting async-timeout==4.0.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 8))\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting attrs==23.2.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 9))\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 10)) (0.2.0)\n",
            "Collecting cachetools==5.3.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 11))\n",
            "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting certifi==2022.12.7 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 12))\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting charset-normalizer==2.1.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 13))\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting click==8.1.7 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 14))\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting cloudpickle==3.0.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 15))\n",
            "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting cmake==3.25.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 16))\n",
            "  Downloading cmake-3.25.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting comm==0.2.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 17))\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting contourpy==1.1.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 18))\n",
            "  Downloading contourpy-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 19)) (0.12.1)\n",
            "Collecting datasets==2.20.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 20))\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting debugpy==1.8.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 21))\n",
            "  Downloading debugpy-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting decorator==5.1.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 22))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting diffusers==0.29.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 23))\n",
            "  Downloading diffusers-0.29.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting dill==0.3.8 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 24))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting diskcache==5.6.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 25))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: distro==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 26)) (1.9.0)\n",
            "Collecting dnspython==2.6.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 27))\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: einops==0.8.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 28)) (0.8.0)\n",
            "Collecting email_validator==2.2.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 29))\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting et-xmlfile==1.1.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 30))\n",
            "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting exceptiongroup==1.2.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 31))\n",
            "  Downloading exceptiongroup-1.2.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting executing==2.0.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 32))\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting fastapi==0.111.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 33))\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting fastapi-cli==0.0.4 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 34))\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting filelock==3.13.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 35))\n",
            "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting flash-attn==2.5.8 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 36))\n",
            "  Downloading flash_attn-2.5.8.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fonttools==4.51.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 37))\n",
            "  Downloading fonttools-4.51.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist==1.4.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 38))\n",
            "  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting fsspec==2024.3.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 39))\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting google-auth==2.29.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 40))\n",
            "  Downloading google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting google-auth-oauthlib==1.0.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 41))\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting grpcio==1.63.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 42))\n",
            "  Downloading grpcio-1.63.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: h11==0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 43)) (0.14.0)\n",
            "Collecting httpcore==1.0.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 44))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting httptools==0.6.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 45))\n",
            "  Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting httpx==0.27.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 46))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting huggingface-hub==0.23.4 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 47))\n",
            "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting idna==3.4 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 48))\n",
            "  Downloading idna-3.4-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting importlib_metadata==7.1.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 49))\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting importlib_resources==6.4.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 50))\n",
            "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting interegular==0.3.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 51))\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Collecting ipykernel==6.29.4 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 52))\n",
            "  Downloading ipykernel-6.29.4-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ipython==8.12.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 53))\n",
            "  Downloading ipython-8.12.3-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jedi==0.19.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 54))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting Jinja2==3.1.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 55))\n",
            "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 56)) (1.4.2)\n",
            "Requirement already satisfied: jsonschema==4.23.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 57)) (4.23.0)\n",
            "Collecting jsonschema-specifications==2023.12.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 58))\n",
            "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting jupyter_client==8.6.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 59))\n",
            "  Downloading jupyter_client-8.6.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: jupyter_core==5.7.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 60)) (5.7.2)\n",
            "Collecting kiwisolver==1.4.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 61))\n",
            "  Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting lark==1.1.9 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 62))\n",
            "  Downloading lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting lit==15.0.7 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 63))\n",
            "  Downloading lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llvmlite==0.41.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 64))\n",
            "  Downloading llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting lm-format-enforcer==0.10.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 65))\n",
            "  Downloading lm_format_enforcer-0.10.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting lxml==5.2.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 66))\n",
            "  Downloading lxml-5.2.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting Markdown==3.6 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 67))\n",
            "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: markdown-it-py==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 68)) (3.0.0)\n",
            "Collecting MarkupSafe==2.1.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 69))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting matplotlib==3.7.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 70))\n",
            "  Downloading matplotlib-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.7 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 71)) (0.1.7)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 72)) (0.1.2)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 73)) (1.3.0)\n",
            "Collecting msgpack==1.0.8 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 74))\n",
            "  Downloading msgpack-1.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting multidict==6.0.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 75))\n",
            "  Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting multiprocess==0.70.16 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 76))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 77)) (1.6.0)\n",
            "Collecting networkx==3.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 78))\n",
            "  Downloading networkx-3.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting ninja==1.11.1.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 79))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting numba==0.58.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 80))\n",
            "  Downloading numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numpy==1.24.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 81))\n",
            "  Downloading numpy-1.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 82))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 83))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 84))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 85))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 86))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 87))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 88))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 89))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 90))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-ml-py==12.555.43 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 91))\n",
            "  Downloading nvidia_ml_py-12.555.43-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 92))\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 93)) (12.5.82)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 94))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 95)) (3.2.2)\n",
            "Collecting openai==1.35.13 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 96))\n",
            "  Downloading openai-1.35.13-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting opencv-python==4.10.0.82 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 97))\n",
            "  Downloading opencv_python-4.10.0.82-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting openpyxl==3.1.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 98))\n",
            "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting orjson==3.10.6 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 99))\n",
            "  Downloading orjson-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting outlines==0.0.46 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 100))\n",
            "  Downloading outlines-0.0.46-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting packaging==24.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 101))\n",
            "  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas==2.0.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 102))\n",
            "  Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: parso==0.8.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 103)) (0.8.4)\n",
            "Collecting peft==0.10.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 104))\n",
            "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pexpect==4.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 105)) (4.9.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 106)) (0.7.5)\n",
            "Collecting pillow==10.2.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 107))\n",
            "  Downloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting pkgutil_resolve_name==1.3.10 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 108))\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl.metadata (624 bytes)\n",
            "Collecting platformdirs==4.2.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 109))\n",
            "  Downloading platformdirs-4.2.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting prometheus-fastapi-instrumentator==7.0.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 110))\n",
            "  Downloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting prometheus_client==0.20.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 111))\n",
            "  Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting prompt-toolkit==3.0.43 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 112))\n",
            "  Downloading prompt_toolkit-3.0.43-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting protobuf==5.26.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 113))\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting psutil==5.9.8 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 114))\n",
            "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 115)) (0.7.0)\n",
            "Collecting pure-eval==0.2.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 116))\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: py-cpuinfo==9.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 117)) (9.0.0)\n",
            "Collecting pyairports==2.1.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 118))\n",
            "  Downloading pyairports-2.1.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pyarrow==16.1.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 119))\n",
            "  Downloading pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyarrow-hotfix==0.6 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 120))\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pyasn1==0.6.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 121))\n",
            "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting pyasn1_modules==0.4.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 122))\n",
            "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pycountry==24.6.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 123))\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic==2.8.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 124))\n",
            "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic_core==2.20.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 125))\n",
            "  Downloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: Pygments==2.18.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 126)) (2.18.0)\n",
            "Collecting pyparsing==3.1.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 127))\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-dateutil==2.9.0.post0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 128))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting python-docx==1.1.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 129))\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-dotenv==1.0.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 130))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting python-multipart==0.0.9 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 131))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pytz==2024.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 132))\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting PyYAML==6.0.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 133))\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting pyzmq==26.0.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 134))\n",
            "  Downloading pyzmq-26.0.3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting ray==2.10.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 135))\n",
            "  Downloading ray-2.10.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting referencing==0.35.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 136))\n",
            "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting regex==2024.5.10 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 137))\n",
            "  Downloading regex-2024.5.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 138)) (2.32.3)\n",
            "Collecting requests-oauthlib==2.0.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 139))\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting rich==13.7.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 140))\n",
            "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rpds-py==0.19.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 141))\n",
            "  Downloading rpds_py-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 142)) (4.9)\n",
            "Collecting safetensors==0.4.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 143))\n",
            "  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting scikit-learn==1.3.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 144))\n",
            "  Downloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy==1.10.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 145))\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 146)) (0.13.2)\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 147)) (0.2.0)\n",
            "Requirement already satisfied: shellingham==1.5.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 148)) (1.5.4)\n",
            "Collecting six==1.16.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 149))\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 150)) (1.3.1)\n",
            "Collecting stack-data==0.6.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 151))\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting starlette==0.37.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 152))\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting sympy==1.12 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 153))\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tensorboard==2.14.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 154))\n",
            "  Downloading tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorboard-data-server==0.7.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 155)) (0.7.2)\n",
            "Requirement already satisfied: threadpoolctl==3.5.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 156)) (3.5.0)\n",
            "Collecting tiktoken==0.7.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 157))\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting timm==0.9.16 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 158))\n",
            "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting tokenizers==0.19.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 159))\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting torch==2.3.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 160))\n",
            "  Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 0.36.0 Requires-Python >=3.6,<3.10; 0.37.0 Requires-Python >=3.7,<3.10; 0.38.0 Requires-Python >=3.7,<3.11; 0.38.1 Requires-Python >=3.7,<3.11; 0.52.0 Requires-Python >=3.6,<3.9; 0.52.0rc3 Requires-Python >=3.6,<3.9; 0.53.0 Requires-Python >=3.6,<3.10; 0.53.0rc1.post1 Requires-Python >=3.6,<3.10; 0.53.0rc2 Requires-Python >=3.6,<3.10; 0.53.0rc3 Requires-Python >=3.6,<3.10; 0.53.1 Requires-Python >=3.6,<3.10; 0.54.0 Requires-Python >=3.7,<3.10; 0.54.0rc2 Requires-Python >=3.7,<3.10; 0.54.0rc3 Requires-Python >=3.7,<3.10; 0.54.1 Requires-Python >=3.7,<3.10; 0.55.0 Requires-Python >=3.7,<3.11; 0.55.0rc1 Requires-Python >=3.7,<3.11; 0.55.1 Requires-Python >=3.7,<3.11; 0.55.2 Requires-Python >=3.7,<3.11; 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchaudio==2.0.2+cu118 (from versions: 2.0.1, 2.0.2, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchaudio==2.0.2+cu118\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision torchaudio==2.0.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfAI9ysqfn_S",
        "outputId": "1227afb7-4e9f-4106-fa43-f921df05a286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m726.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/triton/\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Multi_Country_GDP_Prediction"
      ],
      "metadata": {
        "id": "c7pUWYmdsKTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.linear_mlp_quarter\n",
        "# !python -m Multi_Country_GDP_Prediction.scripts.linear_mlp_quarter\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqylRX_zPjLD",
        "outputId": "4760249a-96db-428d-8f01-1900cafb181d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Multi_Country_GDP_Prediction\n",
            "MLP_data_light_sms_q_13-19.pt\n",
            "cost time:  0.13428115844726562\n",
            "MLP_data_q_95-19.pt\n",
            "cost time:  0.02292490005493164\n",
            "MLP_data_light_months_q_13-19.pt\n",
            "cost time:  0.028390169143676758\n",
            "MLP_data_light_mean_q_13-19.pt\n",
            "cost time:  0.028704404830932617\n",
            "MLP_data_q_13-19.pt\n",
            "cost time:  0.02730846405029297\n",
            "                               data  train_mae  train_mse  ...  test_mspe  test_rse  test_corr\n",
            "0     MLP_data_light_sms_q_13-19.pt   0.992814   1.897927  ...   8.503452  0.787327   0.027247\n",
            "1               MLP_data_q_95-19.pt   0.897575   1.490365  ...   0.519753  0.849424   0.033762\n",
            "2  MLP_data_light_months_q_13-19.pt   1.000516   1.920275  ...  14.792241  0.769888   0.027828\n",
            "3    MLP_data_light_mean_q_13-19.pt   0.999351   1.926022  ...  13.229493  0.770982   0.027769\n",
            "4               MLP_data_q_13-19.pt   1.011365   1.932060  ...  96.145195  0.767031   0.028065\n",
            "\n",
            "[5 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.linear_lstm_quarter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioyhLQ5Pkmyq",
        "outputId": "521e31c3-866a-4903-9388-7eb45e0d6c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM_data_gdp_more_light_sms_q_t8_13-19.pt\n",
            "cost time:  0.02939605712890625\n",
            "LSTM_data_light_sms_q_t10_13-19.pt\n",
            "cost time:  0.03708767890930176\n",
            "LSTM_data_gdp_q_t8_13-19.pt\n",
            "cost time:  0.017667055130004883\n",
            "LSTM_data_gdp_light_sms_q_t12_13-19.pt\n",
            "cost time:  0.015044689178466797\n",
            "LSTM_data_q_t10_13-19.pt\n",
            "cost time:  0.029384851455688477\n",
            "LSTM_data_gdp_q_t8_95-19.pt\n",
            "cost time:  0.03245711326599121\n",
            "LSTM_data_gdp_light_months_q_t12_13-19.pt\n",
            "cost time:  0.019125938415527344\n",
            "LSTM_data_q_t8_13-19.pt\n",
            "cost time:  0.030218124389648438\n",
            "LSTM_data_gdp_q_t10_13-19.pt\n",
            "cost time:  0.014409780502319336\n",
            "LSTM_data_gdp_more_q_t12_13-19.pt\n",
            "cost time:  0.02617359161376953\n",
            "LSTM_data_gdp_more_light_months_q_t10_13-19.pt\n",
            "cost time:  0.024965524673461914\n",
            "LSTM_data_gdp_more_light_sms_q_t12_13-19.pt\n",
            "cost time:  0.021146535873413086\n",
            "LSTM_data_gdp_more_light_months_q_t12_13-19.pt\n",
            "cost time:  0.02482891082763672\n",
            "LSTM_data_light_sms_q_t12_13-19.pt\n",
            "cost time:  0.04002833366394043\n",
            "LSTM_data_gdp_light_months_q_t8_13-19.pt\n",
            "cost time:  0.020772695541381836\n",
            "LSTM_data_gdp_light_sms_q_t8_13-19.pt\n",
            "cost time:  0.020306110382080078\n",
            "LSTM_data_gdp_more_q_t10_95-19.pt\n",
            "cost time:  0.07238411903381348\n",
            "LSTM_data_gdp_more_light_mean_q_t8_13-19.pt\n",
            "cost time:  0.02661728858947754\n",
            "LSTM_data_gdp_more_q_t8_13-19.pt\n",
            "cost time:  0.024854660034179688\n",
            "LSTM_data_gdp_q_t10_95-19.pt\n",
            "cost time:  0.020208120346069336\n",
            "LSTM_data_gdp_more_light_mean_q_t12_13-19.pt\n",
            "cost time:  0.019814014434814453\n",
            "LSTM_data_gdp_more_light_sms_q_t10_13-19.pt\n",
            "cost time:  0.0281527042388916\n",
            "LSTM_data_gdp_more_q_t12_95-19.pt\n",
            "cost time:  0.039305686950683594\n",
            "LSTM_data_gdp_more_light_months_q_t8_13-19.pt\n",
            "cost time:  0.030285120010375977\n",
            "LSTM_data_light_months_q_t8_13-19.pt\n",
            "cost time:  0.03799772262573242\n",
            "LSTM_data_light_mean_q_t12_13-19.pt\n",
            "cost time:  0.029729366302490234\n",
            "LSTM_data_gdp_more_light_mean_q_t10_13-19.pt\n",
            "cost time:  0.021983861923217773\n",
            "LSTM_data_q_t12_13-19.pt\n",
            "cost time:  0.033624887466430664\n",
            "LSTM_data_gdp_light_mean_q_t12_13-19.pt\n",
            "cost time:  0.01903510093688965\n",
            "LSTM_data_light_sms_q_t8_13-19.pt\n",
            "cost time:  0.11910057067871094\n",
            "LSTM_data_light_months_q_t10_13-19.pt\n",
            "cost time:  0.15208864212036133\n",
            "LSTM_data_light_mean_q_t10_13-19.pt\n",
            "cost time:  0.15189099311828613\n",
            "LSTM_data_gdp_q_t12_13-19.pt\n",
            "cost time:  0.024971961975097656\n",
            "LSTM_data_gdp_light_mean_q_t8_13-19.pt\n",
            "cost time:  0.03409838676452637\n",
            "LSTM_data_gdp_light_mean_q_t10_13-19.pt\n",
            "cost time:  0.047419071197509766\n",
            "LSTM_data_gdp_light_months_q_t10_13-19.pt\n",
            "cost time:  0.01855301856994629\n",
            "LSTM_data_light_months_q_t12_13-19.pt\n",
            "cost time:  0.10381889343261719\n",
            "LSTM_data_gdp_more_q_t10_13-19.pt\n",
            "cost time:  0.022269725799560547\n",
            "LSTM_data_gdp_more_q_t8_95-19.pt\n",
            "cost time:  0.11813092231750488\n",
            "LSTM_data_gdp_q_t12_95-19.pt\n",
            "cost time:  0.05630683898925781\n",
            "LSTM_data_gdp_light_sms_q_t10_13-19.pt\n",
            "cost time:  0.02867913246154785\n",
            "LSTM_data_light_mean_q_t8_13-19.pt\n",
            "cost time:  0.2889885902404785\n",
            "                                              data  train_mae  ...  test_rse  test_corr\n",
            "0       LSTM_data_gdp_more_light_sms_q_t8_13-19.pt   0.599465  ...  0.488616   0.050334\n",
            "1               LSTM_data_light_sms_q_t10_13-19.pt   0.000005  ...  1.023570   0.029056\n",
            "2                      LSTM_data_gdp_q_t8_13-19.pt   0.440863  ...  0.409240   0.037366\n",
            "3           LSTM_data_gdp_light_sms_q_t12_13-19.pt   0.300615  ...  0.539681   0.036018\n",
            "4                         LSTM_data_q_t10_13-19.pt   0.000006  ...  0.950362   0.029840\n",
            "5                      LSTM_data_gdp_q_t8_95-19.pt   0.643525  ...  0.431631   0.052954\n",
            "6        LSTM_data_gdp_light_months_q_t12_13-19.pt   0.313499  ...  0.547943   0.035972\n",
            "7                          LSTM_data_q_t8_13-19.pt   0.123210  ...  0.979801   0.033769\n",
            "8                     LSTM_data_gdp_q_t10_13-19.pt   0.383507  ...  0.394186   0.037628\n",
            "9                LSTM_data_gdp_more_q_t12_13-19.pt   0.585752  ...  0.494139   0.051722\n",
            "10  LSTM_data_gdp_more_light_months_q_t10_13-19.pt   0.545191  ...  0.518186   0.051555\n",
            "11     LSTM_data_gdp_more_light_sms_q_t12_13-19.pt   0.534767  ...  0.583347   0.051107\n",
            "12  LSTM_data_gdp_more_light_months_q_t12_13-19.pt   0.538779  ...  0.546791   0.052109\n",
            "13              LSTM_data_light_sms_q_t12_13-19.pt   0.000002  ...  0.958100   0.028729\n",
            "14        LSTM_data_gdp_light_months_q_t8_13-19.pt   0.420599  ...  0.451707   0.037127\n",
            "15           LSTM_data_gdp_light_sms_q_t8_13-19.pt   0.412457  ...  0.442528   0.036860\n",
            "16               LSTM_data_gdp_more_q_t10_95-19.pt   0.918921  ...  0.479790   0.067329\n",
            "17     LSTM_data_gdp_more_light_mean_q_t8_13-19.pt   0.599836  ...  0.484601   0.050701\n",
            "18                LSTM_data_gdp_more_q_t8_13-19.pt   0.609856  ...  0.464054   0.050578\n",
            "19                    LSTM_data_gdp_q_t10_95-19.pt   0.585186  ...  0.400444   0.052624\n",
            "20    LSTM_data_gdp_more_light_mean_q_t12_13-19.pt   0.561576  ...  0.550268   0.051755\n",
            "21     LSTM_data_gdp_more_light_sms_q_t10_13-19.pt   0.547671  ...  0.534288   0.050912\n",
            "22               LSTM_data_gdp_more_q_t12_95-19.pt   0.916933  ...  0.480757   0.067334\n",
            "23   LSTM_data_gdp_more_light_months_q_t8_13-19.pt   0.597396  ...  0.487672   0.050691\n",
            "24            LSTM_data_light_months_q_t8_13-19.pt   0.073414  ...  0.963424   0.025660\n",
            "25             LSTM_data_light_mean_q_t12_13-19.pt   0.000003  ...  1.080639   0.028698\n",
            "26    LSTM_data_gdp_more_light_mean_q_t10_13-19.pt   0.565325  ...  0.515991   0.051477\n",
            "27                        LSTM_data_q_t12_13-19.pt   0.000002  ...  1.050596   0.028921\n",
            "28         LSTM_data_gdp_light_mean_q_t12_13-19.pt   0.348048  ...  0.522308   0.036121\n",
            "29               LSTM_data_light_sms_q_t8_13-19.pt   0.051237  ...  0.990845   0.025839\n",
            "30           LSTM_data_light_months_q_t10_13-19.pt   0.000006  ...  1.057916   0.032796\n",
            "31             LSTM_data_light_mean_q_t10_13-19.pt   0.000007  ...  1.010223   0.028237\n",
            "32                    LSTM_data_gdp_q_t12_13-19.pt   0.369937  ...  0.437357   0.036189\n",
            "33          LSTM_data_gdp_light_mean_q_t8_13-19.pt   0.434316  ...  0.409644   0.037428\n",
            "34         LSTM_data_gdp_light_mean_q_t10_13-19.pt   0.364929  ...  0.462398   0.037619\n",
            "35       LSTM_data_gdp_light_months_q_t10_13-19.pt   0.338817  ...  0.514140   0.037151\n",
            "36           LSTM_data_light_months_q_t12_13-19.pt   0.000004  ...  0.860074   0.030744\n",
            "37               LSTM_data_gdp_more_q_t10_13-19.pt   0.573211  ...  0.448086   0.051567\n",
            "38                LSTM_data_gdp_more_q_t8_95-19.pt   0.975825  ...  0.529513   0.065845\n",
            "39                    LSTM_data_gdp_q_t12_95-19.pt   0.577053  ...  0.410118   0.051988\n",
            "40          LSTM_data_gdp_light_sms_q_t10_13-19.pt   0.333463  ...  0.508377   0.036848\n",
            "41              LSTM_data_light_mean_q_t8_13-19.pt   0.094623  ...  0.971553   0.029204\n",
            "\n",
            "[42 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.linear_mlp_year"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sInOf6fFoT__",
        "outputId": "41a4092f-000b-429e-d40e-2663a22cdeb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP_data_y_80-19.pt\n",
            "cost time:  0.018796443939208984\n",
            "MLP_data_light_months_y_13-19.pt\n",
            "cost time:  0.005925655364990234\n",
            "MLP_data_y_13-19.pt\n",
            "cost time:  0.005396604537963867\n",
            "MLP_data_light_sms_y_13-19.pt\n",
            "cost time:  0.005670070648193359\n",
            "MLP_data_y_80-07.pt\n",
            "cost time:  0.009649991989135742\n",
            "MLP_data_light_mean_y_13-19.pt\n",
            "cost time:  0.006495475769042969\n",
            "                               data  train_mae  train_mse  ...  test_mspe  test_rse  test_corr\n",
            "0               MLP_data_y_80-19.pt   0.720665   1.086349  ...   2.738609  0.363372   0.028275\n",
            "1  MLP_data_light_months_y_13-19.pt   0.485427   0.408693  ...   0.499493  0.344191   0.022700\n",
            "2               MLP_data_y_13-19.pt   0.537904   0.557611  ...  33.316257  0.360310   0.022742\n",
            "3     MLP_data_light_sms_y_13-19.pt   0.495155   0.488961  ...   0.271816  0.292129   0.023153\n",
            "4               MLP_data_y_80-07.pt   0.724248   0.999173  ...   0.070267  0.597057   0.029627\n",
            "5    MLP_data_light_mean_y_13-19.pt   0.536801   0.554186  ...   9.610674  0.342089   0.022934\n",
            "\n",
            "[6 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.run_lstm_q"
      ],
      "metadata": {
        "id": "hUHDLc_Ko5Mk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9620f151-0a61-4e51-be39-e09a011ddd0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file item list length:  6\n",
            "  0% 0/6 [00:00<?, ?it/s]LSTM_data_gdp_q_t8_95-19.pt\n",
            "/content/Multi_Country_GDP_Prediction/scripts/run_lstm_q.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  dataset = TensorDataset(torch.tensor(X, dtype=torch.float32),\n",
            "/content/Multi_Country_GDP_Prediction/scripts/run_lstm_q.py:258: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(y, dtype=torch.float32))\n",
            "\n",
            "Hyperparameter Search:   0% 0/54 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "initial train loss:  7.129329778175273 initial gdp train loss:  95.98164516069924\n",
            "initial val loss:  7.501234471297064 initial gdp val loss:  100.98857655244716\n",
            "Best Validation GDP Loss for fold 1: 0.7196\n",
            "Best best_epoch 137\n",
            "Fold 2/5\n",
            "initial train loss:  7.240161596342575 initial gdp train loss:  97.47376956092883\n",
            "initial val loss:  7.530119915970233 initial gdp val loss:  101.37746217871914\n",
            "Best Validation GDP Loss for fold 2: 0.8092\n",
            "Best best_epoch 192\n",
            "Fold 3/5\n",
            "initial train loss:  6.936738195298593 initial gdp train loss:  93.38880411783855\n",
            "initial val loss:  6.870341793965485 initial gdp val loss:  92.49491196971829\n",
            "Best Validation GDP Loss for fold 3: 0.5923\n",
            "Best best_epoch 634\n",
            "Fold 4/5\n",
            "initial train loss:  7.00097069559218 initial gdp train loss:  94.25356122109457\n",
            "initial val loss:  6.388508788609909 initial gdp val loss:  86.00802819203523\n",
            "Best Validation GDP Loss for fold 4: 0.7872\n",
            "Best best_epoch 779\n",
            "Fold 5/5\n",
            "initial train loss:  5.884451771587259 initial gdp train loss:  79.22194449509246\n",
            "initial val loss:  5.917250309960317 initial gdp val loss:  79.66350878699352\n",
            "Best Validation GDP Loss for fold 5: 0.7011\n",
            "Best best_epoch 559\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}: 0.7219\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t8_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Hyperparameter Search:   2% 1/54 [02:33<2:15:52, 153.82s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  21.81572686290136 initial gdp train loss:  97.90118137222515\n",
            "initial val loss:  22.933277242323932 initial gdp val loss:  102.9163497155454\n",
            "Best Validation GDP Loss for fold 1: 0.7174\n",
            "Best best_epoch 139\n",
            "Fold 2/5\n",
            "initial train loss:  21.847014695342953 initial gdp train loss:  98.04159274917828\n",
            "initial val loss:  22.72093243959571 initial gdp val loss:  101.9634194894999\n",
            "Best Validation GDP Loss for fold 2: 0.8122\n",
            "Best best_epoch 156\n",
            "Fold 3/5\n",
            "initial train loss:  19.77333845468513 initial gdp train loss:  88.73567405732875\n",
            "initial val loss:  19.570508795269465 initial gdp val loss:  87.82544307385461\n",
            "Best Validation GDP Loss for fold 3: 0.5967\n",
            "Best best_epoch 596\n",
            "Fold 4/5\n",
            "initial train loss:  19.82659830020953 initial gdp train loss:  88.97468525045532\n",
            "initial val loss:  18.052926273669225 initial gdp val loss:  81.01507904569982\n",
            "Best Validation GDP Loss for fold 4: 0.8105\n",
            "Best best_epoch 464\n",
            "Fold 5/5\n",
            "initial train loss:  18.791801629690177 initial gdp train loss:  84.33088793533261\n",
            "initial val loss:  18.89656858929133 initial gdp val loss:  84.80104194253178\n",
            "Best Validation GDP Loss for fold 5: 0.7701\n",
            "Best best_epoch 95\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}: 0.7414\n",
            "\n",
            "Hyperparameter Search:   4% 2/54 [05:07<2:13:01, 153.48s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.9770857415794065 initial gdp train loss:  93.93199706127982\n",
            "initial val loss:  7.342716197005841 initial gdp val loss:  98.85446064412093\n",
            "Best Validation GDP Loss for fold 1: 0.7472\n",
            "Best best_epoch 987\n",
            "Fold 2/5\n",
            "initial train loss:  6.967659631692834 initial gdp train loss:  93.8050942128607\n",
            "initial val loss:  7.250199714628589 initial gdp val loss:  97.60891345368714\n",
            "Best Validation GDP Loss for fold 2: 0.8340\n",
            "Best best_epoch 995\n",
            "Fold 3/5\n",
            "initial train loss:  7.1442946683505415 initial gdp train loss:  96.18311757276832\n",
            "initial val loss:  7.074216681011652 initial gdp val loss:  95.23966643769862\n",
            "Best Validation GDP Loss for fold 3: 0.7078\n",
            "Best best_epoch 991\n",
            "Fold 4/5\n",
            "initial train loss:  6.540124571273095 initial gdp train loss:  88.04922334051334\n",
            "initial val loss:  5.945363553903871 initial gdp val loss:  80.04199089438228\n",
            "Best Validation GDP Loss for fold 4: 0.8571\n",
            "Best best_epoch 966\n",
            "Fold 5/5\n",
            "initial train loss:  7.345068201234069 initial gdp train loss:  98.88611950451815\n",
            "initial val loss:  7.383735567836438 initial gdp val loss:  99.4066966428595\n",
            "Best Validation GDP Loss for fold 5: 0.7849\n",
            "Best best_epoch 461\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}: 0.7862\n",
            "\n",
            "Hyperparameter Search:   6% 3/54 [07:40<2:10:21, 153.36s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  20.91814921824675 initial gdp train loss:  93.87317363908376\n",
            "initial val loss:  22.018188733012735 initial gdp val loss:  98.80975771351021\n",
            "Best Validation GDP Loss for fold 1: 0.7572\n",
            "Best best_epoch 984\n",
            "Fold 2/5\n",
            "initial train loss:  20.726750061325493 initial gdp train loss:  93.01424490220955\n",
            "initial val loss:  21.565681088872317 initial gdp val loss:  96.77906606978729\n",
            "Best Validation GDP Loss for fold 2: 0.8089\n",
            "Best best_epoch 983\n",
            "Fold 3/5\n",
            "initial train loss:  20.01824529462726 initial gdp train loss:  89.83472507010029\n",
            "initial val loss:  19.81808193659378 initial gdp val loss:  88.93646912655588\n",
            "Best Validation GDP Loss for fold 3: 0.7256\n",
            "Best best_epoch 999\n",
            "Fold 4/5\n",
            "initial train loss:  18.729428351679935 initial gdp train loss:  84.05097771495707\n",
            "initial val loss:  17.018335439391056 initial gdp val loss:  76.3722060898603\n",
            "Best Validation GDP Loss for fold 4: 0.8551\n",
            "Best best_epoch 973\n",
            "Fold 5/5\n",
            "initial train loss:  23.123286661719472 initial gdp train loss:  103.76904113383233\n",
            "initial val loss:  23.251709339982373 initial gdp val loss:  104.34535721601065\n",
            "Best Validation GDP Loss for fold 5: 0.7879\n",
            "Best best_epoch 527\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}: 0.7869\n",
            "\n",
            "Hyperparameter Search:   7% 4/54 [10:14<2:07:55, 153.51s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.08866194791572 initial gdp train loss:  95.43414384063657\n",
            "initial val loss:  7.4569205797019125 initial gdp val loss:  100.39198290400144\n",
            "Best Validation GDP Loss for fold 1: 2.1883\n",
            "Best best_epoch 999\n",
            "Fold 2/5\n",
            "initial train loss:  6.066104102588355 initial gdp train loss:  81.66751856733326\n",
            "initial val loss:  6.320910169296906 initial gdp val loss:  85.09795142422203\n",
            "Best Validation GDP Loss for fold 2: 2.0406\n",
            "Best best_epoch 985\n",
            "Fold 3/5\n",
            "initial train loss:  7.001847510599386 initial gdp train loss:  94.26536653414054\n",
            "initial val loss:  6.9331801543801514 initial gdp val loss:  93.34090320134567\n",
            "Best Validation GDP Loss for fold 3: 1.7328\n",
            "Best best_epoch 996\n",
            "Fold 4/5\n",
            "initial train loss:  6.168401038093406 initial gdp train loss:  83.04473603325052\n",
            "initial val loss:  5.598666385068732 initial gdp val loss:  75.37444421800517\n",
            "Best Validation GDP Loss for fold 4: 2.4456\n",
            "Best best_epoch 999\n",
            "Fold 5/5\n",
            "initial train loss:  5.9260586183282395 initial gdp train loss:  79.78209518883298\n",
            "initial val loss:  5.959891973915747 initial gdp val loss:  80.23759369930978\n",
            "Best Validation GDP Loss for fold 5: 1.4997\n",
            "Best best_epoch 1000\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}: 1.9814\n",
            "\n",
            "Hyperparameter Search:   9% 5/54 [12:48<2:05:43, 153.94s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  20.59939130819373 initial gdp train loss:  92.44269911784198\n",
            "initial val loss:  21.682202299102013 initial gdp val loss:  97.30196970450778\n",
            "Best Validation GDP Loss for fold 1: 2.0851\n",
            "Best best_epoch 999\n",
            "Fold 2/5\n",
            "initial train loss:  20.066354316082364 initial gdp train loss:  90.05062219406031\n",
            "initial val loss:  20.890844874021386 initial gdp val loss:  93.750639651002\n",
            "Best Validation GDP Loss for fold 2: 2.0545\n",
            "Best best_epoch 996\n",
            "Fold 3/5\n",
            "initial train loss:  19.849589545012527 initial gdp train loss:  89.0778579711914\n",
            "initial val loss:  19.646119586491988 initial gdp val loss:  88.16476595603814\n",
            "Best Validation GDP Loss for fold 3: 1.7394\n",
            "Best best_epoch 993\n",
            "Fold 4/5\n",
            "initial train loss:  21.355517640898498 initial gdp train loss:  95.83592945211548\n",
            "initial val loss:  19.473698082616774 initial gdp val loss:  87.39099780583786\n",
            "Best Validation GDP Loss for fold 4: 2.5160\n",
            "Best best_epoch 997\n",
            "Fold 5/5\n",
            "initial train loss:  19.703278762881766 initial gdp train loss:  88.42127353330201\n",
            "initial val loss:  19.818804627757963 initial gdp val loss:  88.93970993817862\n",
            "Best Validation GDP Loss for fold 5: 1.6094\n",
            "Best best_epoch 999\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}: 2.0009\n",
            "\n",
            "Hyperparameter Search:  11% 6/54 [15:21<2:02:47, 153.48s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  8.077957048476625 initial gdp train loss:  108.75294923681537\n",
            "initial val loss:  8.467074995281315 initial gdp val loss:  113.99161542363528\n",
            "Best Validation GDP Loss for fold 1: 0.8588\n",
            "Best best_epoch 179\n",
            "Fold 2/5\n",
            "initial train loss:  5.980278484917091 initial gdp train loss:  80.51205492725332\n",
            "initial val loss:  6.23459953019599 initial gdp val loss:  83.93596052923122\n",
            "Best Validation GDP Loss for fold 2: 0.8072\n",
            "Best best_epoch 279\n",
            "Fold 3/5\n",
            "initial train loss:  6.154412048275461 initial gdp train loss:  82.85640388199046\n",
            "initial val loss:  6.085959345607434 initial gdp val loss:  81.93482376357257\n",
            "Best Validation GDP Loss for fold 3: 0.6258\n",
            "Best best_epoch 381\n",
            "Fold 4/5\n",
            "initial train loss:  6.796062042944542 initial gdp train loss:  91.49488988304942\n",
            "initial val loss:  6.192904254137459 initial gdp val loss:  83.37461853027344\n",
            "Best Validation GDP Loss for fold 4: 0.8241\n",
            "Best best_epoch 178\n",
            "Fold 5/5\n",
            "initial train loss:  7.052925989094666 initial gdp train loss:  94.95303061441027\n",
            "initial val loss:  7.0908151400291315 initial gdp val loss:  95.46312972246591\n",
            "Best Validation GDP Loss for fold 5: 0.6646\n",
            "Best best_epoch 358\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}: 0.7561\n",
            "\n",
            "Hyperparameter Search:  13% 7/54 [19:46<2:28:50, 190.02s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  21.82351414799438 initial gdp train loss:  97.93612785420004\n",
            "initial val loss:  22.94889757813526 initial gdp val loss:  102.98644256591797\n",
            "Best Validation GDP Loss for fold 1: 0.8235\n",
            "Best best_epoch 96\n",
            "Fold 2/5\n",
            "initial train loss:  18.437761903565228 initial gdp train loss:  82.74208709200643\n",
            "initial val loss:  19.211181255949647 initial gdp val loss:  86.21291479543477\n",
            "Best Validation GDP Loss for fold 2: 0.8075\n",
            "Best best_epoch 229\n",
            "Fold 3/5\n",
            "initial train loss:  21.2547766045679 initial gdp train loss:  95.38383464571795\n",
            "initial val loss:  21.049935357045317 initial gdp val loss:  94.46457749706204\n",
            "Best Validation GDP Loss for fold 3: 0.6372\n",
            "Best best_epoch 277\n",
            "Fold 4/5\n",
            "initial train loss:  21.61447564459048 initial gdp train loss:  96.99803589768551\n",
            "initial val loss:  19.741005784374174 initial gdp val loss:  88.59058108572232\n",
            "Best Validation GDP Loss for fold 4: 0.7759\n",
            "Best best_epoch 327\n",
            "Fold 5/5\n",
            "initial train loss:  19.244654442187603 initial gdp train loss:  86.36313011072859\n",
            "initial val loss:  19.35109730090125 initial gdp val loss:  86.84080466577562\n",
            "Best Validation GDP Loss for fold 5: 0.7543\n",
            "Best best_epoch 330\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}: 0.7597\n",
            "\n",
            "Hyperparameter Search:  15% 8/54 [24:11<2:43:55, 213.81s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.84688026960506 initial gdp train loss:  92.1790534215044\n",
            "initial val loss:  7.211553906192298 initial gdp val loss:  97.0886224057494\n",
            "Best Validation GDP Loss for fold 1: 0.7535\n",
            "Best best_epoch 811\n",
            "Fold 2/5\n",
            "initial train loss:  5.931628281671956 initial gdp train loss:  79.85707887484206\n",
            "initial val loss:  6.183234815837956 initial gdp val loss:  83.24444618545661\n",
            "Best Validation GDP Loss for fold 2: 0.8278\n",
            "Best best_epoch 861\n",
            "Fold 3/5\n",
            "initial train loss:  8.26448385826143 initial gdp train loss:  111.26415001591549\n",
            "initial val loss:  8.196223226644225 initial gdp val loss:  110.34515846381753\n",
            "Best Validation GDP Loss for fold 3: 0.6763\n",
            "Best best_epoch 982\n",
            "Fold 4/5\n",
            "initial train loss:  7.456479173169357 initial gdp train loss:  100.38603886471519\n",
            "initial val loss:  6.81667472548404 initial gdp val loss:  91.77239550574352\n",
            "Best Validation GDP Loss for fold 4: 0.8641\n",
            "Best best_epoch 911\n",
            "Fold 5/5\n",
            "initial train loss:  7.547370962955781 initial gdp train loss:  101.60970786050402\n",
            "initial val loss:  7.587515321828551 initial gdp val loss:  102.15016782081733\n",
            "Best Validation GDP Loss for fold 5: 0.7993\n",
            "Best best_epoch 911\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}: 0.7842\n",
            "\n",
            "Hyperparameter Search:  17% 9/54 [28:35<2:52:17, 229.71s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  22.088779360749 initial gdp train loss:  99.12654575081758\n",
            "initial val loss:  23.217434346174993 initial gdp val loss:  104.19154505369042\n",
            "Best Validation GDP Loss for fold 1: 0.7540\n",
            "Best best_epoch 822\n",
            "Fold 2/5\n",
            "initial train loss:  18.562940621728877 initial gdp train loss:  83.30383797579033\n",
            "initial val loss:  19.34040778023856 initial gdp val loss:  86.79283520353943\n",
            "Best Validation GDP Loss for fold 2: 0.8321\n",
            "Best best_epoch 797\n",
            "Fold 3/5\n",
            "initial train loss:  19.6829316988273 initial gdp train loss:  88.3299617203982\n",
            "initial val loss:  19.47866339602713 initial gdp val loss:  87.413277965481\n",
            "Best Validation GDP Loss for fold 3: 0.6793\n",
            "Best best_epoch 954\n",
            "Fold 4/5\n",
            "initial train loss:  18.28423832438666 initial gdp train loss:  82.05312379603647\n",
            "initial val loss:  16.58738003746938 initial gdp val loss:  74.43822724940414\n",
            "Best Validation GDP Loss for fold 4: 0.8243\n",
            "Best best_epoch 997\n",
            "Fold 5/5\n",
            "initial train loss:  20.96749388618308 initial gdp train loss:  94.0946148900543\n",
            "initial val loss:  21.081354044251523 initial gdp val loss:  94.60557633739407\n",
            "Best Validation GDP Loss for fold 5: 0.8015\n",
            "Best best_epoch 987\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}: 0.7782\n",
            "\n",
            "Hyperparameter Search:  19% 10/54 [33:05<2:57:28, 242.01s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.217436662436036 initial gdp train loss:  83.70489300330648\n",
            "initial val loss:  6.568565428757868 initial gdp val loss:  88.43211819945263\n",
            "Best Validation GDP Loss for fold 1: 1.3060\n",
            "Best best_epoch 998\n",
            "Fold 2/5\n",
            "initial train loss:  7.481019356790103 initial gdp train loss:  100.71641993774672\n",
            "initial val loss:  7.777569919073281 initial gdp val loss:  104.70886769014247\n",
            "Best Validation GDP Loss for fold 2: 1.3276\n",
            "Best best_epoch 998\n",
            "Fold 3/5\n",
            "initial train loss:  7.587497041195253 initial gdp train loss:  102.14992233469516\n",
            "initial val loss:  7.520348961070432 initial gdp val loss:  101.24591620493743\n",
            "Best Validation GDP Loss for fold 3: 1.0803\n",
            "Best best_epoch 999\n",
            "Fold 4/5\n",
            "initial train loss:  7.1509764687421455 initial gdp train loss:  96.27307772737012\n",
            "initial val loss:  6.525503861702095 initial gdp val loss:  87.8523809142032\n",
            "Best Validation GDP Loss for fold 4: 1.5162\n",
            "Best best_epoch 995\n",
            "Fold 5/5\n",
            "initial train loss:  5.938856796876288 initial gdp train loss:  79.95439949518517\n",
            "initial val loss:  5.971950563333802 initial gdp val loss:  80.39994100796974\n",
            "Best Validation GDP Loss for fold 5: 0.9246\n",
            "Best best_epoch 995\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}: 1.2309\n",
            "\n",
            "Hyperparameter Search:  20% 11/54 [37:40<3:00:42, 252.16s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  18.22587908448427 initial gdp train loss:  81.79122853833576\n",
            "initial val loss:  19.267777803565274 initial gdp val loss:  86.46690189137178\n",
            "Best Validation GDP Loss for fold 1: 1.3195\n",
            "Best best_epoch 1000\n",
            "Fold 2/5\n",
            "initial train loss:  18.765584917451566 initial gdp train loss:  84.21323202830793\n",
            "initial val loss:  19.549492924153302 initial gdp val loss:  87.73112910935859\n",
            "Best Validation GDP Loss for fold 2: 1.3271\n",
            "Best best_epoch 998\n",
            "Fold 3/5\n",
            "initial train loss:  19.598602085676877 initial gdp train loss:  87.95151960799463\n",
            "initial val loss:  19.397764917147363 initial gdp val loss:  87.05023374395856\n",
            "Best Validation GDP Loss for fold 3: 1.0873\n",
            "Best best_epoch 992\n",
            "Fold 4/5\n",
            "initial train loss:  20.683105090499428 initial gdp train loss:  92.81838313235512\n",
            "initial val loss:  18.84802181437864 initial gdp val loss:  84.58318225408004\n",
            "Best Validation GDP Loss for fold 4: 1.5308\n",
            "Best best_epoch 1000\n",
            "Fold 5/5\n",
            "initial train loss:  19.469363289040352 initial gdp train loss:  87.37153786445971\n",
            "initial val loss:  19.575958445920783 initial gdp val loss:  87.8499033006571\n",
            "Best Validation GDP Loss for fold 5: 0.9508\n",
            "Best best_epoch 993\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}: 1.2431\n",
            "\n",
            "Hyperparameter Search:  22% 12/54 [42:06<2:59:20, 256.19s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 3, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.06423985882491 initial gdp train loss:  95.10534585706779\n",
            "initial val loss:  7.432933522873566 initial gdp val loss:  100.06904377656825\n",
            "Best Validation GDP Loss for fold 1: 0.8520\n",
            "Best best_epoch 69\n",
            "Fold 2/5\n",
            "initial train loss:  6.715343832213581 initial gdp train loss:  90.40819005986349\n",
            "initial val loss:  6.990372409339712 initial gdp val loss:  94.11087581089565\n",
            "Best Validation GDP Loss for fold 2: 0.8033\n",
            "Best best_epoch 362\n",
            "Fold 3/5\n",
            "initial train loss:  7.6400117552230125 initial gdp train loss:  102.85692470888549\n",
            "initial val loss:  7.572376364368504 initial gdp val loss:  101.94635242526815\n",
            "Best Validation GDP Loss for fold 3: 0.6317\n",
            "Best best_epoch 247\n",
            "Fold 4/5\n",
            "initial train loss:  8.140245286724236 initial gdp train loss:  109.59153438519827\n",
            "initial val loss:  7.466228517435365 initial gdp val loss:  100.51728898387844\n",
            "Best Validation GDP Loss for fold 4: 0.8661\n",
            "Best best_epoch 162\n",
            "Fold 5/5\n",
            "initial train loss:  5.973269893147271 initial gdp train loss:  80.41770114174372\n",
            "initial val loss:  6.006551888029454 initial gdp val loss:  80.86577127747617\n",
            "Best Validation GDP Loss for fold 5: 0.7233\n",
            "Best best_epoch 229\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 3, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}: 0.7753\n",
            "\n",
            "Hyperparameter Search:  24% 13/54 [48:35<3:22:36, 296.51s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 3, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  19.735691389120156 initial gdp train loss:  88.56672923307842\n",
            "initial val loss:  20.81253566261099 initial gdp val loss:  93.39921582646731\n",
            "Best Validation GDP Loss for fold 1: 0.7818\n",
            "Best best_epoch 168\n",
            "Fold 2/5\n",
            "initial train loss:  19.93190313746511 initial gdp train loss:  89.4472568826494\n",
            "initial val loss:  20.751061094909154 initial gdp val loss:  93.1233411516462\n",
            "Best Validation GDP Loss for fold 2: 0.7271\n",
            "Best best_epoch 990\n",
            "Fold 3/5\n",
            "initial train loss:  21.191838204106197 initial gdp train loss:  95.10139294716879\n",
            "initial val loss:  20.987764293864622 initial gdp val loss:  94.18558140124304\n",
            "Best Validation GDP Loss for fold 3: 0.6285\n",
            "Best best_epoch 356\n",
            "Fold 4/5\n",
            "initial train loss:  19.256345080926952 initial gdp train loss:  86.41559307887081\n",
            "initial val loss:  17.50691000081725 initial gdp val loss:  78.56475157656912\n",
            "Best Validation GDP Loss for fold 4: 0.8124\n",
            "Best best_epoch 213\n",
            "Fold 5/5\n",
            "initial train loss:  17.985082240044317 initial gdp train loss:  80.71061844966583\n",
            "initial val loss:  18.085366944135245 initial gdp val loss:  81.16065849692134\n",
            "Best Validation GDP Loss for fold 5: 0.7255\n",
            "Best best_epoch 221\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 3, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}: 0.7351\n",
            "\n",
            "Hyperparameter Search:  26% 14/54 [55:04<3:36:14, 324.35s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 3, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  5.9676920787980645 initial gdp train loss:  80.34260368750412\n",
            "initial val loss:  6.313273838588169 initial gdp val loss:  84.9951471280651\n",
            "Best Validation GDP Loss for fold 1: 0.7488\n",
            "Best best_epoch 823\n",
            "Fold 2/5\n",
            "initial train loss:  6.843531731571254 initial gdp train loss:  92.13397003883539\n",
            "initial val loss:  7.12215098212747 initial gdp val loss:  95.88499918705276\n",
            "Best Validation GDP Loss for fold 2: 0.8767\n",
            "Best best_epoch 993\n",
            "Fold 3/5\n",
            "initial train loss:  7.5839353995987135 initial gdp train loss:  102.10196737297477\n",
            "initial val loss:  7.516047186770682 initial gdp val loss:  101.18799358303264\n",
            "Best Validation GDP Loss for fold 3: 0.8093\n",
            "Best best_epoch 984\n",
            "Fold 4/5\n",
            "initial train loss:  7.162197774975612 initial gdp train loss:  96.42414785135648\n",
            "initial val loss:  6.538650553105241 initial gdp val loss:  88.0293760138043\n",
            "Best Validation GDP Loss for fold 4: 0.9485\n",
            "Best best_epoch 900\n",
            "Fold 5/5\n",
            "initial train loss:  6.3433215185559755 initial gdp train loss:  85.39967903105016\n",
            "initial val loss:  6.378288075075311 initial gdp val loss:  85.87043335478185\n",
            "Best Validation GDP Loss for fold 5: 0.7704\n",
            "Best best_epoch 943\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 3, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}: 0.8307\n",
            "\n",
            "Hyperparameter Search:  28% 15/54 [1:01:31<3:43:11, 343.38s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 3, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  19.376065655440154 initial gdp train loss:  86.95285508395753\n",
            "initial val loss:  20.445022470810834 initial gdp val loss:  91.74995467242073\n",
            "Best Validation GDP Loss for fold 1: 0.7382\n",
            "Best best_epoch 778\n",
            "Fold 2/5\n",
            "initial train loss:  16.916829615264312 initial gdp train loss:  75.91668339864397\n",
            "initial val loss:  17.64355956005449 initial gdp val loss:  79.17798858129677\n",
            "Best Validation GDP Loss for fold 2: 0.8790\n",
            "Best best_epoch 912\n",
            "Fold 3/5\n",
            "initial train loss:  19.620001684261275 initial gdp train loss:  88.04755465994404\n",
            "initial val loss:  19.415365930330957 initial gdp val loss:  87.1292203482935\n",
            "Best Validation GDP Loss for fold 3: 0.8039\n",
            "Best best_epoch 859\n",
            "Fold 4/5\n",
            "initial train loss:  18.582320965795073 initial gdp train loss:  83.39081200064486\n",
            "initial val loss:  16.87107719809322 initial gdp val loss:  75.7113644874702\n",
            "Best Validation GDP Loss for fold 4: 0.9851\n",
            "Best best_epoch 758\n",
            "Fold 5/5\n",
            "initial train loss:  18.22331878404577 initial gdp train loss:  81.77973706209207\n",
            "initial val loss:  18.324659218222408 initial gdp val loss:  82.2345162084547\n",
            "Best Validation GDP Loss for fold 5: 0.7840\n",
            "Best best_epoch 972\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 3, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}: 0.8380\n",
            "\n",
            "Hyperparameter Search:  30% 16/54 [1:07:58<3:45:45, 356.47s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 3, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  5.900392008130193 initial gdp train loss:  79.43654790640382\n",
            "initial val loss:  6.244459064066911 initial gdp val loss:  84.0686948760217\n",
            "Best Validation GDP Loss for fold 1: 1.3830\n",
            "Best best_epoch 998\n",
            "Fold 2/5\n",
            "initial train loss:  7.076393642586835 initial gdp train loss:  95.26897164278252\n",
            "initial val loss:  7.36189148205669 initial gdp val loss:  99.11261236367105\n",
            "Best Validation GDP Loss for fold 2: 1.4165\n",
            "Best best_epoch 996\n",
            "Fold 3/5\n",
            "initial train loss:  7.064397646908016 initial gdp train loss:  95.10747518418711\n",
            "initial val loss:  6.9963732573945645 initial gdp val loss:  94.19166707184355\n",
            "Best Validation GDP Loss for fold 3: 1.0719\n",
            "Best best_epoch 999\n",
            "Fold 4/5\n",
            "initial train loss:  6.726759204381628 initial gdp train loss:  90.56187062323848\n",
            "initial val loss:  6.126262777942722 initial gdp val loss:  82.4774330268472\n",
            "Best Validation GDP Loss for fold 4: 1.5627\n",
            "Best best_epoch 998\n",
            "Fold 5/5\n",
            "initial train loss:  6.762751683907167 initial gdp train loss:  91.04643674440021\n",
            "initial val loss:  6.799548149108887 initial gdp val loss:  91.54182666843221\n",
            "Best Validation GDP Loss for fold 5: 1.0217\n",
            "Best best_epoch 999\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 3, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}: 1.2912\n",
            "\n",
            "Hyperparameter Search:  31% 17/54 [1:14:25<3:45:31, 365.71s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 3, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  22.004121106976434 initial gdp train loss:  98.74662225896662\n",
            "initial val loss:  23.12771840456153 initial gdp val loss:  103.78892888942687\n",
            "Best Validation GDP Loss for fold 1: 1.3926\n",
            "Best best_epoch 1000\n",
            "Fold 2/5\n",
            "initial train loss:  21.384019387952872 initial gdp train loss:  95.96383397624558\n",
            "initial val loss:  22.244476478640774 initial gdp val loss:  99.82525904038373\n",
            "Best Validation GDP Loss for fold 2: 1.4192\n",
            "Best best_epoch 1000\n",
            "Fold 3/5\n",
            "initial train loss:  19.916000752509394 initial gdp train loss:  89.37589009602864\n",
            "initial val loss:  19.71138637348757 initial gdp val loss:  88.4576699208405\n",
            "Best Validation GDP Loss for fold 3: 1.0703\n",
            "Best best_epoch 996\n",
            "Fold 4/5\n",
            "initial train loss:  18.39889428987785 initial gdp train loss:  82.5676576960439\n",
            "initial val loss:  16.698055170350155 initial gdp val loss:  74.93490109201205\n",
            "Best Validation GDP Loss for fold 4: 1.5381\n",
            "Best best_epoch 994\n",
            "Fold 5/5\n",
            "initial train loss:  20.338859195950665 initial gdp train loss:  91.27352847328669\n",
            "initial val loss:  20.449644379696604 initial gdp val loss:  91.77068936622749\n",
            "Best Validation GDP Loss for fold 5: 1.0076\n",
            "Best best_epoch 1000\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 3, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}: 1.2856\n",
            "\n",
            "Hyperparameter Search:  33% 18/54 [1:20:52<3:43:15, 372.10s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.368100180434374 initial gdp train loss:  99.19619452575296\n",
            "initial val loss:  7.743251944790368 initial gdp val loss:  104.24683835326123\n",
            "Best Validation GDP Loss for fold 1: 0.7370\n",
            "Best best_epoch 136\n",
            "Fold 2/5\n",
            "initial train loss:  7.288800930119972 initial gdp train loss:  98.12859810633589\n",
            "initial val loss:  7.579926606987705 initial gdp val loss:  102.04800049597476\n",
            "Best Validation GDP Loss for fold 2: 0.8026\n",
            "Best best_epoch 136\n",
            "Fold 3/5\n",
            "initial train loss:  7.0806940275908525 initial gdp train loss:  95.32686888618308\n",
            "initial val loss:  7.010998200562041 initial gdp val loss:  94.38855678752317\n",
            "Best Validation GDP Loss for fold 3: 0.5550\n",
            "Best best_epoch 660\n",
            "Fold 4/5\n",
            "initial train loss:  6.354188045871911 initial gdp train loss:  85.5459726068038\n",
            "initial val loss:  5.778196771266097 initial gdp val loss:  77.79144300040552\n",
            "Best Validation GDP Loss for fold 4: 0.8745\n",
            "Best best_epoch 354\n",
            "Fold 5/5\n",
            "initial train loss:  6.1609327098991296 initial gdp train loss:  82.94419255638927\n",
            "initial val loss:  6.1938913070549395 initial gdp val loss:  83.38790803036447\n",
            "Best Validation GDP Loss for fold 5: 0.6682\n",
            "Best best_epoch 440\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}: 0.7274\n",
            "\n",
            "Hyperparameter Search:  35% 19/54 [1:26:02<3:26:08, 353.38s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  22.272629518085505 initial gdp train loss:  99.95159965337709\n",
            "initial val loss:  23.40795690071683 initial gdp val loss:  105.04653674213826\n",
            "Best Validation GDP Loss for fold 1: 0.7199\n",
            "Best best_epoch 115\n",
            "Fold 2/5\n",
            "initial train loss:  20.444003292672477 initial gdp train loss:  91.7453754255686\n",
            "initial val loss:  21.27679449770631 initial gdp val loss:  95.48265056449826\n",
            "Best Validation GDP Loss for fold 2: 0.8159\n",
            "Best best_epoch 128\n",
            "Fold 3/5\n",
            "initial train loss:  20.679893614370613 initial gdp train loss:  92.80397085197868\n",
            "initial val loss:  20.47450838250629 initial gdp val loss:  91.88227430440612\n",
            "Best Validation GDP Loss for fold 3: 0.5287\n",
            "Best best_epoch 542\n",
            "Fold 4/5\n",
            "initial train loss:  20.66205742590538 initial gdp train loss:  92.72392565892216\n",
            "initial val loss:  18.839504435911017 initial gdp val loss:  84.54496002197266\n",
            "Best Validation GDP Loss for fold 4: 0.8579\n",
            "Best best_epoch 202\n",
            "Fold 5/5\n",
            "initial train loss:  22.997873475279988 initial gdp train loss:  103.20623405875033\n",
            "initial val loss:  23.118409690210374 initial gdp val loss:  103.74715914968716\n",
            "Best Validation GDP Loss for fold 5: 0.7270\n",
            "Best best_epoch 552\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}: 0.7299\n",
            "\n",
            "Hyperparameter Search:  37% 20/54 [1:31:10<3:12:32, 339.78s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.546882553786102 initial gdp train loss:  88.14020688337202\n",
            "initial val loss:  6.906395503452846 initial gdp val loss:  92.98029673600398\n",
            "Best Validation GDP Loss for fold 1: 0.7251\n",
            "Best best_epoch 881\n",
            "Fold 2/5\n",
            "initial train loss:  6.640104846268829 initial gdp train loss:  89.39525167130516\n",
            "initial val loss:  6.9130796264199645 initial gdp val loss:  93.0702955742844\n",
            "Best Validation GDP Loss for fold 2: 0.7913\n",
            "Best best_epoch 796\n",
            "Fold 3/5\n",
            "initial train loss:  6.157061749872779 initial gdp train loss:  82.89207625892092\n",
            "initial val loss:  6.088884903212725 initial gdp val loss:  81.97421613790222\n",
            "Best Validation GDP Loss for fold 3: 0.7031\n",
            "Best best_epoch 565\n",
            "Fold 4/5\n",
            "initial train loss:  6.953299307118991 initial gdp train loss:  93.61176592991825\n",
            "initial val loss:  6.336804996102543 initial gdp val loss:  85.31194602836997\n",
            "Best Validation GDP Loss for fold 4: 0.8295\n",
            "Best best_epoch 936\n",
            "Fold 5/5\n",
            "initial train loss:  7.498620632831558 initial gdp train loss:  100.95338542954329\n",
            "initial val loss:  7.539390167947543 initial gdp val loss:  101.50226269738148\n",
            "Best Validation GDP Loss for fold 5: 0.7753\n",
            "Best best_epoch 535\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}: 0.7649\n",
            "\n",
            "Hyperparameter Search:  39% 21/54 [1:36:17<3:01:32, 330.07s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  21.48326724578664 initial gdp train loss:  96.40922467350708\n",
            "initial val loss:  22.589794094822988 initial gdp val loss:  101.37492178267792\n",
            "Best Validation GDP Loss for fold 1: 0.7278\n",
            "Best best_epoch 787\n",
            "Fold 2/5\n",
            "initial train loss:  19.444660392422506 initial gdp train loss:  87.26068620097058\n",
            "initial val loss:  20.24795711741728 initial gdp val loss:  90.86559276420529\n",
            "Best Validation GDP Loss for fold 2: 0.7899\n",
            "Best best_epoch 842\n",
            "Fold 3/5\n",
            "initial train loss:  21.867477763051223 initial gdp train loss:  98.13342262622173\n",
            "initial val loss:  21.662643270977473 initial gdp val loss:  97.21419926012976\n",
            "Best Validation GDP Loss for fold 3: 0.7062\n",
            "Best best_epoch 722\n",
            "Fold 4/5\n",
            "initial train loss:  20.033002016413565 initial gdp train loss:  89.90094979201692\n",
            "initial val loss:  18.244819220850022 initial gdp val loss:  81.87622445316639\n",
            "Best Validation GDP Loss for fold 4: 0.8364\n",
            "Best best_epoch 983\n",
            "Fold 5/5\n",
            "initial train loss:  20.780139577036667 initial gdp train loss:  93.25383620121308\n",
            "initial val loss:  20.892574342630677 initial gdp val loss:  93.7583990581965\n",
            "Best Validation GDP Loss for fold 5: 0.7835\n",
            "Best best_epoch 364\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}: 0.7688\n",
            "\n",
            "Hyperparameter Search:  41% 22/54 [1:41:25<2:52:25, 323.30s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.028764394070583 initial gdp train loss:  94.62774693688681\n",
            "initial val loss:  7.39545481144881 initial gdp val loss:  99.56447517972033\n",
            "Best Validation GDP Loss for fold 1: 1.9379\n",
            "Best best_epoch 998\n",
            "Fold 2/5\n",
            "initial train loss:  6.283056807568411 initial gdp train loss:  84.58833892048035\n",
            "initial val loss:  6.545934548898905 initial gdp val loss:  88.12744256027607\n",
            "Best Validation GDP Loss for fold 2: 1.8557\n",
            "Best best_epoch 996\n",
            "Fold 3/5\n",
            "initial train loss:  7.389405465830228 initial gdp train loss:  99.4830303594533\n",
            "initial val loss:  7.322079286736957 initial gdp val loss:  98.57662252652443\n",
            "Best Validation GDP Loss for fold 3: 1.5721\n",
            "Best best_epoch 1000\n",
            "Fold 4/5\n",
            "initial train loss:  7.423957778431695 initial gdp train loss:  99.94820323573889\n",
            "initial val loss:  6.7858299400846835 initial gdp val loss:  91.35713519080211\n",
            "Best Validation GDP Loss for fold 4: 2.1970\n",
            "Best best_epoch 994\n",
            "Fold 5/5\n",
            "initial train loss:  6.417633259849709 initial gdp train loss:  86.40013000230749\n",
            "initial val loss:  6.453342728695627 initial gdp val loss:  86.88088290974245\n",
            "Best Validation GDP Loss for fold 5: 1.3320\n",
            "Best best_epoch 990\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}: 1.7789\n",
            "\n",
            "Hyperparameter Search:  43% 23/54 [1:46:32<2:44:27, 318.30s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  19.441429194637887 initial gdp train loss:  87.2461824961495\n",
            "initial val loss:  20.507090945203764 initial gdp val loss:  92.02849655792492\n",
            "Best Validation GDP Loss for fold 1: 1.8264\n",
            "Best best_epoch 998\n",
            "Fold 2/5\n",
            "initial train loss:  23.56118323586204 initial gdp train loss:  105.73416365125466\n",
            "initial val loss:  24.475718217737533 initial gdp val loss:  109.83827158182609\n",
            "Best Validation GDP Loss for fold 2: 1.9406\n",
            "Best best_epoch 1000\n",
            "Fold 3/5\n",
            "initial train loss:  20.504186775110945 initial gdp train loss:  92.01546030809105\n",
            "initial val loss:  20.300342268862966 initial gdp val loss:  91.10067684367552\n",
            "Best Validation GDP Loss for fold 3: 1.5793\n",
            "Best best_epoch 1000\n",
            "Fold 4/5\n",
            "initial train loss:  22.472932646546184 initial gdp train loss:  100.85048662660495\n",
            "initial val loss:  20.54544966099626 initial gdp val loss:  92.20063497252383\n",
            "Best Validation GDP Loss for fold 4: 2.2219\n",
            "Best best_epoch 999\n",
            "Fold 5/5\n",
            "initial train loss:  21.26988615365974 initial gdp train loss:  95.4516479878486\n",
            "initial val loss:  21.387400934251687 initial gdp val loss:  95.97901114770922\n",
            "Best Validation GDP Loss for fold 5: 1.3089\n",
            "Best best_epoch 1000\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 1e-05, 'batch_size': 64, 'num_epochs': 1000, 'weight': 60, 'weight_decay': 0.01}: 1.7754\n",
            "\n",
            "Hyperparameter Search:  44% 24/54 [1:51:38<2:37:26, 314.88s/it]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.256812468643672 initial gdp train loss:  97.69794202808598\n",
            "initial val loss:  7.630125718958237 initial gdp val loss:  102.72382816346753\n",
            "Best Validation GDP Loss for fold 1: 0.8132\n",
            "Best best_epoch 85\n",
            "Fold 2/5\n",
            "initial train loss:  7.330022375376986 initial gdp train loss:  98.68356052261578\n",
            "initial val loss:  7.622185374508385 initial gdp val loss:  102.6169331654781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.run_mlp_q"
      ],
      "metadata": {
        "id": "LWP9Puo-R9L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.run_mlp_y"
      ],
      "metadata": {
        "id": "LLlx8jcebvxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.run_transformer_y"
      ],
      "metadata": {
        "id": "ch2Bd7YTcENt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Multi_Country_GDP_Prediction/timesfm_PatchTST_TimeLLM/Time-LLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6le6aOtkWtsZ",
        "outputId": "9fca555a-3c6b-4497-9cfe-5c53f7763adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Multi_Country_GDP_Prediction/timesfm_PatchTST_TimeLLM/Time-LLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NrQRtW_AddZL",
        "outputId": "304c9571-c1ff-4c83-b49c-d5315b51c71e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.2.2 (from -r requirements.txt (line 1))\n",
            "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting accelerate==0.28.0 (from -r requirements.txt (line 2))\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting einops==0.7.0 (from -r requirements.txt (line 3))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting matplotlib==3.7.0 (from -r requirements.txt (line 4))\n",
            "  Downloading matplotlib-3.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting numpy==1.23.5 (from -r requirements.txt (line 5))\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting pandas==1.5.3 (from -r requirements.txt (line 6))\n",
            "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scikit_learn==1.2.2 (from -r requirements.txt (line 7))\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy==1.12.0 (from -r requirements.txt (line 8))\n",
            "  Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.65.0 (from -r requirements.txt (line 9))\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft==0.4.0 (from -r requirements.txt (line 10))\n",
            "  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting transformers==4.31.0 (from -r requirements.txt (line 11))\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepspeed==0.14.0 (from -r requirements.txt (line 12))\n",
            "  Downloading deepspeed-0.14.0.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (0.27.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (0.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3->-r requirements.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.2.2->-r requirements.txt (line 7)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.2.2->-r requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0->-r requirements.txt (line 11)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0->-r requirements.txt (line 11)) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0->-r requirements.txt (line 11))\n",
            "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting hjson (from deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting ninja (from deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.14.0->-r requirements.txt (line 12)) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.14.0->-r requirements.txt (line 12)) (2.10.6)\n",
            "Collecting pynvml (from deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->-r requirements.txt (line 1)) (12.5.82)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.0->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.2->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->deepspeed==0.14.0->-r requirements.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->deepspeed==0.14.0->-r requirements.txt (line 12)) (2.27.2)\n",
            "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml->deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.2->-r requirements.txt (line 1)) (1.3.0)\n",
            "Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.4.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.14.0-py3-none-any.whl size=1400392 sha256=daf27650b0408cc4c67d7c9e5a9b85a7df9e2a511a0e2d1e7050a599cc64e7dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/93/10/aca4f9f9390297a80a58fb8db0fcdcf1f41499d1afe922a513\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: tokenizers, nvidia-ml-py, hjson, triton, tqdm, pynvml, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ninja, einops, scipy, pandas, nvidia-cusolver-cu12, nvidia-cudnn-cu12, transformers, torch, scikit_learn, matplotlib, deepspeed, accelerate, peft\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.0\n",
            "    Uninstalling einops-0.8.0:\n",
            "      Successfully uninstalled einops-0.8.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.2.1\n",
            "    Uninstalling accelerate-1.2.1:\n",
            "      Successfully uninstalled accelerate-1.2.1\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.2.2 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 2.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "bigframes 1.34.0 requires matplotlib>=3.7.1, but you have matplotlib 3.7.0 which is incompatible.\n",
            "bigframes 1.34.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.31.0 which is incompatible.\n",
            "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.1 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "blosc2 3.0.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.0 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 24.12.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.28.0 deepspeed-0.14.0 einops-0.7.0 hjson-3.1.0 matplotlib-3.7.0 ninja-1.11.1.3 numpy-1.23.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py-12.570.86 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 pandas-1.5.3 peft-0.4.0 pynvml-12.0.0 scikit_learn-1.2.2 scipy-1.12.0 tokenizers-0.13.3 torch-2.2.2 tqdm-4.65.0 transformers-4.31.0 triton-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              },
              "id": "7690c0485b4d4898af7e9c7adda4957b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m run_timellm_q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wbOJsEdRWi0",
        "outputId": "382dadd3-f943-4a31-fb08-d5b877aedd38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file item list length:  42\n",
            "\r  0% 0/42 [00:00<?, ?it/s]LSTM_data_gdp_more_light_sms_q_t8_13-19.pt\n",
            "train_data shape  torch.Size([336, 8, 4])\n",
            "test_data shape  torch.Size([84, 8, 4])\n",
            "\n",
            "\rHyperparameter Search:   0% 0/12 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating parameters: {'d_model': 32, 'learning_rate': 0.01, 'train_epochs': 20, 'patch_len': 3, 'description_add': 'Gross Domestic Product (GDP) is a measure of the total monetary value of all finished goods and services produced within a country’s borders in a specific time period. This dataset consists GDP and some Nighttime light remote sensing data, which refers to the use of remote sensing technology to capture the distribution of lights on Earth at night.'}\n",
            "Fold 1/5\n",
            "Loader Done!\n",
            "\rHyperparameter Search:   0% 0/12 [00:00<?, ?it/s]\n",
            "\r  0% 0/42 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 672, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "                           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 417, in cached_file\n",
            "    resolved_file = hf_hub_download(\n",
            "                    ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n",
            "    validate_repo_id(arg_value)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n",
            "    raise HFValidationError(\n",
            "huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/ailab/user/xiehuaqing/Time-LLM/local_model/gpt2'. Use `repo_type` argument if needed.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/Multi_Country_GDP_Prediction/timesfm_PatchTST_TimeLLM/Time-LLM/run_timellm_q.py\", line 832, in <module>\n",
            "    best_params, best_overall_loss = hyperparameter_search(train_data, train_targets, param_grid, k_folds=5, device=device)\n",
            "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Multi_Country_GDP_Prediction/timesfm_PatchTST_TimeLLM/Time-LLM/run_timellm_q.py\", line 449, in hyperparameter_search\n",
            "    model = TimeLLM.Model(args).float()\n",
            "            ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Multi_Country_GDP_Prediction/timesfm_PatchTST_TimeLLM/Time-LLM/models/TimeLLM.py\", line 103, in __init__\n",
            "    self.gpt2_config = GPT2Config.from_pretrained('/ailab/user/xiehuaqing/Time-LLM/local_model/gpt2')\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 590, in from_pretrained\n",
            "    config_dict, kwargs = cls.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 617, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 693, in _get_config_dict\n",
            "    raise EnvironmentError(\n",
            "OSError: Can't load the configuration of '/ailab/user/xiehuaqing/Time-LLM/local_model/gpt2'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/ailab/user/xiehuaqing/Time-LLM/local_model/gpt2' is the correct path to a directory containing a config.json file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Multi_Country_GDP_Prediction/timesfm_PatchTST_TimeLLM/patchTST"
      ],
      "metadata": {
        "id": "8FZ2siflWf6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "HLgP5mq-zh9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m run_patchtst_q"
      ],
      "metadata": {
        "id": "_9UI50C7zyz2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
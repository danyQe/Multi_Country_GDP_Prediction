{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIQXZNvBNglc",
        "outputId": "7413149c-621d-485e-acef-2b563841d2e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Multi_Country_GDP_Prediction'...\n",
            "remote: Enumerating objects: 736, done.\u001b[K\n",
            "remote: Counting objects: 100% (204/204), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 736 (delta 120), reused 155 (delta 86), pack-reused 532 (from 1)\u001b[K\n",
            "Receiving objects: 100% (736/736), 284.82 MiB | 21.58 MiB/s, done.\n",
            "Resolving deltas: 100% (427/427), done.\n",
            "Updating files: 100% (400/400), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/danyQe/Multi_Country_GDP_Prediction.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/Multi_Country_GDP_Prediction/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H37ZQk8KOa8R",
        "outputId": "d19fbeb0-c4cb-44a9-ffce-bdfb159582e1",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting absl-py==2.1.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 1))\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting accelerate==0.30.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 2))\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting aiohttp==3.9.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 3))\n",
            "  Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting aiosignal==1.3.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 4))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 5)) (0.7.0)\n",
            "Collecting anyio==4.4.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 6))\n",
            "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting asttokens==2.4.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 7))\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting async-timeout==4.0.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 8))\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting attrs==23.2.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 9))\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 10)) (0.2.0)\n",
            "Collecting cachetools==5.3.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 11))\n",
            "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting certifi==2022.12.7 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 12))\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting charset-normalizer==2.1.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 13))\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting click==8.1.7 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 14))\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting cloudpickle==3.0.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 15))\n",
            "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting cmake==3.25.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 16))\n",
            "  Downloading cmake-3.25.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting comm==0.2.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 17))\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting contourpy==1.1.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 18))\n",
            "  Downloading contourpy-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 19)) (0.12.1)\n",
            "Collecting datasets==2.20.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 20))\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting debugpy==1.8.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 21))\n",
            "  Downloading debugpy-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting decorator==5.1.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 22))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting diffusers==0.29.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 23))\n",
            "  Downloading diffusers-0.29.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting dill==0.3.8 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 24))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting diskcache==5.6.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 25))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: distro==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 26)) (1.9.0)\n",
            "Collecting dnspython==2.6.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 27))\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: einops==0.8.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 28)) (0.8.0)\n",
            "Collecting email_validator==2.2.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 29))\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting et-xmlfile==1.1.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 30))\n",
            "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting exceptiongroup==1.2.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 31))\n",
            "  Downloading exceptiongroup-1.2.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting executing==2.0.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 32))\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting fastapi==0.111.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 33))\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting fastapi-cli==0.0.4 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 34))\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting filelock==3.13.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 35))\n",
            "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting flash-attn==2.5.8 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 36))\n",
            "  Downloading flash_attn-2.5.8.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fonttools==4.51.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 37))\n",
            "  Downloading fonttools-4.51.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist==1.4.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 38))\n",
            "  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting fsspec==2024.3.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 39))\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting google-auth==2.29.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 40))\n",
            "  Downloading google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting google-auth-oauthlib==1.0.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 41))\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting grpcio==1.63.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 42))\n",
            "  Downloading grpcio-1.63.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: h11==0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 43)) (0.14.0)\n",
            "Collecting httpcore==1.0.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 44))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting httptools==0.6.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 45))\n",
            "  Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting httpx==0.27.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 46))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting huggingface-hub==0.23.4 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 47))\n",
            "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting idna==3.4 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 48))\n",
            "  Downloading idna-3.4-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting importlib_metadata==7.1.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 49))\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting importlib_resources==6.4.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 50))\n",
            "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting interegular==0.3.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 51))\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Collecting ipykernel==6.29.4 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 52))\n",
            "  Downloading ipykernel-6.29.4-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ipython==8.12.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 53))\n",
            "  Downloading ipython-8.12.3-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jedi==0.19.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 54))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting Jinja2==3.1.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 55))\n",
            "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 56)) (1.4.2)\n",
            "Requirement already satisfied: jsonschema==4.23.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 57)) (4.23.0)\n",
            "Collecting jsonschema-specifications==2023.12.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 58))\n",
            "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting jupyter_client==8.6.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 59))\n",
            "  Downloading jupyter_client-8.6.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: jupyter_core==5.7.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 60)) (5.7.2)\n",
            "Collecting kiwisolver==1.4.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 61))\n",
            "  Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting lark==1.1.9 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 62))\n",
            "  Downloading lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting lit==15.0.7 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 63))\n",
            "  Downloading lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llvmlite==0.41.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 64))\n",
            "  Downloading llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting lm-format-enforcer==0.10.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 65))\n",
            "  Downloading lm_format_enforcer-0.10.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting lxml==5.2.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 66))\n",
            "  Downloading lxml-5.2.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting Markdown==3.6 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 67))\n",
            "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: markdown-it-py==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 68)) (3.0.0)\n",
            "Collecting MarkupSafe==2.1.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 69))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting matplotlib==3.7.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 70))\n",
            "  Downloading matplotlib-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.7 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 71)) (0.1.7)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 72)) (0.1.2)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 73)) (1.3.0)\n",
            "Collecting msgpack==1.0.8 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 74))\n",
            "  Downloading msgpack-1.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting multidict==6.0.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 75))\n",
            "  Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting multiprocess==0.70.16 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 76))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 77)) (1.6.0)\n",
            "Collecting networkx==3.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 78))\n",
            "  Downloading networkx-3.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting ninja==1.11.1.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 79))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting numba==0.58.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 80))\n",
            "  Downloading numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numpy==1.24.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 81))\n",
            "  Downloading numpy-1.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 82))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 83))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 84))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 85))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 86))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 87))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 88))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 89))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 90))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-ml-py==12.555.43 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 91))\n",
            "  Downloading nvidia_ml_py-12.555.43-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 92))\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.5.82 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 93)) (12.5.82)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 94))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 95)) (3.2.2)\n",
            "Collecting openai==1.35.13 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 96))\n",
            "  Downloading openai-1.35.13-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting opencv-python==4.10.0.82 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 97))\n",
            "  Downloading opencv_python-4.10.0.82-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting openpyxl==3.1.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 98))\n",
            "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting orjson==3.10.6 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 99))\n",
            "  Downloading orjson-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting outlines==0.0.46 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 100))\n",
            "  Downloading outlines-0.0.46-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting packaging==24.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 101))\n",
            "  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas==2.0.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 102))\n",
            "  Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: parso==0.8.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 103)) (0.8.4)\n",
            "Collecting peft==0.10.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 104))\n",
            "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pexpect==4.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 105)) (4.9.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 106)) (0.7.5)\n",
            "Collecting pillow==10.2.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 107))\n",
            "  Downloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting pkgutil_resolve_name==1.3.10 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 108))\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl.metadata (624 bytes)\n",
            "Collecting platformdirs==4.2.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 109))\n",
            "  Downloading platformdirs-4.2.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting prometheus-fastapi-instrumentator==7.0.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 110))\n",
            "  Downloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting prometheus_client==0.20.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 111))\n",
            "  Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting prompt-toolkit==3.0.43 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 112))\n",
            "  Downloading prompt_toolkit-3.0.43-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting protobuf==5.26.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 113))\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting psutil==5.9.8 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 114))\n",
            "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 115)) (0.7.0)\n",
            "Collecting pure-eval==0.2.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 116))\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: py-cpuinfo==9.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 117)) (9.0.0)\n",
            "Collecting pyairports==2.1.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 118))\n",
            "  Downloading pyairports-2.1.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pyarrow==16.1.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 119))\n",
            "  Downloading pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyarrow-hotfix==0.6 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 120))\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pyasn1==0.6.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 121))\n",
            "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting pyasn1_modules==0.4.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 122))\n",
            "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pycountry==24.6.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 123))\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic==2.8.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 124))\n",
            "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic_core==2.20.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 125))\n",
            "  Downloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: Pygments==2.18.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 126)) (2.18.0)\n",
            "Collecting pyparsing==3.1.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 127))\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-dateutil==2.9.0.post0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 128))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting python-docx==1.1.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 129))\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-dotenv==1.0.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 130))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting python-multipart==0.0.9 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 131))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pytz==2024.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 132))\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting PyYAML==6.0.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 133))\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting pyzmq==26.0.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 134))\n",
            "  Downloading pyzmq-26.0.3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting ray==2.10.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 135))\n",
            "  Downloading ray-2.10.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting referencing==0.35.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 136))\n",
            "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting regex==2024.5.10 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 137))\n",
            "  Downloading regex-2024.5.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 138)) (2.32.3)\n",
            "Collecting requests-oauthlib==2.0.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 139))\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting rich==13.7.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 140))\n",
            "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rpds-py==0.19.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 141))\n",
            "  Downloading rpds_py-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 142)) (4.9)\n",
            "Collecting safetensors==0.4.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 143))\n",
            "  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting scikit-learn==1.3.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 144))\n",
            "  Downloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy==1.10.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 145))\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 146)) (0.13.2)\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 147)) (0.2.0)\n",
            "Requirement already satisfied: shellingham==1.5.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 148)) (1.5.4)\n",
            "Collecting six==1.16.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 149))\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 150)) (1.3.1)\n",
            "Collecting stack-data==0.6.3 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 151))\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting starlette==0.37.2 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 152))\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting sympy==1.12 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 153))\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tensorboard==2.14.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 154))\n",
            "  Downloading tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorboard-data-server==0.7.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 155)) (0.7.2)\n",
            "Requirement already satisfied: threadpoolctl==3.5.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 156)) (3.5.0)\n",
            "Collecting tiktoken==0.7.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 157))\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting timm==0.9.16 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 158))\n",
            "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting tokenizers==0.19.1 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 159))\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting torch==2.3.0 (from -r /content/Multi_Country_GDP_Prediction/requirements.txt (line 160))\n",
            "  Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 0.36.0 Requires-Python >=3.6,<3.10; 0.37.0 Requires-Python >=3.7,<3.10; 0.38.0 Requires-Python >=3.7,<3.11; 0.38.1 Requires-Python >=3.7,<3.11; 0.52.0 Requires-Python >=3.6,<3.9; 0.52.0rc3 Requires-Python >=3.6,<3.9; 0.53.0 Requires-Python >=3.6,<3.10; 0.53.0rc1.post1 Requires-Python >=3.6,<3.10; 0.53.0rc2 Requires-Python >=3.6,<3.10; 0.53.0rc3 Requires-Python >=3.6,<3.10; 0.53.1 Requires-Python >=3.6,<3.10; 0.54.0 Requires-Python >=3.7,<3.10; 0.54.0rc2 Requires-Python >=3.7,<3.10; 0.54.0rc3 Requires-Python >=3.7,<3.10; 0.54.1 Requires-Python >=3.7,<3.10; 0.55.0 Requires-Python >=3.7,<3.11; 0.55.0rc1 Requires-Python >=3.7,<3.11; 0.55.1 Requires-Python >=3.7,<3.11; 0.55.2 Requires-Python >=3.7,<3.11; 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchaudio==2.0.2+cu118 (from versions: 2.0.1, 2.0.2, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchaudio==2.0.2+cu118\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision torchaudio==2.0.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfAI9ysqfn_S",
        "outputId": "953c776b-8bb1-41e8-ee20-8204b2c9a328"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m596.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Multi_Country_GDP_Prediction"
      ],
      "metadata": {
        "id": "c7pUWYmdsKTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf6c3682-4bc3-4c95-a45d-527318fe4f2d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Multi_Country_GDP_Prediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.linear_mlp_quarter\n",
        "# !python -m Multi_Country_GDP_Prediction.scripts.linear_mlp_quarter\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqylRX_zPjLD",
        "outputId": "4760249a-96db-428d-8f01-1900cafb181d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Multi_Country_GDP_Prediction\n",
            "MLP_data_light_sms_q_13-19.pt\n",
            "cost time:  0.13428115844726562\n",
            "MLP_data_q_95-19.pt\n",
            "cost time:  0.02292490005493164\n",
            "MLP_data_light_months_q_13-19.pt\n",
            "cost time:  0.028390169143676758\n",
            "MLP_data_light_mean_q_13-19.pt\n",
            "cost time:  0.028704404830932617\n",
            "MLP_data_q_13-19.pt\n",
            "cost time:  0.02730846405029297\n",
            "                               data  train_mae  train_mse  ...  test_mspe  test_rse  test_corr\n",
            "0     MLP_data_light_sms_q_13-19.pt   0.992814   1.897927  ...   8.503452  0.787327   0.027247\n",
            "1               MLP_data_q_95-19.pt   0.897575   1.490365  ...   0.519753  0.849424   0.033762\n",
            "2  MLP_data_light_months_q_13-19.pt   1.000516   1.920275  ...  14.792241  0.769888   0.027828\n",
            "3    MLP_data_light_mean_q_13-19.pt   0.999351   1.926022  ...  13.229493  0.770982   0.027769\n",
            "4               MLP_data_q_13-19.pt   1.011365   1.932060  ...  96.145195  0.767031   0.028065\n",
            "\n",
            "[5 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.linear_lstm_quarter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioyhLQ5Pkmyq",
        "outputId": "521e31c3-866a-4903-9388-7eb45e0d6c83",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM_data_gdp_more_light_sms_q_t8_13-19.pt\n",
            "cost time:  0.02939605712890625\n",
            "LSTM_data_light_sms_q_t10_13-19.pt\n",
            "cost time:  0.03708767890930176\n",
            "LSTM_data_gdp_q_t8_13-19.pt\n",
            "cost time:  0.017667055130004883\n",
            "LSTM_data_gdp_light_sms_q_t12_13-19.pt\n",
            "cost time:  0.015044689178466797\n",
            "LSTM_data_q_t10_13-19.pt\n",
            "cost time:  0.029384851455688477\n",
            "LSTM_data_gdp_q_t8_95-19.pt\n",
            "cost time:  0.03245711326599121\n",
            "LSTM_data_gdp_light_months_q_t12_13-19.pt\n",
            "cost time:  0.019125938415527344\n",
            "LSTM_data_q_t8_13-19.pt\n",
            "cost time:  0.030218124389648438\n",
            "LSTM_data_gdp_q_t10_13-19.pt\n",
            "cost time:  0.014409780502319336\n",
            "LSTM_data_gdp_more_q_t12_13-19.pt\n",
            "cost time:  0.02617359161376953\n",
            "LSTM_data_gdp_more_light_months_q_t10_13-19.pt\n",
            "cost time:  0.024965524673461914\n",
            "LSTM_data_gdp_more_light_sms_q_t12_13-19.pt\n",
            "cost time:  0.021146535873413086\n",
            "LSTM_data_gdp_more_light_months_q_t12_13-19.pt\n",
            "cost time:  0.02482891082763672\n",
            "LSTM_data_light_sms_q_t12_13-19.pt\n",
            "cost time:  0.04002833366394043\n",
            "LSTM_data_gdp_light_months_q_t8_13-19.pt\n",
            "cost time:  0.020772695541381836\n",
            "LSTM_data_gdp_light_sms_q_t8_13-19.pt\n",
            "cost time:  0.020306110382080078\n",
            "LSTM_data_gdp_more_q_t10_95-19.pt\n",
            "cost time:  0.07238411903381348\n",
            "LSTM_data_gdp_more_light_mean_q_t8_13-19.pt\n",
            "cost time:  0.02661728858947754\n",
            "LSTM_data_gdp_more_q_t8_13-19.pt\n",
            "cost time:  0.024854660034179688\n",
            "LSTM_data_gdp_q_t10_95-19.pt\n",
            "cost time:  0.020208120346069336\n",
            "LSTM_data_gdp_more_light_mean_q_t12_13-19.pt\n",
            "cost time:  0.019814014434814453\n",
            "LSTM_data_gdp_more_light_sms_q_t10_13-19.pt\n",
            "cost time:  0.0281527042388916\n",
            "LSTM_data_gdp_more_q_t12_95-19.pt\n",
            "cost time:  0.039305686950683594\n",
            "LSTM_data_gdp_more_light_months_q_t8_13-19.pt\n",
            "cost time:  0.030285120010375977\n",
            "LSTM_data_light_months_q_t8_13-19.pt\n",
            "cost time:  0.03799772262573242\n",
            "LSTM_data_light_mean_q_t12_13-19.pt\n",
            "cost time:  0.029729366302490234\n",
            "LSTM_data_gdp_more_light_mean_q_t10_13-19.pt\n",
            "cost time:  0.021983861923217773\n",
            "LSTM_data_q_t12_13-19.pt\n",
            "cost time:  0.033624887466430664\n",
            "LSTM_data_gdp_light_mean_q_t12_13-19.pt\n",
            "cost time:  0.01903510093688965\n",
            "LSTM_data_light_sms_q_t8_13-19.pt\n",
            "cost time:  0.11910057067871094\n",
            "LSTM_data_light_months_q_t10_13-19.pt\n",
            "cost time:  0.15208864212036133\n",
            "LSTM_data_light_mean_q_t10_13-19.pt\n",
            "cost time:  0.15189099311828613\n",
            "LSTM_data_gdp_q_t12_13-19.pt\n",
            "cost time:  0.024971961975097656\n",
            "LSTM_data_gdp_light_mean_q_t8_13-19.pt\n",
            "cost time:  0.03409838676452637\n",
            "LSTM_data_gdp_light_mean_q_t10_13-19.pt\n",
            "cost time:  0.047419071197509766\n",
            "LSTM_data_gdp_light_months_q_t10_13-19.pt\n",
            "cost time:  0.01855301856994629\n",
            "LSTM_data_light_months_q_t12_13-19.pt\n",
            "cost time:  0.10381889343261719\n",
            "LSTM_data_gdp_more_q_t10_13-19.pt\n",
            "cost time:  0.022269725799560547\n",
            "LSTM_data_gdp_more_q_t8_95-19.pt\n",
            "cost time:  0.11813092231750488\n",
            "LSTM_data_gdp_q_t12_95-19.pt\n",
            "cost time:  0.05630683898925781\n",
            "LSTM_data_gdp_light_sms_q_t10_13-19.pt\n",
            "cost time:  0.02867913246154785\n",
            "LSTM_data_light_mean_q_t8_13-19.pt\n",
            "cost time:  0.2889885902404785\n",
            "                                              data  train_mae  ...  test_rse  test_corr\n",
            "0       LSTM_data_gdp_more_light_sms_q_t8_13-19.pt   0.599465  ...  0.488616   0.050334\n",
            "1               LSTM_data_light_sms_q_t10_13-19.pt   0.000005  ...  1.023570   0.029056\n",
            "2                      LSTM_data_gdp_q_t8_13-19.pt   0.440863  ...  0.409240   0.037366\n",
            "3           LSTM_data_gdp_light_sms_q_t12_13-19.pt   0.300615  ...  0.539681   0.036018\n",
            "4                         LSTM_data_q_t10_13-19.pt   0.000006  ...  0.950362   0.029840\n",
            "5                      LSTM_data_gdp_q_t8_95-19.pt   0.643525  ...  0.431631   0.052954\n",
            "6        LSTM_data_gdp_light_months_q_t12_13-19.pt   0.313499  ...  0.547943   0.035972\n",
            "7                          LSTM_data_q_t8_13-19.pt   0.123210  ...  0.979801   0.033769\n",
            "8                     LSTM_data_gdp_q_t10_13-19.pt   0.383507  ...  0.394186   0.037628\n",
            "9                LSTM_data_gdp_more_q_t12_13-19.pt   0.585752  ...  0.494139   0.051722\n",
            "10  LSTM_data_gdp_more_light_months_q_t10_13-19.pt   0.545191  ...  0.518186   0.051555\n",
            "11     LSTM_data_gdp_more_light_sms_q_t12_13-19.pt   0.534767  ...  0.583347   0.051107\n",
            "12  LSTM_data_gdp_more_light_months_q_t12_13-19.pt   0.538779  ...  0.546791   0.052109\n",
            "13              LSTM_data_light_sms_q_t12_13-19.pt   0.000002  ...  0.958100   0.028729\n",
            "14        LSTM_data_gdp_light_months_q_t8_13-19.pt   0.420599  ...  0.451707   0.037127\n",
            "15           LSTM_data_gdp_light_sms_q_t8_13-19.pt   0.412457  ...  0.442528   0.036860\n",
            "16               LSTM_data_gdp_more_q_t10_95-19.pt   0.918921  ...  0.479790   0.067329\n",
            "17     LSTM_data_gdp_more_light_mean_q_t8_13-19.pt   0.599836  ...  0.484601   0.050701\n",
            "18                LSTM_data_gdp_more_q_t8_13-19.pt   0.609856  ...  0.464054   0.050578\n",
            "19                    LSTM_data_gdp_q_t10_95-19.pt   0.585186  ...  0.400444   0.052624\n",
            "20    LSTM_data_gdp_more_light_mean_q_t12_13-19.pt   0.561576  ...  0.550268   0.051755\n",
            "21     LSTM_data_gdp_more_light_sms_q_t10_13-19.pt   0.547671  ...  0.534288   0.050912\n",
            "22               LSTM_data_gdp_more_q_t12_95-19.pt   0.916933  ...  0.480757   0.067334\n",
            "23   LSTM_data_gdp_more_light_months_q_t8_13-19.pt   0.597396  ...  0.487672   0.050691\n",
            "24            LSTM_data_light_months_q_t8_13-19.pt   0.073414  ...  0.963424   0.025660\n",
            "25             LSTM_data_light_mean_q_t12_13-19.pt   0.000003  ...  1.080639   0.028698\n",
            "26    LSTM_data_gdp_more_light_mean_q_t10_13-19.pt   0.565325  ...  0.515991   0.051477\n",
            "27                        LSTM_data_q_t12_13-19.pt   0.000002  ...  1.050596   0.028921\n",
            "28         LSTM_data_gdp_light_mean_q_t12_13-19.pt   0.348048  ...  0.522308   0.036121\n",
            "29               LSTM_data_light_sms_q_t8_13-19.pt   0.051237  ...  0.990845   0.025839\n",
            "30           LSTM_data_light_months_q_t10_13-19.pt   0.000006  ...  1.057916   0.032796\n",
            "31             LSTM_data_light_mean_q_t10_13-19.pt   0.000007  ...  1.010223   0.028237\n",
            "32                    LSTM_data_gdp_q_t12_13-19.pt   0.369937  ...  0.437357   0.036189\n",
            "33          LSTM_data_gdp_light_mean_q_t8_13-19.pt   0.434316  ...  0.409644   0.037428\n",
            "34         LSTM_data_gdp_light_mean_q_t10_13-19.pt   0.364929  ...  0.462398   0.037619\n",
            "35       LSTM_data_gdp_light_months_q_t10_13-19.pt   0.338817  ...  0.514140   0.037151\n",
            "36           LSTM_data_light_months_q_t12_13-19.pt   0.000004  ...  0.860074   0.030744\n",
            "37               LSTM_data_gdp_more_q_t10_13-19.pt   0.573211  ...  0.448086   0.051567\n",
            "38                LSTM_data_gdp_more_q_t8_95-19.pt   0.975825  ...  0.529513   0.065845\n",
            "39                    LSTM_data_gdp_q_t12_95-19.pt   0.577053  ...  0.410118   0.051988\n",
            "40          LSTM_data_gdp_light_sms_q_t10_13-19.pt   0.333463  ...  0.508377   0.036848\n",
            "41              LSTM_data_light_mean_q_t8_13-19.pt   0.094623  ...  0.971553   0.029204\n",
            "\n",
            "[42 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.linear_mlp_year"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sInOf6fFoT__",
        "outputId": "41a4092f-000b-429e-d40e-2663a22cdeb4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP_data_y_80-19.pt\n",
            "cost time:  0.018796443939208984\n",
            "MLP_data_light_months_y_13-19.pt\n",
            "cost time:  0.005925655364990234\n",
            "MLP_data_y_13-19.pt\n",
            "cost time:  0.005396604537963867\n",
            "MLP_data_light_sms_y_13-19.pt\n",
            "cost time:  0.005670070648193359\n",
            "MLP_data_y_80-07.pt\n",
            "cost time:  0.009649991989135742\n",
            "MLP_data_light_mean_y_13-19.pt\n",
            "cost time:  0.006495475769042969\n",
            "                               data  train_mae  train_mse  ...  test_mspe  test_rse  test_corr\n",
            "0               MLP_data_y_80-19.pt   0.720665   1.086349  ...   2.738609  0.363372   0.028275\n",
            "1  MLP_data_light_months_y_13-19.pt   0.485427   0.408693  ...   0.499493  0.344191   0.022700\n",
            "2               MLP_data_y_13-19.pt   0.537904   0.557611  ...  33.316257  0.360310   0.022742\n",
            "3     MLP_data_light_sms_y_13-19.pt   0.495155   0.488961  ...   0.271816  0.292129   0.023153\n",
            "4               MLP_data_y_80-07.pt   0.724248   0.999173  ...   0.070267  0.597057   0.029627\n",
            "5    MLP_data_light_mean_y_13-19.pt   0.536801   0.554186  ...   9.610674  0.342089   0.022934\n",
            "\n",
            "[6 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from utils.metrics import metric\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import itertools\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "torch.backends.cudnn.deterministic = False\n",
        "torch.backends.cudnn.benchmark = True\n",
        "folder_path=\"/content/Multi_Country_GDP_Prediction/checkpoint_lstm\"\n",
        "if not os.path.exists(folder_path):\n",
        "  os.makedirs(folder_path)\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "# 计算最小值和最大值, 并进行归一化\n",
        "def norm_lstm_tensor(data, labels, freq='quarter'):\n",
        "    if freq == 'quarter':\n",
        "        drop_index = -3\n",
        "    else:\n",
        "        drop_index = -2\n",
        "\n",
        "    # 将最后一维的数据分开\n",
        "    data_to_norm = data[:, :, :drop_index]  # 除了最后一个维度\n",
        "    labels_to_norm = labels[:, :drop_index]  # 除了最后一个维度\n",
        "\n",
        "    # 计算data的最小值和最大值\n",
        "    max_vals_data, _ = torch.max(data_to_norm, dim=0)  # 对第一个维度求最大值\n",
        "    max_vals_data, _ = torch.max(max_vals_data, dim=0)  # 再对第二个维度求最大值\n",
        "\n",
        "    min_vals_data, _ = torch.min(data_to_norm, dim=0)  # 对第一个维度求最小值\n",
        "    min_vals_data, _ = torch.min(min_vals_data, dim=0)  # 再对第二个维度求最小值\n",
        "\n",
        "    # 计算labels的最小值和最大值\n",
        "    min_vals_label = labels_to_norm.min(dim=0, keepdim=True).values[-1]\n",
        "    max_vals_label = labels_to_norm.max(dim=0, keepdim=True).values[-1]\n",
        "\n",
        "    min_value_all = torch.min(min_vals_data, min_vals_label)\n",
        "    max_value_all = torch.max(max_vals_data, max_vals_label)\n",
        "\n",
        "    min_value = min_value_all[-1]\n",
        "    max_value = max_value_all[-1]\n",
        "\n",
        "    # 计算 Min-Max 归一化\n",
        "    # 对 data (去除最后一个维度的部分) 进行 Min-Max 归一化\n",
        "    normalized_data_to_norm = (data_to_norm - min_value_all) / (max_value_all - min_value_all)\n",
        "\n",
        "    # 对 label (去除最后一个维度的部分) 进行 Min-Max 归一化\n",
        "    normalized_labels_to_norm = (labels_to_norm - min_value_all) / (max_value_all - min_value_all)\n",
        "\n",
        "    # cat the last dim\n",
        "    normalized_data = torch.cat([normalized_data_to_norm, data[:, :, drop_index:]], dim=2)\n",
        "    normalized_label = torch.cat([normalized_labels_to_norm, labels[:, drop_index:]], dim=1)\n",
        "\n",
        "    return normalized_data, normalized_label, min_value, max_value\n",
        "\n",
        "\n",
        "def split_lstm_dataset_by_year(data, labels, year, freq='quarter'):\n",
        "    if freq == 'quarter':\n",
        "        dim_index = -2\n",
        "    else:\n",
        "        dim_index = -1\n",
        "\n",
        "    train_index_list = []\n",
        "    test_index_list = []\n",
        "    for i in range(len(labels)):\n",
        "        if labels[i, dim_index] >= year:\n",
        "            test_index_list.append(i)\n",
        "        else:\n",
        "            train_index_list.append(i)\n",
        "\n",
        "\n",
        "    train_data = data[train_index_list, :, :dim_index-1]\n",
        "    train_targets = labels[train_index_list, :dim_index-1]\n",
        "\n",
        "    test_data = data[test_index_list, :, :dim_index-1]\n",
        "    test_targets = labels[test_index_list, :dim_index-1]\n",
        "    return train_data, test_data, train_targets, test_targets\n",
        "\n",
        "\n",
        "def reverse_norm(row):\n",
        "    # row = row.cpu()\n",
        "    if len(row.shape) == 2:\n",
        "        gap = max_value.item() - min_value.item()\n",
        "        return row[:, -1] * gap + min_value.item()\n",
        "    else:\n",
        "        gap = max_value.item() - min_value.item()\n",
        "        return row * gap + min_value.item()\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout_rate):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_rate)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # initial hidden and cell\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
        "\n",
        "        # Forward LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_dim)\n",
        "\n",
        "        # Decode the last time step of the hidden state\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "\n",
        "# no train loss\n",
        "import time\n",
        "def no_train_loss(model, train_loader, criterion, weight, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_gdp_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_data, batch_labels in train_loader:\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "\n",
        "            # Forward\n",
        "            outputs = model(batch_data)\n",
        "\n",
        "            loss = criterion(outputs, batch_labels, weight)\n",
        "\n",
        "            gdp_loss = criterion(reverse_norm(outputs),\n",
        "                                 reverse_norm(batch_labels),\n",
        "                                 weight)\n",
        "\n",
        "            total_loss += loss.item() * batch_data.size(0)\n",
        "            total_gdp_loss += gdp_loss.item() * batch_data.size(0)\n",
        "\n",
        "    total_loss = total_loss/len(train_loader.dataset)\n",
        "    total_gdp_loss = total_gdp_loss/len(train_loader.dataset)\n",
        "    return total_loss, total_gdp_loss\n",
        "\n",
        "\n",
        "def loss_weight(outputs, targets, weight):\n",
        "    # print(outputs.shape)\n",
        "    if len(outputs.shape) != 1:\n",
        "        criterion_ = nn.MSELoss(reduction='none')\n",
        "\n",
        "        weights = torch.tensor([1.0] * outputs.shape[-1])\n",
        "        weights[-1] = weight\n",
        "        weights = weights.to(device)\n",
        "\n",
        "        # Compute the element-wise MSE loss\n",
        "        loss_temp = criterion_(outputs, targets)\n",
        "\n",
        "        # Apply the weights\n",
        "        weighted_loss = loss_temp * weights\n",
        "\n",
        "        # Reduce the weighted loss (e.g., take the mean or sum)\n",
        "        loss = weighted_loss.mean()  # or .sum()\n",
        "\n",
        "    elif len(outputs.shape) == 1:  # GDP use MSE\n",
        "        criterion_ = nn.MSELoss()\n",
        "        loss = criterion_(outputs, targets)\n",
        "    else:\n",
        "        raise ValueError(\"output shape Value Wrong!\")\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "# train and eval\n",
        "def train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, num_epochs, weight, device):\n",
        "    best_model_wts = None\n",
        "    best_val_gdp_loss = float('inf')\n",
        "    best_epoch = 0  # for save best epoch\n",
        "\n",
        "\n",
        "    no_train_loss_res, no_train_gdp_loss_res = no_train_loss(model, train_loader, criterion, weight, device)\n",
        "    print('initial train loss: ', no_train_loss_res, 'initial gdp train loss: ', no_train_gdp_loss_res)\n",
        "\n",
        "    no_train_loss_res, no_train_gdp_loss_res = no_train_loss(model, val_loader, criterion, weight, device)\n",
        "    print('initial val loss: ', no_train_loss_res, 'initial gdp val loss: ', no_train_gdp_loss_res)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # 训练阶段\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_gdp_loss = 0.0\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets, weight)\n",
        "\n",
        "            gdp_loss = criterion(reverse_norm(outputs),\n",
        "                                 reverse_norm(targets),\n",
        "                                 weight)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_gdp_loss += gdp_loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_train_gdp_loss = running_gdp_loss / len(train_loader.dataset)\n",
        "\n",
        "        # 验证阶段\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        running_val_gdp_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                loss = criterion(outputs, targets, weight)\n",
        "                gdp_loss = criterion(reverse_norm(outputs),\n",
        "                                     reverse_norm(targets),\n",
        "                                     weight)\n",
        "\n",
        "                running_val_loss += loss.item() * inputs.size(0)\n",
        "                running_val_gdp_loss += gdp_loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
        "        epoch_val_gdp_loss = running_val_gdp_loss / len(val_loader.dataset)\n",
        "\n",
        "        # 如果当前验证损失小于最佳损失，则更新最佳模型权重和最佳 epoch\n",
        "        if epoch_val_gdp_loss < best_val_gdp_loss:\n",
        "            best_val_gdp_loss = epoch_val_gdp_loss\n",
        "            best_model_wts = model.state_dict()\n",
        "            best_epoch = epoch + 1  # 保存最佳 epoch（从 1 开始）\n",
        "\n",
        "    # 返回最佳模型权重、最佳验证损失和最佳 epoch\n",
        "    return best_model_wts, best_val_gdp_loss, best_epoch\n",
        "\n",
        "\n",
        "# 主函数，执行超参数搜索和交叉验证\n",
        "def hyperparameter_search(X, y, param_grid, k_folds=5, device='cpu'):\n",
        "    # 将数据转换为TensorDataset\n",
        "    print(\"device:\",device)\n",
        "    dataset = TensorDataset(torch.tensor(X, dtype=torch.float32).to(device),\n",
        "                            torch.tensor(y, dtype=torch.float32).to(device))\n",
        "\n",
        "    # 创建超参数组合\n",
        "    param_combinations = list(itertools.product(*param_grid.values()))\n",
        "    param_names = list(param_grid.keys())\n",
        "\n",
        "    best_overall_loss = float('inf')\n",
        "    best_params = None\n",
        "    best_model_wts = None\n",
        "\n",
        "    # 遍历每个超参数组合\n",
        "    for param_values in tqdm(param_combinations, desc=\"Hyperparameter Search\"):\n",
        "        params = dict(zip(param_names, param_values))\n",
        "        print(f\"\\nEvaluating parameters: {params}\")\n",
        "\n",
        "        # 存储每个折的验证损失\n",
        "        val_losses = []\n",
        "\n",
        "        # 创建KFold对象\n",
        "        kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "        # 遍历每个折，记录每个折里最优的折和epoch\n",
        "        record_best_val_gdp_loss = float('inf')\n",
        "        record_best_epoch = 0\n",
        "        record_best_fold = 0\n",
        "        for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
        "            print(f\"Fold {fold + 1}/{k_folds}\")\n",
        "\n",
        "            # 创建数据加载器\n",
        "            train_subset = Subset(dataset, train_idx)\n",
        "            val_subset = Subset(dataset, val_idx)\n",
        "            train_loader = DataLoader(train_subset, batch_size=params['batch_size'], shuffle=True)\n",
        "            val_loader = DataLoader(val_subset, batch_size=params['batch_size'], shuffle=False)\n",
        "\n",
        "            # 初始化模型、损失函数和优化器\n",
        "            model = LSTMModel(input_dim=X.shape[-1],\n",
        "                              hidden_dim=params['hidden_dim'],\n",
        "                              num_layers=params['num_layers'],\n",
        "                              output_dim=X.shape[-1],\n",
        "                              dropout_rate=params['dropout_rate']).to(device)\n",
        "            criterion = loss_weight.to(device) if isinstance(loss_weight, torch.Tensor) else loss_weight\n",
        "            optimizer = optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
        "\n",
        "            # 训练和验证\n",
        "            best_model_wts, best_val_gdp_loss, best_epoch = train_and_evaluate(model, train_loader, val_loader,\n",
        "                                                               criterion, optimizer, params['num_epochs'],\n",
        "                                                                               params['weight'], device)\n",
        "            print(f\"Best Validation GDP Loss for fold {fold + 1}: {best_val_gdp_loss:.4f}\")\n",
        "            print(f\"Best best_epoch {best_epoch}\")\n",
        "            val_losses.append(best_val_gdp_loss)\n",
        "\n",
        "            if best_val_gdp_loss < record_best_val_gdp_loss:\n",
        "                record_best_val_gdp_loss = best_val_gdp_loss\n",
        "                record_best_epoch = best_epoch\n",
        "                record_best_fold = fold + 1\n",
        "                best_valid_model = model\n",
        "\n",
        "\n",
        "        # 计算当前超参数组合的平均验证损失\n",
        "        avg_val_loss = np.mean(val_losses)\n",
        "        print(f\"Average Validation Loss for parameters {params}: {avg_val_loss:.4f}\")\n",
        "\n",
        "\n",
        "        # 如果当前平均验证损失小于整体最佳损失，则更新最佳参数和模型权重\n",
        "        if avg_val_loss < best_overall_loss:\n",
        "            best_overall_loss = avg_val_loss\n",
        "            best_params = params\n",
        "            best_params['record_best_epoch'] = record_best_epoch\n",
        "            best_params['record_best_val_gdp_loss'] = record_best_val_gdp_loss\n",
        "            best_params['record_best_fold'] = record_best_fold\n",
        "            model_save_path = folder_path  + file_item.replace('.pt', '_') + 'lstm_best_valid_model.pth'\n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "            print(f\"\\nBest valid model saved to {model_save_path}\")\n",
        "\n",
        "    print(f\"\\nBest Hyperparameters: {best_params}\")\n",
        "    print(f\"Best Average Validation Loss: {best_overall_loss:.4f}\")\n",
        "    return best_params, best_overall_loss\n",
        "\n",
        "\n",
        "# 使用最佳超参数在整个训练数据集上训练最终模型，并计算在测试集的performance\n",
        "def train_and_evaluate_final(train_data, test_data, train_targets, test_targets,\n",
        "                             best_params, device='cpu'):\n",
        "\n",
        "    # 创建TensorDataset和DataLoader\n",
        "    train_dataset = TensorDataset(train_data, train_targets)\n",
        "    test_dataset = TensorDataset(test_data, test_targets)\n",
        "    train_dataloader = DataLoader(train_dataset,\n",
        "                                  batch_size=best_params['batch_size'], shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset,\n",
        "                                 batch_size=best_params['batch_size'], shuffle=False)\n",
        "\n",
        "    final_model = LSTMModel(input_dim=train_data.shape[-1],\n",
        "                            hidden_dim=best_params['hidden_dim'],\n",
        "                            num_layers=best_params['num_layers'],\n",
        "                            output_dim=train_data.shape[-1],\n",
        "                            dropout_rate=best_params['dropout_rate']).to(device)\n",
        "    final_criterion = loss_weight\n",
        "    final_optimizer = optim.AdamW(final_model.parameters(), lr=best_params['lr'],\n",
        "                                  weight_decay=best_params['weight_decay'])\n",
        "\n",
        "    weight = best_params['weight']\n",
        "\n",
        "    no_train_loss_res, no_train_gdp_loss_res = no_train_loss(final_model, train_dataloader, final_criterion, weight, device)\n",
        "    print('initial train loss: ', no_train_loss_res, 'initial gdp train loss: ', no_train_gdp_loss_res)\n",
        "\n",
        "    no_train_loss_res, no_train_gdp_loss_res = no_train_loss(final_model, test_dataloader, final_criterion, weight, device)\n",
        "    print('initial val loss: ', no_train_loss_res, 'initial gdp val loss: ', no_train_gdp_loss_res)\n",
        "\n",
        "\n",
        "    # 训练最终模型\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_gdp_losses = []\n",
        "    test_gdp_losses = []\n",
        "    num_epochs = best_params['record_best_epoch']\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        total_gdp_loss = 0\n",
        "        for batch_data, batch_labels in train_dataloader:\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "\n",
        "            # 前向传播\n",
        "            final_model.train()\n",
        "            outputs = final_model(batch_data)\n",
        "\n",
        "            loss = final_criterion(outputs, batch_labels, weight)\n",
        "\n",
        "            gdp_loss = final_criterion(reverse_norm(outputs),\n",
        "                                       reverse_norm(batch_labels),\n",
        "                                       weight)\n",
        "            # 反向传播和优化\n",
        "            final_optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            final_optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * batch_data.size(0)\n",
        "            total_gdp_loss += gdp_loss.item() * batch_data.size(0)\n",
        "\n",
        "        train_loss = total_loss/len(train_dataloader.dataset)\n",
        "        train_gdp_loss = total_gdp_loss/len(train_dataloader.dataset)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_gdp_losses.append(train_gdp_loss)\n",
        "\n",
        "\n",
        "        preds = []\n",
        "        trues = []\n",
        "        # 评估模型\n",
        "        final_model.eval()\n",
        "        with torch.no_grad():\n",
        "            test_loss = 0\n",
        "            test_gdp_loss = 0\n",
        "            for batch_data, batch_targets in test_dataloader:\n",
        "\n",
        "                batch_data = batch_data.to(device)\n",
        "                batch_targets = batch_targets.to(device)\n",
        "\n",
        "                outputs = final_model(batch_data)\n",
        "\n",
        "                loss = final_criterion(outputs, batch_targets, weight)\n",
        "\n",
        "                gdp_loss = final_criterion(reverse_norm(outputs),\n",
        "                                           reverse_norm(batch_targets),\n",
        "                                           weight)\n",
        "\n",
        "                test_loss += loss.item() * batch_data.size(0)\n",
        "                test_gdp_loss += gdp_loss.item() * batch_data.size(0)\n",
        "\n",
        "\n",
        "                outputs = reverse_norm(outputs)\n",
        "                batch_targets = reverse_norm(batch_targets)\n",
        "\n",
        "                for item in outputs:\n",
        "                    preds.append(item.item())\n",
        "                for item in batch_targets:\n",
        "                    trues.append(item.item())\n",
        "\n",
        "            test_loss = test_loss / len(test_dataloader.dataset)\n",
        "            test_gdp_loss = test_gdp_loss / len(test_dataloader.dataset)\n",
        "\n",
        "            test_losses.append(test_loss)\n",
        "            test_gdp_losses.append(test_gdp_loss)\n",
        "\n",
        "        preds = torch.Tensor(np.array(preds))\n",
        "        trues = torch.Tensor(np.array(trues))\n",
        "\n",
        "        mae, mse, rmse, mape, mspe, rse, corr = metric(preds, trues)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, GDP Train Loss: {train_gdp_loss:.4f}, GDP Test Loss: {test_gdp_loss:.4f}\")\n",
        "    print('mae, mse, rmse, mape: ', mae, mse, rmse, mape)\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    # # 保存最终模型\n",
        "    model_save_path = folder_path  + file_item.replace('.pt', '_') + 'lstm_best_final_model.pth'\n",
        "    torch.save(final_model.state_dict(), model_save_path)\n",
        "    print(f\"\\nFinal model saved to {model_save_path}\")\n",
        "\n",
        "    best_params['final model mae'] = mae\n",
        "    best_params['final model mse'] = mse\n",
        "    best_params['final model rmse'] = rmse\n",
        "    best_params['final model mape'] = mape\n",
        "    return best_params\n",
        "\n",
        "\n",
        "# 使用checkpoint在测试集上测试\n",
        "def eval_model(test_data, test_targets, model_path, best_params, device='cpu'):\n",
        "    test_dataset = TensorDataset(test_data, test_targets)\n",
        "    test_dataloader = DataLoader(test_dataset,\n",
        "                                 batch_size=best_params['batch_size'], shuffle=False)\n",
        "\n",
        "    final_model = LSTMModel(input_dim=test_data.shape[-1],\n",
        "                            hidden_dim=best_params['hidden_dim'],\n",
        "                            num_layers=best_params['num_layers'],\n",
        "                            output_dim=test_data.shape[-1],\n",
        "                            dropout_rate=best_params['dropout_rate']).to(device)\n",
        "    final_criterion = loss_weight\n",
        "    final_optimizer = optim.AdamW(final_model.parameters(), lr=best_params['lr'],\n",
        "                                  weight_decay=best_params['weight_decay'])\n",
        "    # 3. 加载模型权重\n",
        "    final_model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "    # 4. 设置模型为评估模式\n",
        "    test_losses = []\n",
        "    test_gdp_losses = []\n",
        "    preds = []\n",
        "    trues = []\n",
        "    weight = best_params['weight']\n",
        "    # 评估模型\n",
        "    final_model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_loss = 0\n",
        "        test_gdp_loss = 0\n",
        "        for batch_data, batch_targets in test_dataloader:\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_targets = batch_targets.to(device)\n",
        "\n",
        "            outputs = final_model(batch_data)\n",
        "            loss = final_criterion(outputs, batch_targets, weight)\n",
        "\n",
        "            gdp_loss = final_criterion(reverse_norm(outputs),\n",
        "                                       reverse_norm(batch_targets),\n",
        "                                       weight)\n",
        "\n",
        "            test_loss += loss.item() * batch_data.size(0)\n",
        "            test_gdp_loss += gdp_loss.item() * batch_data.size(0)\n",
        "\n",
        "            outputs = reverse_norm(outputs)\n",
        "            batch_targets = reverse_norm(batch_targets)\n",
        "\n",
        "            for item in outputs:\n",
        "                preds.append(item.detach().cpu().numpy())\n",
        "\n",
        "            for item in batch_targets:\n",
        "                trues.append(item.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "        test_loss = test_loss / len(test_dataloader.dataset)\n",
        "        test_gdp_loss = test_gdp_loss / len(test_dataloader.dataset)\n",
        "\n",
        "        test_losses.append(test_loss)\n",
        "        test_gdp_losses.append(test_gdp_loss)\n",
        "\n",
        "\n",
        "    preds = torch.Tensor(np.array(preds))\n",
        "    trues = torch.Tensor(np.array(trues))\n",
        "\n",
        "    mae, mse, rmse, mape, mspe, rse, corr = metric(preds, trues)\n",
        "\n",
        "    print(f\"Test Loss: {test_loss:.4f}, GDP Test Loss: {test_gdp_loss:.4f}\")\n",
        "    print('mae, mse, rmse, mape: ', mae, mse, rmse, mape)\n",
        "\n",
        "    best_params['best val model mae'] = mae\n",
        "    best_params['best val model mse'] = mse\n",
        "    best_params['best val model rmse'] = rmse\n",
        "    best_params['best val model mape'] = mape\n",
        "    return best_params\n",
        "\n",
        "\n",
        "file_item_list = []\n",
        "for file_item in os.listdir('/content/Multi_Country_GDP_Prediction/dataset'):\n",
        "    if ('LSTM_data_' in file_item) and ('95-19' in file_item):\n",
        "        file_item_list.append(file_item)\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "print('file item list length: ', len(file_item_list))\n",
        "\n",
        "\n",
        "# select device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "for file_item in tqdm(file_item_list[:]):\n",
        "    print(file_item)\n",
        "    start_time = time.time()\n",
        "    data_path = '/content/Multi_Country_GDP_Prediction/dataset/' + file_item\n",
        "    label_path = '/content/Multi_Country_GDP_Prediction/dataset/' + file_item.replace('LSTM_data', 'LSTM_label')\n",
        "\n",
        "\n",
        "    set_seed(1)\n",
        "    data = torch.load(data_path)\n",
        "    labels = torch.load(label_path)\n",
        "\n",
        "    data, labels, min_value, max_value = norm_lstm_tensor(data, labels, 'quarter')\n",
        "\n",
        "    # 13-19 use 2019 as test dataset, other use 2018-2019 as test dataset\n",
        "    if '13-19' in file_item:\n",
        "        year = 2019\n",
        "    else:\n",
        "        year = 2018\n",
        "\n",
        "    train_data, test_data, train_targets, test_targets = split_lstm_dataset_by_year(data, labels, year, freq='quarter')\n",
        "\n",
        "\n",
        "    set_seed(1)\n",
        "\n",
        "    # 定义超参数网格\n",
        "    param_grid = {\n",
        "        'hidden_dim': [512, 1024],\n",
        "        'num_layers': [1, 2],\n",
        "        'dropout_rate': [0.1],\n",
        "        'lr': [0.001, 0.0001],\n",
        "        'batch_size': [64,128],\n",
        "        'num_epochs': [100],\n",
        "        'weight': [20, 60],\n",
        "        'weight_decay': [0.01]\n",
        "    }\n",
        "\n",
        "\n",
        "    # 执行超参数搜索\n",
        "    best_params, best_overall_loss = hyperparameter_search(train_data, train_targets, param_grid, k_folds=5, device=device)\n",
        "\n",
        "    best_params['best_overall_loss_average'] = best_overall_loss\n",
        "\n",
        "    set_seed(1)\n",
        "    best_params = train_and_evaluate_final(train_data, test_data, train_targets, test_targets,\n",
        "                             best_params, device)\n",
        "\n",
        "\n",
        "    model_path = folder_path + file_item.replace('.pt', '_') + 'lstm_best_valid_model.pth'\n",
        "    best_params = eval_model(test_data, test_targets, model_path, best_params, device)\n",
        "    best_params['train_data shape'] = ', '.join([str(x) for x in train_data.shape])\n",
        "    best_params['test_data shape'] = ', '.join([str(x) for x in test_data.shape])\n",
        "    best_params['train_targets shape'] = ', '.join([str(x) for x in train_targets.shape])\n",
        "    best_params['test_targets shape'] = ', '.join([str(x) for x in test_targets.shape])\n",
        "    pd.DataFrame([best_params]).to_csv(folder_path + file_item.replace('.pt', '_') + 'best_params_res.csv')\n",
        "    print('cost time: ', time.time() - start_time)\n",
        "    print('\\n===================Next=====================')\n",
        "\n",
        "print('Done!')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWewwDaIVZEI",
        "outputId": "b2c628df-11e8-48da-df44-fa41c9c48657"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "file item list length:  6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/6 [00:00<?, ?it/s]<ipython-input-10-b1d027f06370>:258: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  dataset = TensorDataset(torch.tensor(X, dtype=torch.float32).to(device),\n",
            "<ipython-input-10-b1d027f06370>:259: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(y, dtype=torch.float32).to(device))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM_data_gdp_q_t8_95-19.pt\n",
            "device: cuda\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.129329778175273 initial gdp train loss:  95.98164516069924\n",
            "initial val loss:  7.501234471297064 initial gdp val loss:  100.98857655244716\n",
            "Best Validation GDP Loss for fold 1: 0.8733\n",
            "Best best_epoch 90\n",
            "Fold 2/5\n",
            "initial train loss:  7.515637209249097 initial gdp train loss:  101.18247969710046\n",
            "initial val loss:  7.813959634604574 initial gdp val loss:  105.1987724624762\n",
            "Best Validation GDP Loss for fold 2: 1.0256\n",
            "Best best_epoch 98\n",
            "Fold 3/5\n",
            "initial train loss:  5.955274622148602 initial gdp train loss:  80.17543277659999\n",
            "initial val loss:  5.886348756693177 initial gdp val loss:  79.2474850153519\n",
            "Best Validation GDP Loss for fold 3: 0.9349\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  6.863714743264114 initial gdp train loss:  92.40569488911689\n",
            "initial val loss:  6.260799795894299 initial gdp val loss:  84.28869292695643\n",
            "Best Validation GDP Loss for fold 4: 1.0686\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  6.225400425713777 initial gdp train loss:  83.81211891657189\n",
            "initial val loss:  6.262762991048522 initial gdp val loss:  84.31513265836037\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:   3%|▎         | 1/32 [00:16<08:28, 16.39s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.7863\n",
            "Best best_epoch 73\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 0.9377\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t8_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  18.05103497575756 initial gdp train loss:  81.00658976452043\n",
            "initial val loss:  19.092553627591172 initial gdp val loss:  85.68055455824909\n",
            "Best Validation GDP Loss for fold 1: 0.8075\n",
            "Best best_epoch 96\n",
            "Fold 2/5\n",
            "initial train loss:  17.60341112407015 initial gdp train loss:  78.99781618662666\n",
            "initial val loss:  18.35447383527996 initial gdp val loss:  82.3683090209961\n",
            "Best Validation GDP Loss for fold 2: 1.0077\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  23.68527084060862 initial gdp train loss:  106.29102676327219\n",
            "initial val loss:  23.49062583406093 initial gdp val loss:  105.41752883135263\n",
            "Best Validation GDP Loss for fold 3: 0.9110\n",
            "Best best_epoch 97\n",
            "Fold 4/5\n",
            "initial train loss:  21.67055722329184 initial gdp train loss:  97.24971439667392\n",
            "initial val loss:  19.801563683202712 initial gdp val loss:  88.86233908443127\n",
            "Best Validation GDP Loss for fold 4: 1.1027\n",
            "Best best_epoch 91\n",
            "Fold 5/5\n",
            "initial train loss:  17.128140461595752 initial gdp train loss:  76.86496937425831\n",
            "initial val loss:  17.224543652292024 initial gdp val loss:  77.297583628509\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:   6%|▋         | 2/32 [00:31<07:56, 15.88s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.7980\n",
            "Best best_epoch 93\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 0.9254\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t8_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.546408571602174 initial gdp train loss:  101.59675390070134\n",
            "initial val loss:  7.925256729125977 initial gdp val loss:  106.69715881347656\n",
            "Best Validation GDP Loss for fold 1: 1.1414\n",
            "Best best_epoch 98\n",
            "Fold 2/5\n",
            "initial train loss:  6.444267699380758 initial gdp train loss:  86.75870834898998\n",
            "initial val loss:  6.71126651763916 initial gdp val loss:  90.35328674316406\n",
            "Best Validation GDP Loss for fold 2: 1.3812\n",
            "Best best_epoch 95\n",
            "Fold 3/5\n",
            "initial train loss:  7.438608612189313 initial gdp train loss:  100.14544700268452\n",
            "initial val loss:  7.373302936553955 initial gdp val loss:  99.2662353515625\n",
            "Best Validation GDP Loss for fold 3: 1.0314\n",
            "Best best_epoch 90\n",
            "Fold 4/5\n",
            "initial train loss:  6.8983718393221185 initial gdp train loss:  92.87227649930158\n",
            "initial val loss:  6.2948431968688965 initial gdp val loss:  84.74700927734375\n",
            "Best Validation GDP Loss for fold 4: 1.3818\n",
            "Best best_epoch 92\n",
            "Fold 5/5\n",
            "initial train loss:  6.752023447414993 initial gdp train loss:  90.9020005238207\n",
            "initial val loss:  6.79002571105957 initial gdp val loss:  91.41362762451172\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:   9%|▉         | 3/32 [00:42<06:30, 13.48s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.8396\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 1.1551\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  21.020437768851476 initial gdp train loss:  94.3322103552788\n",
            "initial val loss:  22.125308990478516 initial gdp val loss:  99.29047393798828\n",
            "Best Validation GDP Loss for fold 1: 1.1173\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  19.688609476069317 initial gdp train loss:  88.35544436174517\n",
            "initial val loss:  20.502079010009766 initial gdp val loss:  92.0060043334961\n",
            "Best Validation GDP Loss for fold 2: 1.4030\n",
            "Best best_epoch 98\n",
            "Fold 3/5\n",
            "initial train loss:  22.82746211184731 initial gdp train loss:  102.44148347749992\n",
            "initial val loss:  22.624065399169922 initial gdp val loss:  101.52870178222656\n",
            "Best Validation GDP Loss for fold 3: 1.0020\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  25.49551707078636 initial gdp train loss:  114.41476710838607\n",
            "initial val loss:  23.43189239501953 initial gdp val loss:  105.15396118164062\n",
            "Best Validation GDP Loss for fold 4: 1.3629\n",
            "Best best_epoch 98\n",
            "Fold 5/5\n",
            "initial train loss:  22.780078976466182 initial gdp train loss:  102.22884822797171\n",
            "initial val loss:  22.90437126159668 initial gdp val loss:  102.78662109375\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:  12%|█▎        | 4/32 [00:53<05:46, 12.37s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.8692\n",
            "Best best_epoch 98\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 1.1509\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.0287052279546955 initial gdp train loss:  94.62694986678078\n",
            "initial val loss:  7.398609738389985 initial gdp val loss:  99.60695186582934\n",
            "Best Validation GDP Loss for fold 1: 3.8395\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  6.544489401843533 initial gdp train loss:  88.10798320810588\n",
            "initial val loss:  6.814172103625386 initial gdp val loss:  91.73870823964351\n",
            "Best Validation GDP Loss for fold 2: 3.6298\n",
            "Best best_epoch 98\n",
            "Fold 3/5\n",
            "initial train loss:  7.254318629639058 initial gdp train loss:  97.66436410252052\n",
            "initial val loss:  7.1894173702951205 initial gdp val loss:  96.7906101032839\n",
            "Best Validation GDP Loss for fold 3: 3.0947\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  7.031071600531727 initial gdp train loss:  94.65880851906563\n",
            "initial val loss:  6.419254109010858 initial gdp val loss:  86.42195297499835\n",
            "Best Validation GDP Loss for fold 4: 4.1389\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  6.48314009235881 initial gdp train loss:  87.28204799603812\n",
            "initial val loss:  6.518229710853706 initial gdp val loss:  87.7544612561242\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:  16%|█▌        | 5/32 [01:09<06:08, 13.66s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 3.1423\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 3.5690\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  23.70656562305152 initial gdp train loss:  106.3865922601228\n",
            "initial val loss:  24.87750593554072 initial gdp val loss:  111.64134876667953\n",
            "Best Validation GDP Loss for fold 1: 4.0283\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  22.29477091621899 initial gdp train loss:  100.05096329090208\n",
            "initial val loss:  23.178296594058764 initial gdp val loss:  104.01590286383107\n",
            "Best Validation GDP Loss for fold 2: 3.6217\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  19.948795455417553 initial gdp train loss:  89.52305970010879\n",
            "initial val loss:  19.746674909430034 initial gdp val loss:  88.6160275734077\n",
            "Best Validation GDP Loss for fold 3: 3.1648\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  21.611400829588813 initial gdp train loss:  96.98423911951765\n",
            "initial val loss:  19.760305275351314 initial gdp val loss:  88.67718867932336\n",
            "Best Validation GDP Loss for fold 4: 4.0054\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  19.941745629290487 initial gdp train loss:  89.4914244961638\n",
            "initial val loss:  20.05517878774869 initial gdp val loss:  90.00047108278436\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:  19%|█▉        | 6/32 [01:24<06:12, 14.31s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 3.2433\n",
            "Best best_epoch 98\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 3.6127\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.750777071172541 initial gdp train loss:  90.88522461453654\n",
            "initial val loss:  7.116534233093262 initial gdp val loss:  95.80938720703125\n",
            "Best Validation GDP Loss for fold 1: 4.9772\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  7.460111982978676 initial gdp train loss:  100.43495047571291\n",
            "initial val loss:  7.754864692687988 initial gdp val loss:  104.4031753540039\n",
            "Best Validation GDP Loss for fold 2: 4.3811\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  6.2657633370990995 initial gdp train loss:  84.35551916194868\n",
            "initial val loss:  6.197093963623047 initial gdp val loss:  83.4310302734375\n",
            "Best Validation GDP Loss for fold 3: 4.0113\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  6.111726937917718 initial gdp train loss:  82.28173119911162\n",
            "initial val loss:  5.546961784362793 initial gdp val loss:  74.6783447265625\n",
            "Best Validation GDP Loss for fold 4: 5.0896\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  7.023668244921206 initial gdp train loss:  94.55913820548399\n",
            "initial val loss:  7.060800552368164 initial gdp val loss:  95.05904388427734\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:  22%|██▏       | 7/32 [01:36<05:35, 13.43s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 4.2922\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 4.5503\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  19.87256861438711 initial gdp train loss:  89.1809836744506\n",
            "initial val loss:  20.942852020263672 initial gdp val loss:  93.9840316772461\n",
            "Best Validation GDP Loss for fold 1: 4.9389\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  18.69517636853595 initial gdp train loss:  83.89726902516145\n",
            "initial val loss:  19.475534439086914 initial gdp val loss:  87.39923095703125\n",
            "Best Validation GDP Loss for fold 2: 4.2855\n",
            "Best best_epoch 93\n",
            "Fold 3/5\n",
            "initial train loss:  19.4326505781729 initial gdp train loss:  87.20678813950423\n",
            "initial val loss:  19.231081008911133 initial gdp val loss:  86.30220794677734\n",
            "Best Validation GDP Loss for fold 3: 4.0343\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  20.732964962343626 initial gdp train loss:  93.04213080426308\n",
            "initial val loss:  18.918439865112305 initial gdp val loss:  84.89920043945312\n",
            "Best Validation GDP Loss for fold 4: 5.0962\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  22.901383130359246 initial gdp train loss:  102.77321689138935\n",
            "initial val loss:  23.024559020996094 initial gdp val loss:  103.32598114013672\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:  25%|██▌       | 8/32 [01:47<05:01, 12.55s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 4.4146\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 4.5539\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.040011732573237 initial gdp train loss:  81.31623946788699\n",
            "initial val loss:  6.386597881797983 initial gdp val loss:  85.9823018562894\n",
            "Best Validation GDP Loss for fold 1: 0.7769\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  6.507217239879907 initial gdp train loss:  87.6061958651714\n",
            "initial val loss:  6.776401303395503 initial gdp val loss:  91.23019114261916\n",
            "Best Validation GDP Loss for fold 2: 0.9624\n",
            "Best best_epoch 91\n",
            "Fold 3/5\n",
            "initial train loss:  7.059083970790171 initial gdp train loss:  95.03593477015757\n",
            "initial val loss:  6.991412898241463 initial gdp val loss:  94.12488685219975\n",
            "Best Validation GDP Loss for fold 3: 0.8816\n",
            "Best best_epoch 99\n",
            "Fold 4/5\n",
            "initial train loss:  6.129133467935811 initial gdp train loss:  82.51607806370731\n",
            "initial val loss:  5.563554004087287 initial gdp val loss:  74.90171826896021\n",
            "Best Validation GDP Loss for fold 4: 0.9462\n",
            "Best best_epoch 90\n",
            "Fold 5/5\n",
            "initial train loss:  6.1486062661504945 initial gdp train loss:  82.77823719394861\n",
            "initial val loss:  6.182860156237068 initial gdp val loss:  83.2394004433842\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:  28%|██▊       | 9/32 [02:14<06:33, 17.12s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.8016\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 0.8737\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t8_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  21.542043794789222 initial gdp train loss:  96.67299453703092\n",
            "initial val loss:  22.65601287970022 initial gdp val loss:  101.67208535330636\n",
            "Best Validation GDP Loss for fold 1: 0.9420\n",
            "Best best_epoch 60\n",
            "Fold 2/5\n",
            "initial train loss:  21.635262563919163 initial gdp train loss:  97.09132032011327\n",
            "initial val loss:  22.50324201183159 initial gdp val loss:  100.98651014055524\n",
            "Best Validation GDP Loss for fold 2: 0.9688\n",
            "Best best_epoch 96\n",
            "Fold 3/5\n",
            "initial train loss:  20.837031304081783 initial gdp train loss:  93.50914513310299\n",
            "initial val loss:  20.62948989868164 initial gdp val loss:  92.57777676339877\n",
            "Best Validation GDP Loss for fold 3: 0.8917\n",
            "Best best_epoch 93\n",
            "Fold 4/5\n",
            "initial train loss:  22.648572664220623 initial gdp train loss:  101.63869643714358\n",
            "initial val loss:  20.715751260013903 initial gdp val loss:  92.9648821555962\n",
            "Best Validation GDP Loss for fold 4: 1.0015\n",
            "Best best_epoch 64\n",
            "Fold 5/5\n",
            "initial train loss:  20.809449602279987 initial gdp train loss:  93.3853705683841\n",
            "initial val loss:  20.922085002317267 initial gdp val loss:  93.89083655405852\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:  31%|███▏      | 10/32 [02:41<07:24, 20.20s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.8257\n",
            "Best best_epoch 87\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 0.9259\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.8997406747830095 initial gdp train loss:  106.35363574360692\n",
            "initial val loss:  8.285440444946289 initial gdp val loss:  111.5462875366211\n",
            "Best Validation GDP Loss for fold 1: 0.9862\n",
            "Best best_epoch 89\n",
            "Fold 2/5\n",
            "initial train loss:  6.951831699677804 initial gdp train loss:  93.59200998189334\n",
            "initial val loss:  7.233412742614746 initial gdp val loss:  97.38291931152344\n",
            "Best Validation GDP Loss for fold 2: 1.0222\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  6.279407636022769 initial gdp train loss:  84.53921161120451\n",
            "initial val loss:  6.211287975311279 initial gdp val loss:  83.62212371826172\n",
            "Best Validation GDP Loss for fold 3: 0.8885\n",
            "Best best_epoch 89\n",
            "Fold 4/5\n",
            "initial train loss:  7.585953342260691 initial gdp train loss:  102.12913986399204\n",
            "initial val loss:  6.942264080047607 initial gdp val loss:  93.46319580078125\n",
            "Best Validation GDP Loss for fold 4: 1.0636\n",
            "Best best_epoch 97\n",
            "Fold 5/5\n",
            "initial train loss:  7.190928175479551 initial gdp train loss:  96.81094302406794\n",
            "initial val loss:  7.22949743270874 initial gdp val loss:  97.3302001953125\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:  34%|███▍      | 11/32 [03:01<07:03, 20.17s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.8757\n",
            "Best best_epoch 84\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 0.9672\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  19.444261946083376 initial gdp train loss:  87.25889627726839\n",
            "initial val loss:  20.513389587402344 initial gdp val loss:  92.05677032470703\n",
            "Best Validation GDP Loss for fold 1: 0.8991\n",
            "Best best_epoch 97\n",
            "Fold 2/5\n",
            "initial train loss:  22.947439786495668 initial gdp train loss:  102.97990511033298\n",
            "initial val loss:  23.85018539428711 initial gdp val loss:  107.03109741210938\n",
            "Best Validation GDP Loss for fold 2: 1.0329\n",
            "Best best_epoch 97\n",
            "Fold 3/5\n",
            "initial train loss:  19.51532726046405 initial gdp train loss:  87.57781802149262\n",
            "initial val loss:  19.310976028442383 initial gdp val loss:  86.66075134277344\n",
            "Best Validation GDP Loss for fold 3: 0.9137\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  21.284945717340783 initial gdp train loss:  95.51922713653951\n",
            "initial val loss:  19.42350959777832 initial gdp val loss:  87.16577911376953\n",
            "Best Validation GDP Loss for fold 4: 1.0994\n",
            "Best best_epoch 97\n",
            "Fold 5/5\n",
            "initial train loss:  22.5710128832467 initial gdp train loss:  101.29063434842267\n",
            "initial val loss:  22.69197654724121 initial gdp val loss:  101.83348846435547\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:  38%|███▊      | 12/32 [03:21<06:42, 20.11s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.8820\n",
            "Best best_epoch 83\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 0.9654\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.41648337402505 initial gdp train loss:  99.84757611716273\n",
            "initial val loss:  7.791237470482578 initial gdp val loss:  104.8928691319057\n",
            "Best Validation GDP Loss for fold 1: 2.0142\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  6.206931952946282 initial gdp train loss:  83.56347277199743\n",
            "initial val loss:  6.467780578036268 initial gdp val loss:  87.07525916860885\n",
            "Best Validation GDP Loss for fold 2: 1.7608\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  6.664755718617499 initial gdp train loss:  89.72712240742229\n",
            "initial val loss:  6.596264839172363 initial gdp val loss:  88.8050340555482\n",
            "Best Validation GDP Loss for fold 3: 1.3558\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  6.219456747111389 initial gdp train loss:  83.73209329597054\n",
            "initial val loss:  5.647856469881737 initial gdp val loss:  76.0366782495531\n",
            "Best Validation GDP Loss for fold 4: 2.2077\n",
            "Best best_epoch 95\n",
            "Fold 5/5\n",
            "initial train loss:  7.190584573061657 initial gdp train loss:  96.80631632744512\n",
            "initial val loss:  7.228993520898334 initial gdp val loss:  97.32340925830906\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:  41%|████      | 13/32 [03:48<07:02, 22.22s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 1.6216\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 1.7920\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  21.16221712608418 initial gdp train loss:  94.96846503485585\n",
            "initial val loss:  22.27296527894605 initial gdp val loss:  99.95310185536617\n",
            "Best Validation GDP Loss for fold 1: 2.2203\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  18.87837036165072 initial gdp train loss:  84.71937652975006\n",
            "initial val loss:  19.664731771004302 initial gdp val loss:  88.24827934713925\n",
            "Best Validation GDP Loss for fold 2: 1.8390\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  20.265578016450135 initial gdp train loss:  90.94466664117097\n",
            "initial val loss:  20.061788623615847 initial gdp val loss:  90.03013843601033\n",
            "Best Validation GDP Loss for fold 3: 1.5653\n",
            "Best best_epoch 97\n",
            "Fold 4/5\n",
            "initial train loss:  22.90532611895211 initial gdp train loss:  102.79091573465726\n",
            "initial val loss:  20.964077028177552 initial gdp val loss:  94.07928143517445\n",
            "Best Validation GDP Loss for fold 4: 2.7714\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  22.23827998648213 initial gdp train loss:  99.79744981210443\n",
            "initial val loss:  22.357404062303445 initial gdp val loss:  100.33203952595339\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:  44%|████▍     | 14/32 [04:15<07:05, 23.62s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 1.5154\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 1.9823\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.6916209739056 initial gdp train loss:  90.08880860407307\n",
            "initial val loss:  7.0555739402771 initial gdp val loss:  94.98868560791016\n",
            "Best Validation GDP Loss for fold 1: 4.3507\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  6.2934130039578005 initial gdp train loss:  84.72776012138382\n",
            "initial val loss:  6.55562686920166 initial gdp val loss:  88.25794219970703\n",
            "Best Validation GDP Loss for fold 2: 3.8158\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  7.365577997537605 initial gdp train loss:  99.16224197194546\n",
            "initial val loss:  7.29879093170166 initial gdp val loss:  98.26309204101562\n",
            "Best Validation GDP Loss for fold 3: 3.6659\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  6.4075875040851065 initial gdp train loss:  86.26488391860124\n",
            "initial val loss:  5.8256330490112305 initial gdp val loss:  78.43006896972656\n",
            "Best Validation GDP Loss for fold 4: 4.4321\n",
            "Best best_epoch 98\n",
            "Fold 5/5\n",
            "initial train loss:  6.7783631956527 initial gdp train loss:  91.25661407341937\n",
            "initial val loss:  6.815258979797363 initial gdp val loss:  91.75334167480469\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:  47%|████▋     | 15/32 [04:35<06:22, 22.49s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 3.6874\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 3.9904\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  17.918831786948076 initial gdp train loss:  80.41330710929242\n",
            "initial val loss:  18.950620651245117 initial gdp val loss:  85.04360961914062\n",
            "Best Validation GDP Loss for fold 1: 4.1094\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  20.90473035526074 initial gdp train loss:  93.81295442480365\n",
            "initial val loss:  21.75080108642578 initial gdp val loss:  97.60980987548828\n",
            "Best Validation GDP Loss for fold 2: 3.9742\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  19.659103707422183 initial gdp train loss:  88.22302539036747\n",
            "initial val loss:  19.45566749572754 initial gdp val loss:  87.31007385253906\n",
            "Best Validation GDP Loss for fold 3: 3.6068\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  19.472934819475004 initial gdp train loss:  87.38757292027212\n",
            "initial val loss:  17.713829040527344 initial gdp val loss:  79.49333190917969\n",
            "Best Validation GDP Loss for fold 4: 4.5885\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  20.29506115168962 initial gdp train loss:  91.07698174971569\n",
            "initial val loss:  20.405834197998047 initial gdp val loss:  91.57408905029297\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Search:  50%|█████     | 16/32 [04:55<05:49, 21.84s/it]\u001b[A"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation GDP Loss for fold 5: 3.5651\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 3.9688\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.704380493083414 initial gdp train loss:  90.26058919636442\n",
            "initial val loss:  7.066379551126175 initial gdp val loss:  95.13415617101333\n",
            "Best Validation GDP Loss for fold 1: 0.7742\n",
            "Best best_epoch 98\n",
            "Fold 2/5\n",
            "initial train loss:  7.385197970126194 initial gdp train loss:  99.42638292373108\n",
            "initial val loss:  7.6789467875697035 initial gdp val loss:  103.38109434752906\n",
            "Best Validation GDP Loss for fold 2: 0.9766\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  6.385725912665516 initial gdp train loss:  85.97056724451765\n",
            "initial val loss:  6.31791099451356 initial gdp val loss:  85.05758188538633\n",
            "Best Validation GDP Loss for fold 3: 0.7295\n",
            "Best best_epoch 78\n",
            "Fold 4/5\n",
            "initial train loss:  8.09051337825598 initial gdp train loss:  108.9219959758002\n",
            "initial val loss:  7.4206791570631125 initial gdp val loss:  99.90406695866989\n",
            "Best Validation GDP Loss for fold 4: 1.0843\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  6.668205492607149 initial gdp train loss:  89.77356591204551\n",
            "initial val loss:  6.705123715481515 initial gdp val loss:  90.27059328758111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  53%|█████▎    | 17/32 [05:26<06:09, 24.62s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.7570\n",
            "Best best_epoch 93\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 0.8643\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t8_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  21.795686229842914 initial gdp train loss:  97.81124365002105\n",
            "initial val loss:  22.90764890398298 initial gdp val loss:  102.8013387728138\n",
            "Best Validation GDP Loss for fold 1: 0.7346\n",
            "Best best_epoch 92\n",
            "Fold 2/5\n",
            "initial train loss:  21.402092383225423 initial gdp train loss:  96.04493898871586\n",
            "initial val loss:  22.26199520335478 initial gdp val loss:  99.90387520669888\n",
            "Best Validation GDP Loss for fold 2: 1.0308\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  21.797848729644645 initial gdp train loss:  97.82095195271295\n",
            "initial val loss:  21.593632390943625 initial gdp val loss:  96.90450079966399\n",
            "Best Validation GDP Loss for fold 3: 0.7351\n",
            "Best best_epoch 86\n",
            "Fold 4/5\n",
            "initial train loss:  20.48053785718443 initial gdp train loss:  91.90932767200067\n",
            "initial val loss:  18.670151371066854 initial gdp val loss:  83.78496538582495\n",
            "Best Validation GDP Loss for fold 4: 0.9692\n",
            "Best best_epoch 94\n",
            "Fold 5/5\n",
            "initial train loss:  21.41493006195197 initial gdp train loss:  96.1025505548791\n",
            "initial val loss:  21.5309747598939 initial gdp val loss:  96.6233157141734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  56%|█████▋    | 18/32 [05:57<06:12, 26.57s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.7914\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 0.8522\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t8_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.653080822297433 initial gdp train loss:  89.56994312762205\n",
            "initial val loss:  7.0147576332092285 initial gdp val loss:  94.43917083740234\n",
            "Best Validation GDP Loss for fold 1: 0.9549\n",
            "Best best_epoch 93\n",
            "Fold 2/5\n",
            "initial train loss:  7.27129378026434 initial gdp train loss:  97.89290020480972\n",
            "initial val loss:  7.562254428863525 initial gdp val loss:  101.81007385253906\n",
            "Best Validation GDP Loss for fold 2: 1.4075\n",
            "Best best_epoch 94\n",
            "Fold 3/5\n",
            "initial train loss:  7.190839346954088 initial gdp train loss:  96.80974772006651\n",
            "initial val loss:  7.124338626861572 initial gdp val loss:  95.9144515991211\n",
            "Best Validation GDP Loss for fold 3: 1.0236\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  6.5581928446323055 initial gdp train loss:  88.29247406263391\n",
            "initial val loss:  5.969526767730713 initial gdp val loss:  80.36730194091797\n",
            "Best Validation GDP Loss for fold 4: 1.2337\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  6.2697490498989445 initial gdp train loss:  84.40917547040851\n",
            "initial val loss:  6.304070949554443 initial gdp val loss:  84.87124633789062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  59%|█████▉    | 19/32 [06:21<05:35, 25.78s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.7702\n",
            "Best best_epoch 97\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 1.0780\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  21.052740734172925 initial gdp train loss:  94.47717656141607\n",
            "initial val loss:  22.158710479736328 initial gdp val loss:  99.44037628173828\n",
            "Best Validation GDP Loss for fold 1: 1.2176\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  19.552205495048025 initial gdp train loss:  87.74331111786985\n",
            "initial val loss:  20.362606048583984 initial gdp val loss:  91.38009643554688\n",
            "Best Validation GDP Loss for fold 2: 1.1855\n",
            "Best best_epoch 93\n",
            "Fold 3/5\n",
            "initial train loss:  19.975476478222554 initial gdp train loss:  89.64279876580218\n",
            "initial val loss:  19.769981384277344 initial gdp val loss:  88.72061157226562\n",
            "Best Validation GDP Loss for fold 3: 1.0144\n",
            "Best best_epoch 97\n",
            "Fold 4/5\n",
            "initial train loss:  21.772690632172274 initial gdp train loss:  97.70805181833259\n",
            "initial val loss:  19.88237190246582 initial gdp val loss:  89.2249755859375\n",
            "Best Validation GDP Loss for fold 4: 1.2365\n",
            "Best best_epoch 97\n",
            "Fold 5/5\n",
            "initial train loss:  21.723205502023173 initial gdp train loss:  97.48598000570692\n",
            "initial val loss:  21.841482162475586 initial gdp val loss:  98.01676940917969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  62%|██████▎   | 20/32 [06:45<05:02, 25.23s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.8100\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 1.0928\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.329783201721708 initial gdp train loss:  85.21740895245091\n",
            "initial val loss:  6.685447873187666 initial gdp val loss:  90.00569967061531\n",
            "Best Validation GDP Loss for fold 1: 3.0876\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  7.732276024324445 initial gdp train loss:  104.09906694601757\n",
            "initial val loss:  8.035058838980538 initial gdp val loss:  108.17541164109687\n",
            "Best Validation GDP Loss for fold 2: 3.1652\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  6.970205003199195 initial gdp train loss:  93.83936502963682\n",
            "initial val loss:  6.902518062268273 initial gdp val loss:  92.92810627565545\n",
            "Best Validation GDP Loss for fold 3: 2.6573\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  7.7564591435943475 initial gdp train loss:  104.42464717430404\n",
            "initial val loss:  7.10135589211674 initial gdp val loss:  95.60503917629435\n",
            "Best Validation GDP Loss for fold 4: 3.6685\n",
            "Best best_epoch 98\n",
            "Fold 5/5\n",
            "initial train loss:  7.4866750532061745 initial gdp train loss:  100.79256374825908\n",
            "initial val loss:  7.527113575046346 initial gdp val loss:  101.33698531328622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  66%|██████▌   | 21/32 [07:16<04:56, 26.93s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 2.7628\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 3.0683\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  18.324889289904345 initial gdp train loss:  82.23554770084567\n",
            "initial val loss:  19.376430767924845 initial gdp val loss:  86.95449059750854\n",
            "Best Validation GDP Loss for fold 1: 2.9736\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  22.33164125567511 initial gdp train loss:  100.21642292175939\n",
            "initial val loss:  23.218417592409278 initial gdp val loss:  104.19595554896763\n",
            "Best Validation GDP Loss for fold 2: 3.2315\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  19.99666362070333 initial gdp train loss:  89.73787624825908\n",
            "initial val loss:  19.79050238657806 initial gdp val loss:  88.81269991599908\n",
            "Best Validation GDP Loss for fold 3: 2.6495\n",
            "Best best_epoch 97\n",
            "Fold 4/5\n",
            "initial train loss:  21.725888047037245 initial gdp train loss:  97.49801857863801\n",
            "initial val loss:  19.857581413398353 initial gdp val loss:  89.11371586686474\n",
            "Best Validation GDP Loss for fold 4: 3.5440\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  19.96109155260561 initial gdp train loss:  89.57824230596486\n",
            "initial val loss:  20.070923207169873 initial gdp val loss:  90.0711331125033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  69%|██████▉   | 22/32 [07:47<04:41, 28.15s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 2.4602\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 2.9718\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.278129705666991 initial gdp train loss:  97.9849326716417\n",
            "initial val loss:  7.652522087097168 initial gdp val loss:  103.02534484863281\n",
            "Best Validation GDP Loss for fold 1: 4.5120\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  6.608470323977964 initial gdp train loss:  88.96935539971446\n",
            "initial val loss:  6.880800247192383 initial gdp val loss:  92.6357192993164\n",
            "Best Validation GDP Loss for fold 2: 4.0699\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  7.043914434779042 initial gdp train loss:  94.83171071885508\n",
            "initial val loss:  6.975164413452148 initial gdp val loss:  93.90613555908203\n",
            "Best Validation GDP Loss for fold 3: 3.7521\n",
            "Best best_epoch 99\n",
            "Fold 4/5\n",
            "initial train loss:  6.780881746911802 initial gdp train loss:  91.29051765409703\n",
            "initial val loss:  6.175525188446045 initial gdp val loss:  83.14065551757812\n",
            "Best Validation GDP Loss for fold 4: 4.6945\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  6.259420302346789 initial gdp train loss:  84.27012338115193\n",
            "initial val loss:  6.294919490814209 initial gdp val loss:  84.748046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  72%|███████▏  | 23/32 [08:11<04:01, 26.87s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 3.8377\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 4.1732\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  19.813999401842565 initial gdp train loss:  88.91814496804493\n",
            "initial val loss:  20.88083267211914 initial gdp val loss:  93.70570373535156\n",
            "Best Validation GDP Loss for fold 1: 4.4803\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  20.76333471786144 initial gdp train loss:  93.17842568201948\n",
            "initial val loss:  21.604135513305664 initial gdp val loss:  96.9516372680664\n",
            "Best Validation GDP Loss for fold 2: 4.1073\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  21.77995684981849 initial gdp train loss:  97.74065791906686\n",
            "initial val loss:  21.576011657714844 initial gdp val loss:  96.82542419433594\n",
            "Best Validation GDP Loss for fold 3: 3.7666\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  21.304913548980583 initial gdp train loss:  95.6088311239637\n",
            "initial val loss:  19.43927574157715 initial gdp val loss:  87.23652648925781\n",
            "Best Validation GDP Loss for fold 4: 4.7496\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  19.480296138972673 initial gdp train loss:  87.42060185685942\n",
            "initial val loss:  19.584501266479492 initial gdp val loss:  87.88824462890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  75%|███████▌  | 24/32 [08:35<03:28, 26.03s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 3.7846\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 4.1777\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.736993178756746 initial gdp train loss:  90.69965006080288\n",
            "initial val loss:  7.099453409178918 initial gdp val loss:  95.57942308698382\n",
            "Best Validation GDP Loss for fold 1: 0.8284\n",
            "Best best_epoch 75\n",
            "Fold 2/5\n",
            "initial train loss:  7.460914323496264 initial gdp train loss:  100.44574832714638\n",
            "initial val loss:  7.756500600766735 initial gdp val loss:  104.42520263415425\n",
            "Best Validation GDP Loss for fold 2: 0.8385\n",
            "Best best_epoch 87\n",
            "Fold 3/5\n",
            "initial train loss:  6.720545008212706 initial gdp train loss:  90.47820800266186\n",
            "initial val loss:  6.652384620601848 initial gdp val loss:  89.56057040974245\n",
            "Best Validation GDP Loss for fold 3: 0.6930\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  6.406694440399042 initial gdp train loss:  86.25286021816076\n",
            "initial val loss:  5.8231308985564665 initial gdp val loss:  78.39638389975337\n",
            "Best Validation GDP Loss for fold 4: 0.9126\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  6.24600357546585 initial gdp train loss:  84.0894917355308\n",
            "initial val loss:  6.280373322761665 initial gdp val loss:  84.55220613641254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  78%|███████▊  | 25/32 [09:51<04:48, 41.18s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.7840\n",
            "Best best_epoch 89\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 0.8113\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t8_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  19.38383685105951 initial gdp train loss:  86.98773277234325\n",
            "initial val loss:  20.450982839119536 initial gdp val loss:  91.77669871354304\n",
            "Best Validation GDP Loss for fold 1: 0.8034\n",
            "Best best_epoch 63\n",
            "Fold 2/5\n",
            "initial train loss:  21.54729513688521 initial gdp train loss:  96.69655833335054\n",
            "initial val loss:  22.411683106622775 initial gdp val loss:  100.57562063521698\n",
            "Best Validation GDP Loss for fold 2: 0.8382\n",
            "Best best_epoch 91\n",
            "Fold 3/5\n",
            "initial train loss:  20.078587986748932 initial gdp train loss:  90.1055216406971\n",
            "initial val loss:  19.873914104397013 initial gdp val loss:  89.18701896020922\n",
            "Best Validation GDP Loss for fold 3: 0.7100\n",
            "Best best_epoch 85\n",
            "Fold 4/5\n",
            "initial train loss:  19.76308038767883 initial gdp train loss:  88.68963571540414\n",
            "initial val loss:  17.982661683680647 initial gdp val loss:  80.69975578178794\n",
            "Best Validation GDP Loss for fold 4: 0.9081\n",
            "Best best_epoch 88\n",
            "Fold 5/5\n",
            "initial train loss:  23.125115728579495 initial gdp train loss:  103.77725313082023\n",
            "initial val loss:  23.247591826875333 initial gdp val loss:  104.32687933970305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  81%|████████▏ | 26/32 [11:08<05:10, 51.81s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.7886\n",
            "Best best_epoch 76\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 0.8097\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t8_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.508283889318873 initial gdp train loss:  101.08347909294274\n",
            "initial val loss:  7.886937141418457 initial gdp val loss:  106.18126678466797\n",
            "Best Validation GDP Loss for fold 1: 0.7941\n",
            "Best best_epoch 66\n",
            "Fold 2/5\n",
            "initial train loss:  7.184128926621935 initial gdp train loss:  96.71940190192257\n",
            "initial val loss:  7.472301006317139 initial gdp val loss:  100.59906005859375\n",
            "Best Validation GDP Loss for fold 2: 0.8535\n",
            "Best best_epoch 97\n",
            "Fold 3/5\n",
            "initial train loss:  6.701820011380352 initial gdp train loss:  90.22611790266721\n",
            "initial val loss:  6.633857727050781 initial gdp val loss:  89.31114196777344\n",
            "Best Validation GDP Loss for fold 3: 0.7337\n",
            "Best best_epoch 96\n",
            "Fold 4/5\n",
            "initial train loss:  6.887475385947569 initial gdp train loss:  92.72557766427471\n",
            "initial val loss:  6.279590129852295 initial gdp val loss:  84.54166412353516\n",
            "Best Validation GDP Loss for fold 4: 0.9484\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  7.3778995823759566 initial gdp train loss:  99.32812577259692\n",
            "initial val loss:  7.417233943939209 initial gdp val loss:  99.8576889038086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  84%|████████▍ | 27/32 [12:10<04:34, 54.94s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.7921\n",
            "Best best_epoch 91\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 0.8243\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  19.095948285834734 initial gdp train loss:  85.69578915166552\n",
            "initial val loss:  20.154617309570312 initial gdp val loss:  90.44672393798828\n",
            "Best Validation GDP Loss for fold 1: 0.8178\n",
            "Best best_epoch 97\n",
            "Fold 2/5\n",
            "initial train loss:  19.21578275426498 initial gdp train loss:  86.23355947740487\n",
            "initial val loss:  20.013471603393555 initial gdp val loss:  89.81331634521484\n",
            "Best Validation GDP Loss for fold 2: 0.8537\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  19.376836720398206 initial gdp train loss:  86.95631914098554\n",
            "initial val loss:  19.172231674194336 initial gdp val loss:  86.03811645507812\n",
            "Best Validation GDP Loss for fold 3: 0.7638\n",
            "Best best_epoch 95\n",
            "Fold 4/5\n",
            "initial train loss:  21.889813700808755 initial gdp train loss:  98.23366018689634\n",
            "initial val loss:  19.995403289794922 initial gdp val loss:  89.73220825195312\n",
            "Best Validation GDP Loss for fold 4: 0.9271\n",
            "Best best_epoch 93\n",
            "Fold 5/5\n",
            "initial train loss:  22.460776485974275 initial gdp train loss:  100.79593561872652\n",
            "initial val loss:  22.580047607421875 initial gdp val loss:  101.33118438720703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  88%|████████▊ | 28/32 [13:12<03:48, 57.10s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.8173\n",
            "Best best_epoch 98\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 0.8359\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.970403487788194 initial gdp train loss:  93.84203717673304\n",
            "initial val loss:  7.336822966567609 initial gdp val loss:  98.77511551800896\n",
            "Best Validation GDP Loss for fold 1: 1.3308\n",
            "Best best_epoch 95\n",
            "Fold 2/5\n",
            "initial train loss:  6.8712745559643995 initial gdp train loss:  92.50747191931178\n",
            "initial val loss:  7.150699807816193 initial gdp val loss:  96.26935436344948\n",
            "Best Validation GDP Loss for fold 2: 1.2884\n",
            "Best best_epoch 98\n",
            "Fold 3/5\n",
            "initial train loss:  6.472350708040004 initial gdp train loss:  87.13678889536153\n",
            "initial val loss:  6.404492418644792 initial gdp val loss:  86.22321591134799\n",
            "Best Validation GDP Loss for fold 3: 0.9841\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  6.804417360684036 initial gdp train loss:  91.60737883491355\n",
            "initial val loss:  6.19882627260887 initial gdp val loss:  83.45434311688956\n",
            "Best Validation GDP Loss for fold 4: 1.4917\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  6.627878671959985 initial gdp train loss:  89.2306481856334\n",
            "initial val loss:  6.6639222694655595 initial gdp val loss:  89.71590617551642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  91%|█████████ | 29/32 [14:29<03:08, 62.86s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.9707\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 1.2131\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  21.407016992064914 initial gdp train loss:  96.06704055431277\n",
            "initial val loss:  22.519359556566766 initial gdp val loss:  101.0588248757755\n",
            "Best Validation GDP Loss for fold 1: 1.2366\n",
            "Best best_epoch 98\n",
            "Fold 2/5\n",
            "initial train loss:  19.027965456940407 initial gdp train loss:  85.39070622966355\n",
            "initial val loss:  19.819903237479075 initial gdp val loss:  88.94463668951467\n",
            "Best Validation GDP Loss for fold 2: 1.3207\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  22.91501593287987 initial gdp train loss:  102.83440167390847\n",
            "initial val loss:  22.713463864084016 initial gdp val loss:  101.92990164029396\n",
            "Best Validation GDP Loss for fold 3: 0.9981\n",
            "Best best_epoch 96\n",
            "Fold 4/5\n",
            "initial train loss:  22.696632827887555 initial gdp train loss:  101.8543718877221\n",
            "initial val loss:  20.764111793647377 initial gdp val loss:  93.18191049866758\n",
            "Best Validation GDP Loss for fold 4: 1.6046\n",
            "Best best_epoch 91\n",
            "Fold 5/5\n",
            "initial train loss:  21.29144431166508 initial gdp train loss:  95.5483908673379\n",
            "initial val loss:  21.405947766061555 initial gdp val loss:  96.06223930746822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  94%|█████████▍| 30/32 [15:45<02:13, 66.90s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.9846\n",
            "Best best_epoch 93\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 1.2289\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.022924293171275 initial gdp train loss:  81.08619462511253\n",
            "initial val loss:  6.3699493408203125 initial gdp val loss:  85.75816345214844\n",
            "Best Validation GDP Loss for fold 1: 2.7290\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  6.420227068927273 initial gdp train loss:  86.43504701255492\n",
            "initial val loss:  6.686728000640869 initial gdp val loss:  90.0229263305664\n",
            "Best Validation GDP Loss for fold 2: 2.8506\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  7.373706610393927 initial gdp train loss:  99.27167919818862\n",
            "initial val loss:  7.3059186935424805 initial gdp val loss:  98.35906219482422\n",
            "Best Validation GDP Loss for fold 3: 2.5048\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  6.932291825612386 initial gdp train loss:  93.32894060480946\n",
            "initial val loss:  6.321542739868164 initial gdp val loss:  85.10646057128906\n",
            "Best Validation GDP Loss for fold 4: 3.4140\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  7.25632724681484 initial gdp train loss:  97.69140525206232\n",
            "initial val loss:  7.295249938964844 initial gdp val loss:  98.21542358398438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  97%|█████████▋| 31/32 [16:47<01:05, 65.48s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 2.5029\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 2.8002\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  20.45200359997739 initial gdp train loss:  91.78127966269882\n",
            "initial val loss:  21.539962768554688 initial gdp val loss:  96.66364288330078\n",
            "Best Validation GDP Loss for fold 1: 3.0133\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  20.53213455409883 initial gdp train loss:  92.14088375422213\n",
            "initial val loss:  21.366905212402344 initial gdp val loss:  95.88703918457031\n",
            "Best Validation GDP Loss for fold 2: 3.0904\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  21.221627295771732 initial gdp train loss:  95.23507593855074\n",
            "initial val loss:  21.017744064331055 initial gdp val loss:  94.32011413574219\n",
            "Best Validation GDP Loss for fold 3: 2.5428\n",
            "Best best_epoch 99\n",
            "Fold 4/5\n",
            "initial train loss:  22.088745197666345 initial gdp train loss:  99.12638935459314\n",
            "initial val loss:  20.186466217041016 initial gdp val loss:  90.58963775634766\n",
            "Best Validation GDP Loss for fold 4: 3.5115\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  23.197859381824607 initial gdp train loss:  104.10370178866486\n",
            "initial val loss:  23.320558547973633 initial gdp val loss:  104.65432739257812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search: 100%|██████████| 32/32 [17:49<00:00, 33.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 2.5683\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 2.9453\n",
            "\n",
            "Best Hyperparameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01, 'record_best_epoch': 85, 'record_best_val_gdp_loss': 0.7100164779162003, 'record_best_fold': 3}\n",
            "Best Average Validation Loss: 0.8097\n",
            "initial train loss:  22.030114560513884 initial gdp train loss:  98.86327753840266\n",
            "initial val loss:  22.1807536372432 initial gdp val loss:  99.53929477267795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [85/85], Train Loss: 0.1752, Test Loss: 0.1507, GDP Train Loss: 0.7861, GDP Test Loss: 0.6763\n",
            "mae, mse, rmse, mape:  tensor(0.6423) tensor(0.6763) tensor(0.8224) tensor(13439.6104)\n",
            "Training complete!\n",
            "\n",
            "Final model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t8_95-19_lstm_best_final_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 1/6 [18:06<1:30:31, 1086.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1017, GDP Test Loss: 0.4564\n",
            "mae, mse, rmse, mape:  tensor(0.4684) tensor(0.4564) tensor(0.6756) tensor(12435.7988)\n",
            "cost time:  1086.2085106372833\n",
            "\n",
            "===================Next=====================\n",
            "LSTM_data_gdp_q_t10_95-19.pt\n",
            "device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.046009072273836 initial gdp train loss:  94.85990902340465\n",
            "initial val loss:  7.557075296129499 initial gdp val loss:  101.74034772600446\n",
            "Best Validation GDP Loss for fold 1: 0.6189\n",
            "Best best_epoch 93\n",
            "Fold 2/5\n",
            "initial train loss:  7.509819424205832 initial gdp train loss:  101.10415399662583\n",
            "initial val loss:  7.536907468523298 initial gdp val loss:  101.46883937290737\n",
            "Best Validation GDP Loss for fold 2: 0.7283\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  5.9505239687692955 initial gdp train loss:  80.11147322034623\n",
            "initial val loss:  5.657330172402518 initial gdp val loss:  76.16422707693917\n",
            "Best Validation GDP Loss for fold 3: 1.0157\n",
            "Best best_epoch 97\n",
            "Fold 4/5\n",
            "initial train loss:  6.759783290376599 initial gdp train loss:  91.00647187713008\n",
            "initial val loss:  6.402707898938978 initial gdp val loss:  86.19919483081715\n",
            "Best Validation GDP Loss for fold 4: 1.0516\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  6.147822488874397 initial gdp train loss:  82.76768645557515\n",
            "initial val loss:  6.311928637392886 initial gdp val loss:  84.97703696585991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:   3%|▎         | 1/32 [00:15<07:50, 15.17s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.9516\n",
            "Best best_epoch 97\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 0.8732\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t10_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  17.8136644149575 initial gdp train loss:  79.941356881317\n",
            "initial val loss:  19.198147909981863 initial gdp val loss:  86.15442766462054\n",
            "Best Validation GDP Loss for fold 1: 0.6531\n",
            "Best best_epoch 97\n",
            "Fold 2/5\n",
            "initial train loss:  17.59239046242205 initial gdp train loss:  78.94836022073378\n",
            "initial val loss:  17.6350827898298 initial gdp val loss:  79.13994707380023\n",
            "Best Validation GDP Loss for fold 2: 0.7339\n",
            "Best best_epoch 94\n",
            "Fold 3/5\n",
            "initial train loss:  23.68526769218958 initial gdp train loss:  106.29101230638445\n",
            "initial val loss:  22.596448625837052 initial gdp val loss:  101.404782976423\n",
            "Best Validation GDP Loss for fold 3: 1.0237\n",
            "Best best_epoch 95\n",
            "Fold 4/5\n",
            "initial train loss:  21.345306490358357 initial gdp train loss:  95.79010404036349\n",
            "initial val loss:  20.242272694905598 initial gdp val loss:  90.84008376662796\n",
            "Best Validation GDP Loss for fold 4: 1.0373\n",
            "Best best_epoch 88\n",
            "Fold 5/5\n",
            "initial train loss:  16.88716230029761 initial gdp train loss:  75.78354506524617\n",
            "initial val loss:  17.34475240621481 initial gdp val loss:  77.83705283500053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:   6%|▋         | 2/32 [00:30<07:34, 15.14s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.9909\n",
            "Best best_epoch 98\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 0.8878\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.461109063015925 initial gdp train loss:  100.44836918441705\n",
            "initial val loss:  7.987936973571777 initial gdp val loss:  107.54100799560547\n",
            "Best Validation GDP Loss for fold 1: 0.8543\n",
            "Best best_epoch 96\n",
            "Fold 2/5\n",
            "initial train loss:  6.439263020930269 initial gdp train loss:  86.69132680850178\n",
            "initial val loss:  6.454973220825195 initial gdp val loss:  86.90283966064453\n",
            "Best Validation GDP Loss for fold 2: 0.8967\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  7.434260034774986 initial gdp train loss:  100.08690243023928\n",
            "initial val loss:  7.087014675140381 initial gdp val loss:  95.41197204589844\n",
            "Best Validation GDP Loss for fold 3: 1.3842\n",
            "Best best_epoch 99\n",
            "Fold 4/5\n",
            "initial train loss:  6.794574725814581 initial gdp train loss:  91.47486565097067\n",
            "initial val loss:  6.436577796936035 initial gdp val loss:  86.65518188476562\n",
            "Best Validation GDP Loss for fold 4: 1.0864\n",
            "Best best_epoch 95\n",
            "Fold 5/5\n",
            "initial train loss:  6.669294517312274 initial gdp train loss:  89.78822874542851\n",
            "initial val loss:  6.838744640350342 initial gdp val loss:  92.06952667236328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:   9%|▉         | 3/32 [00:41<06:26, 13.32s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 1.0626\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 1.0568\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  20.767528739210736 initial gdp train loss:  93.19724506326855\n",
            "initial val loss:  22.283246994018555 initial gdp val loss:  99.99925231933594\n",
            "Best Validation GDP Loss for fold 1: 0.8096\n",
            "Best best_epoch 97\n",
            "Fold 2/5\n",
            "initial train loss:  19.67207643483252 initial gdp train loss:  88.28124332855636\n",
            "initial val loss:  19.728076934814453 initial gdp val loss:  88.53256225585938\n",
            "Best Validation GDP Loss for fold 2: 0.9638\n",
            "Best best_epoch 98\n",
            "Fold 3/5\n",
            "initial train loss:  22.832121382914316 initial gdp train loss:  102.46239953832242\n",
            "initial val loss:  21.788740158081055 initial gdp val loss:  97.78006744384766\n",
            "Best Validation GDP Loss for fold 3: 1.3391\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  25.17237934223491 initial gdp train loss:  112.96464243297875\n",
            "initial val loss:  23.95813751220703 initial gdp val loss:  107.51555633544922\n",
            "Best Validation GDP Loss for fold 4: 1.1226\n",
            "Best best_epoch 98\n",
            "Fold 5/5\n",
            "initial train loss:  22.526827199880444 initial gdp train loss:  101.09234859799379\n",
            "initial val loss:  23.06798553466797 initial gdp val loss:  103.5208740234375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  12%|█▎        | 4/32 [00:52<05:49, 12.48s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 1.1314\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 1.0733\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.94249892769373 initial gdp train loss:  93.46635987833477\n",
            "initial val loss:  7.449158123561314 initial gdp val loss:  100.2874777657645\n",
            "Best Validation GDP Loss for fold 1: 3.2408\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  6.538845639592329 initial gdp train loss:  88.0320045573829\n",
            "initial val loss:  6.557465757642474 initial gdp val loss:  88.28267996651786\n",
            "Best Validation GDP Loss for fold 2: 3.9274\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  7.249393860855444 initial gdp train loss:  97.59806402916331\n",
            "initial val loss:  6.907181331089565 initial gdp val loss:  92.99087633405414\n",
            "Best Validation GDP Loss for fold 3: 4.8566\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  6.916807568313291 initial gdp train loss:  93.12048112839393\n",
            "initial val loss:  6.554833665624395 initial gdp val loss:  88.24725080610395\n",
            "Best Validation GDP Loss for fold 4: 4.1727\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  6.404369093961097 initial gdp train loss:  86.22155947759914\n",
            "initial val loss:  6.567594206010973 initial gdp val loss:  88.41904435716233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  16%|█▌        | 5/32 [01:07<06:01, 13.40s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 3.5320\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 3.9459\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  23.455295605509804 initial gdp train loss:  105.25897972893821\n",
            "initial val loss:  25.0885865347726 initial gdp val loss:  112.58860124860492\n",
            "Best Validation GDP Loss for fold 1: 3.4288\n",
            "Best best_epoch 98\n",
            "Fold 2/5\n",
            "initial train loss:  22.292443279728225 initial gdp train loss:  100.04051338503713\n",
            "initial val loss:  22.362735475812638 initial gdp val loss:  100.35595703125\n",
            "Best Validation GDP Loss for fold 2: 3.9296\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  19.924963168499183 initial gdp train loss:  89.41611077005018\n",
            "initial val loss:  18.966898236955917 initial gdp val loss:  85.11666107177734\n",
            "Best Validation GDP Loss for fold 3: 4.8540\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  21.286223644111512 initial gdp train loss:  95.524959470335\n",
            "initial val loss:  20.18359986726228 initial gdp val loss:  90.57677885863158\n",
            "Best Validation GDP Loss for fold 4: 3.9688\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  19.701653934965197 initial gdp train loss:  88.41397439500096\n",
            "initial val loss:  20.205262519217825 initial gdp val loss:  90.6739907479501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  19%|█▉        | 6/32 [01:22<06:03, 13.97s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 3.7074\n",
            "Best best_epoch 98\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 3.9777\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.670669846470581 initial gdp train loss:  89.80674719703572\n",
            "initial val loss:  7.166654109954834 initial gdp val loss:  96.4841537475586\n",
            "Best Validation GDP Loss for fold 1: 3.7997\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  7.45450439581422 initial gdp train loss:  100.35945218347113\n",
            "initial val loss:  7.47707462310791 initial gdp val loss:  100.66331481933594\n",
            "Best Validation GDP Loss for fold 2: 4.5551\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  6.2596061817733695 initial gdp train loss:  84.27261824671997\n",
            "initial val loss:  5.95529842376709 initial gdp val loss:  80.1757583618164\n",
            "Best Validation GDP Loss for fold 3: 5.4974\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  6.012902891342539 initial gdp train loss:  80.95127924976732\n",
            "initial val loss:  5.6798601150512695 initial gdp val loss:  76.46753692626953\n",
            "Best Validation GDP Loss for fold 4: 4.9016\n",
            "Best best_epoch 98\n",
            "Fold 5/5\n",
            "initial train loss:  6.946017064770863 initial gdp train loss:  93.51372471751783\n",
            "initial val loss:  7.11643123626709 initial gdp val loss:  95.80799102783203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  22%|██▏       | 7/32 [01:33<05:26, 13.04s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 4.2068\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 4.5921\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  19.62008909045848 initial gdp train loss:  88.04794978667802\n",
            "initial val loss:  21.076717376708984 initial gdp val loss:  94.58476257324219\n",
            "Best Validation GDP Loss for fold 1: 3.8674\n",
            "Best best_epoch 97\n",
            "Fold 2/5\n",
            "initial train loss:  18.695314681048885 initial gdp train loss:  83.89788435179022\n",
            "initial val loss:  18.744651794433594 initial gdp val loss:  84.1192855834961\n",
            "Best Validation GDP Loss for fold 2: 4.4510\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  19.41268794312071 initial gdp train loss:  87.11719892698554\n",
            "initial val loss:  18.469966888427734 initial gdp val loss:  82.8865966796875\n",
            "Best Validation GDP Loss for fold 3: 5.5412\n",
            "Best best_epoch 99\n",
            "Fold 4/5\n",
            "initial train loss:  20.397213562489622 initial gdp train loss:  91.53540411144829\n",
            "initial val loss:  19.32329559326172 initial gdp val loss:  86.7160415649414\n",
            "Best Validation GDP Loss for fold 4: 4.8714\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  22.647739738959327 initial gdp train loss:  101.63496107063037\n",
            "initial val loss:  23.1875057220459 initial gdp val loss:  104.05723571777344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  25%|██▌       | 8/32 [01:44<04:58, 12.42s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 4.2703\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 4.6003\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  5.957429828130611 initial gdp train loss:  80.20444519316669\n",
            "initial val loss:  6.418966361454555 initial gdp val loss:  86.41807883126395\n",
            "Best Validation GDP Loss for fold 1: 0.6292\n",
            "Best best_epoch 98\n",
            "Fold 2/5\n",
            "initial train loss:  6.501242537134966 initial gdp train loss:  87.52575707542522\n",
            "initial val loss:  6.520166669573102 initial gdp val loss:  87.78053610665458\n",
            "Best Validation GDP Loss for fold 2: 0.6998\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  7.052524598724639 initial gdp train loss:  94.94762885944726\n",
            "initial val loss:  6.721396446228027 initial gdp val loss:  90.4896741594587\n",
            "Best Validation GDP Loss for fold 3: 0.9762\n",
            "Best best_epoch 47\n",
            "Fold 4/5\n",
            "initial train loss:  6.031962966492245 initial gdp train loss:  81.20787828347294\n",
            "initial val loss:  5.6982835434578565 initial gdp val loss:  76.71558297647012\n",
            "Best Validation GDP Loss for fold 4: 1.0481\n",
            "Best best_epoch 46\n",
            "Fold 5/5\n",
            "initial train loss:  6.070206105575732 initial gdp train loss:  81.72274288715133\n",
            "initial val loss:  6.229418406615386 initial gdp val loss:  83.86621011270059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  28%|██▊       | 9/32 [02:12<06:36, 17.24s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.8674\n",
            "Best best_epoch 97\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 0.8441\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t10_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  21.296440073192922 initial gdp train loss:  95.57080844485706\n",
            "initial val loss:  22.83065414428711 initial gdp val loss:  102.455812726702\n",
            "Best Validation GDP Loss for fold 1: 0.6386\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  21.631650445707177 initial gdp train loss:  97.07511374982484\n",
            "initial val loss:  21.70199966430664 initial gdp val loss:  97.39081682477679\n",
            "Best Validation GDP Loss for fold 2: 0.7192\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  20.80916021543768 initial gdp train loss:  93.38406751829413\n",
            "initial val loss:  19.830886840820312 initial gdp val loss:  88.99392918178013\n",
            "Best Validation GDP Loss for fold 3: 0.9207\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  22.284191810044668 initial gdp train loss:  100.00348719654467\n",
            "initial val loss:  21.153124250807203 initial gdp val loss:  94.92765938698709\n",
            "Best Validation GDP Loss for fold 4: 1.0961\n",
            "Best best_epoch 85\n",
            "Fold 5/5\n",
            "initial train loss:  20.55429246121605 initial gdp train loss:  92.24031869090376\n",
            "initial val loss:  21.06312995773178 initial gdp val loss:  94.52380522306974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  31%|███▏      | 10/32 [02:40<07:31, 20.50s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.7741\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 0.8297\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t10_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.810481693712585 initial gdp train loss:  105.151951503326\n",
            "initial val loss:  8.351530075073242 initial gdp val loss:  112.43604278564453\n",
            "Best Validation GDP Loss for fold 1: 0.8824\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  6.949980857660952 initial gdp train loss:  93.56708926897947\n",
            "initial val loss:  6.9709649085998535 initial gdp val loss:  93.84959411621094\n",
            "Best Validation GDP Loss for fold 2: 0.7272\n",
            "Best best_epoch 97\n",
            "Fold 3/5\n",
            "initial train loss:  6.271323884014591 initial gdp train loss:  84.43038071431387\n",
            "initial val loss:  5.965451240539551 initial gdp val loss:  80.31242370605469\n",
            "Best Validation GDP Loss for fold 3: 1.0274\n",
            "Best best_epoch 95\n",
            "Fold 4/5\n",
            "initial train loss:  7.478281384879844 initial gdp train loss:  100.67955935348067\n",
            "initial val loss:  7.099523067474365 initial gdp val loss:  95.58036804199219\n",
            "Best Validation GDP Loss for fold 4: 1.0512\n",
            "Best best_epoch 62\n",
            "Fold 5/5\n",
            "initial train loss:  7.105269532342351 initial gdp train loss:  95.65773174106674\n",
            "initial val loss:  7.278257846832275 initial gdp val loss:  97.98665618896484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  34%|███▍      | 11/32 [03:02<07:19, 20.91s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.8744\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 0.9125\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  19.204970877266785 initial gdp train loss:  86.1850416585469\n",
            "initial val loss:  20.649457931518555 initial gdp val loss:  92.6673812866211\n",
            "Best Validation GDP Loss for fold 1: 0.7119\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  22.929731197955896 initial gdp train loss:  102.90044023317071\n",
            "initial val loss:  23.007469177246094 initial gdp val loss:  103.24929809570312\n",
            "Best Validation GDP Loss for fold 2: 0.7529\n",
            "Best best_epoch 80\n",
            "Fold 3/5\n",
            "initial train loss:  19.524722813490794 initial gdp train loss:  87.6199723316415\n",
            "initial val loss:  18.585041046142578 initial gdp val loss:  83.40301513671875\n",
            "Best Validation GDP Loss for fold 3: 1.0374\n",
            "Best best_epoch 73\n",
            "Fold 4/5\n",
            "initial train loss:  20.963822644295576 initial gdp train loss:  94.07814326275648\n",
            "initial val loss:  19.872699737548828 initial gdp val loss:  89.18157196044922\n",
            "Best Validation GDP Loss for fold 4: 1.0927\n",
            "Best best_epoch 98\n",
            "Fold 5/5\n",
            "initial train loss:  22.31705368605236 initial gdp train loss:  100.15095752144286\n",
            "initial val loss:  22.851932525634766 initial gdp val loss:  102.55130004882812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  38%|███▊      | 12/32 [03:24<07:04, 21.24s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.9225\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 0.9035\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.328439742460379 initial gdp train loss:  98.66225351239534\n",
            "initial val loss:  7.84861877986363 initial gdp val loss:  105.66537475585938\n",
            "Best Validation GDP Loss for fold 1: 1.5651\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  6.197262864476362 initial gdp train loss:  83.43330157498073\n",
            "initial val loss:  6.214375223432269 initial gdp val loss:  83.66368538992745\n",
            "Best Validation GDP Loss for fold 2: 1.8809\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  6.657300361068794 initial gdp train loss:  89.62675000520031\n",
            "initial val loss:  6.339280877794538 initial gdp val loss:  85.34528568812779\n",
            "Best Validation GDP Loss for fold 3: 2.6660\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  6.126576898348678 initial gdp train loss:  82.48166013030665\n",
            "initial val loss:  5.789915256672077 initial gdp val loss:  77.94921414486997\n",
            "Best Validation GDP Loss for fold 4: 1.9899\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  7.111554048738757 initial gdp train loss:  95.74233527471556\n",
            "initial val loss:  7.284674476932835 initial gdp val loss:  98.07304574777415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  41%|████      | 13/32 [03:52<07:20, 23.17s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 2.0422\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 2.0288\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  20.910654718031264 initial gdp train loss:  93.83954315869798\n",
            "initial val loss:  22.433270045689174 initial gdp val loss:  100.67250061035156\n",
            "Best Validation GDP Loss for fold 1: 1.4254\n",
            "Best best_epoch 98\n",
            "Fold 2/5\n",
            "initial train loss:  18.862714476649536 initial gdp train loss:  84.64911774776442\n",
            "initial val loss:  18.91255678449358 initial gdp val loss:  84.87279510498047\n",
            "Best Validation GDP Loss for fold 2: 2.0393\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  20.23770495701264 initial gdp train loss:  90.8195852784298\n",
            "initial val loss:  19.273286274501256 initial gdp val loss:  86.49162292480469\n",
            "Best Validation GDP Loss for fold 3: 2.9520\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  22.57238202020359 initial gdp train loss:  101.29678069931815\n",
            "initial val loss:  21.43234175604743 initial gdp val loss:  96.18068860028241\n",
            "Best Validation GDP Loss for fold 4: 2.3707\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  21.978720039862647 initial gdp train loss:  98.63263866245346\n",
            "initial val loss:  22.508826315939963 initial gdp val loss:  101.01155846398156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  44%|████▍     | 14/32 [04:19<07:21, 24.54s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 2.1063\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 2.1787\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.618678522751471 initial gdp train loss:  89.10679051694314\n",
            "initial val loss:  7.111821174621582 initial gdp val loss:  95.74593353271484\n",
            "Best Validation GDP Loss for fold 1: 3.3771\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  6.29121296502015 initial gdp train loss:  84.69814379225932\n",
            "initial val loss:  6.307592391967773 initial gdp val loss:  84.91865539550781\n",
            "Best Validation GDP Loss for fold 2: 3.9857\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  7.3637411626465115 initial gdp train loss:  99.13751316498214\n",
            "initial val loss:  7.021914005279541 initial gdp val loss:  94.53553009033203\n",
            "Best Validation GDP Loss for fold 3: 5.2024\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  6.309367074262376 initial gdp train loss:  84.94255180273547\n",
            "initial val loss:  5.966551303863525 initial gdp val loss:  80.3272476196289\n",
            "Best Validation GDP Loss for fold 4: 4.2861\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  6.692545082211761 initial gdp train loss:  90.10124636656487\n",
            "initial val loss:  6.860267162322998 initial gdp val loss:  92.35926818847656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  47%|████▋     | 15/32 [04:41<06:43, 23.72s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 3.8475\n",
            "Best best_epoch 96\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 4.1398\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  17.719505908777897 initial gdp train loss:  79.51880823657118\n",
            "initial val loss:  19.093536376953125 initial gdp val loss:  85.68496704101562\n",
            "Best Validation GDP Loss for fold 1: 3.2518\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  20.888910721235746 initial gdp train loss:  93.74196990829947\n",
            "initial val loss:  20.952123641967773 initial gdp val loss:  94.02562713623047\n",
            "Best Validation GDP Loss for fold 2: 4.1096\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  19.64992317062857 initial gdp train loss:  88.18182947817405\n",
            "initial val loss:  18.704975128173828 initial gdp val loss:  83.94123840332031\n",
            "Best Validation GDP Loss for fold 3: 5.1212\n",
            "Best best_epoch 97\n",
            "Fold 4/5\n",
            "initial train loss:  19.1672430785177 initial gdp train loss:  86.01573536166676\n",
            "initial val loss:  18.131690979003906 initial gdp val loss:  81.36854553222656\n",
            "Best Validation GDP Loss for fold 4: 4.4471\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  20.052732122024434 initial gdp train loss:  89.98949087599513\n",
            "initial val loss:  20.556665420532227 initial gdp val loss:  92.25096130371094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  50%|█████     | 16/32 [05:03<06:10, 23.14s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 3.7518\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 4.1363\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.618692620452744 initial gdp train loss:  89.1069759146515\n",
            "initial val loss:  7.110664367675781 initial gdp val loss:  95.73035539899554\n",
            "Best Validation GDP Loss for fold 1: 0.6058\n",
            "Best best_epoch 98\n",
            "Fold 2/5\n",
            "initial train loss:  7.381387693465023 initial gdp train loss:  99.37508570239149\n",
            "initial val loss:  7.405827249799456 initial gdp val loss:  99.70411246163505\n",
            "Best Validation GDP Loss for fold 2: 0.5824\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  6.381217597311387 initial gdp train loss:  85.90986776993414\n",
            "initial val loss:  6.070945194789341 initial gdp val loss:  81.73270089285714\n",
            "Best Validation GDP Loss for fold 3: 0.9042\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  7.980237351701297 initial gdp train loss:  107.43735755049943\n",
            "initial val loss:  7.587025285841109 initial gdp val loss:  102.14357008375563\n",
            "Best Validation GDP Loss for fold 4: 0.8105\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  6.587980286386989 initial gdp train loss:  88.69350351423225\n",
            "initial val loss:  6.75506641198923 initial gdp val loss:  90.94296498341603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  53%|█████▎    | 17/32 [05:35<06:28, 25.87s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.9589\n",
            "Best best_epoch 94\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 0.7724\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t10_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  21.539766474155034 initial gdp train loss:  96.66277391921244\n",
            "initial val loss:  23.07827241080148 initial gdp val loss:  103.56703404017857\n",
            "Best Validation GDP Loss for fold 1: 0.5642\n",
            "Best best_epoch 98\n",
            "Fold 2/5\n",
            "initial train loss:  21.389569500636625 initial gdp train loss:  95.9887411006363\n",
            "initial val loss:  21.454440798078263 initial gdp val loss:  96.27985491071429\n",
            "Best Validation GDP Loss for fold 2: 0.5657\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  21.782524305608774 initial gdp train loss:  97.75218139101037\n",
            "initial val loss:  20.77198382786342 initial gdp val loss:  93.2172350202288\n",
            "Best Validation GDP Loss for fold 3: 0.9894\n",
            "Best best_epoch 76\n",
            "Fold 4/5\n",
            "initial train loss:  20.174032655071624 initial gdp train loss:  90.5338462129802\n",
            "initial val loss:  19.10611085633974 initial gdp val loss:  85.7413981669658\n",
            "Best Validation GDP Loss for fold 4: 0.9392\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  21.17108305775346 initial gdp train loss:  95.00825121578754\n",
            "initial val loss:  21.690516016504787 initial gdp val loss:  97.33928419233442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  56%|█████▋    | 18/32 [06:07<06:28, 27.76s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.9422\n",
            "Best best_epoch 98\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 0.8001\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.573404842428028 initial gdp train loss:  88.49727326123704\n",
            "initial val loss:  7.063621520996094 initial gdp val loss:  95.09703063964844\n",
            "Best Validation GDP Loss for fold 1: 0.6900\n",
            "Best best_epoch 92\n",
            "Fold 2/5\n",
            "initial train loss:  7.262673027312275 initial gdp train loss:  97.77684236535042\n",
            "initial val loss:  7.284590244293213 initial gdp val loss:  98.07190704345703\n",
            "Best Validation GDP Loss for fold 2: 0.8117\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  7.193028018078996 initial gdp train loss:  96.8392124603682\n",
            "initial val loss:  6.855309009552002 initial gdp val loss:  92.29252624511719\n",
            "Best Validation GDP Loss for fold 3: 1.1437\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  6.453920597998088 initial gdp train loss:  86.88866245346581\n",
            "initial val loss:  6.1064982414245605 initial gdp val loss:  82.21134185791016\n",
            "Best Validation GDP Loss for fold 4: 1.0439\n",
            "Best best_epoch 86\n",
            "Fold 5/5\n",
            "initial train loss:  6.187297967189644 initial gdp train loss:  83.29914531665094\n",
            "initial val loss:  6.347589492797852 initial gdp val loss:  85.4571304321289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  59%|█████▉    | 19/32 [06:34<05:56, 27.44s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 1.1618\n",
            "Best best_epoch 91\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 0.9702\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  20.802550337239765 initial gdp train loss:  93.35440569822029\n",
            "initial val loss:  22.319629669189453 initial gdp val loss:  100.16251373291016\n",
            "Best Validation GDP Loss for fold 1: 0.6615\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  19.546012296804932 initial gdp train loss:  87.7155129129042\n",
            "initial val loss:  19.60792350769043 initial gdp val loss:  87.99335479736328\n",
            "Best Validation GDP Loss for fold 2: 0.8329\n",
            "Best best_epoch 98\n",
            "Fold 3/5\n",
            "initial train loss:  19.967060773361958 initial gdp train loss:  89.60503072695882\n",
            "initial val loss:  19.012969970703125 initial gdp val loss:  85.32341766357422\n",
            "Best Validation GDP Loss for fold 3: 1.0850\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  21.44895185773538 initial gdp train loss:  96.25523323554054\n",
            "initial val loss:  20.34295082092285 initial gdp val loss:  91.29187774658203\n",
            "Best Validation GDP Loss for fold 4: 1.0699\n",
            "Best best_epoch 91\n",
            "Fold 5/5\n",
            "initial train loss:  21.465480262534463 initial gdp train loss:  96.32940528750153\n",
            "initial val loss:  21.989227294921875 initial gdp val loss:  98.6797866821289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  62%|██████▎   | 20/32 [07:01<05:26, 27.23s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 1.0795\n",
            "Best best_epoch 94\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 0.9458\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.253696129461041 initial gdp train loss:  84.19305638882076\n",
            "initial val loss:  6.730788707733154 initial gdp val loss:  90.61612592424665\n",
            "Best Validation GDP Loss for fold 1: 2.4867\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  7.730893509270365 initial gdp train loss:  104.08045579713556\n",
            "initial val loss:  7.755172865731375 initial gdp val loss:  104.40734209333148\n",
            "Best Validation GDP Loss for fold 2: 3.3994\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  6.966879483295663 initial gdp train loss:  93.7945934346973\n",
            "initial val loss:  6.637286118098667 initial gdp val loss:  89.35730089460101\n",
            "Best Validation GDP Loss for fold 3: 4.2506\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  7.643787309360717 initial gdp train loss:  102.90775553385417\n",
            "initial val loss:  7.260556745099592 initial gdp val loss:  97.74834985131616\n",
            "Best Validation GDP Loss for fold 4: 3.5881\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  7.40245444449269 initial gdp train loss:  99.6587101127744\n",
            "initial val loss:  7.5805417739593235 initial gdp val loss:  102.05627867552612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  66%|██████▌   | 21/32 [07:33<05:15, 28.66s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 3.0651\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 3.3580\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  18.08925034219374 initial gdp train loss:  81.17808926158956\n",
            "initial val loss:  19.489789145333425 initial gdp val loss:  87.4632099696568\n",
            "Best Validation GDP Loss for fold 1: 2.6198\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  22.321904443304636 initial gdp train loss:  100.17272542089624\n",
            "initial val loss:  22.393108095441544 initial gdp val loss:  100.49226379394531\n",
            "Best Validation GDP Loss for fold 2: 3.4412\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  19.984694057515917 initial gdp train loss:  89.68416017267201\n",
            "initial val loss:  19.032104764665878 initial gdp val loss:  85.40928104945591\n",
            "Best Validation GDP Loss for fold 3: 3.9906\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  21.411577583159378 initial gdp train loss:  96.0875041202144\n",
            "initial val loss:  20.30532713194151 initial gdp val loss:  91.1230537483284\n",
            "Best Validation GDP Loss for fold 4: 3.2100\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  19.72535754636897 initial gdp train loss:  88.52035551476531\n",
            "initial val loss:  20.22487092232919 initial gdp val loss:  90.76198529767561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  69%|██████▉   | 22/32 [08:05<04:57, 29.71s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 2.5326\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 3.1588\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.190707593755337 initial gdp train loss:  96.8079747084545\n",
            "initial val loss:  7.707336902618408 initial gdp val loss:  103.76331329345703\n",
            "Best Validation GDP Loss for fold 1: 3.6147\n",
            "Best best_epoch 95\n",
            "Fold 2/5\n",
            "initial train loss:  6.600027011648956 initial gdp train loss:  88.85568634170053\n",
            "initial val loss:  6.618826389312744 initial gdp val loss:  89.10877990722656\n",
            "Best Validation GDP Loss for fold 2: 4.2450\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  7.039449753782674 initial gdp train loss:  94.77160346882226\n",
            "initial val loss:  6.710099697113037 initial gdp val loss:  90.33759307861328\n",
            "Best Validation GDP Loss for fold 3: 5.2725\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  6.670911305702773 initial gdp train loss:  89.80999675639791\n",
            "initial val loss:  6.317022800445557 initial gdp val loss:  85.0456314086914\n",
            "Best Validation GDP Loss for fold 4: 4.6039\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  6.179734315381488 initial gdp train loss:  83.19731430292663\n",
            "initial val loss:  6.341525077819824 initial gdp val loss:  85.37548065185547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  72%|███████▏  | 23/32 [08:31<04:18, 28.77s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 3.9581\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 4.3388\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  19.572014522124835 initial gdp train loss:  87.83220809457548\n",
            "initial val loss:  21.022937774658203 initial gdp val loss:  94.34342956542969\n",
            "Best Validation GDP Loss for fold 1: 3.5054\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  20.753528364036114 initial gdp train loss:  93.13441935996838\n",
            "initial val loss:  20.815383911132812 initial gdp val loss:  93.4120101928711\n",
            "Best Validation GDP Loss for fold 2: 4.3374\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  21.77719331749886 initial gdp train loss:  97.72825725196188\n",
            "initial val loss:  20.76784896850586 initial gdp val loss:  93.19868469238281\n",
            "Best Validation GDP Loss for fold 3: 5.2972\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  20.984598761436924 initial gdp train loss:  94.17137809941165\n",
            "initial val loss:  19.89303970336914 initial gdp val loss:  89.2728500366211\n",
            "Best Validation GDP Loss for fold 4: 4.5511\n",
            "Best best_epoch 98\n",
            "Fold 5/5\n",
            "initial train loss:  19.23694710016784 initial gdp train loss:  86.3285452140791\n",
            "initial val loss:  19.723791122436523 initial gdp val loss:  88.5133285522461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  75%|███████▌  | 24/32 [08:58<03:44, 28.10s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 3.8965\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 4.3175\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.6539319064050515 initial gdp train loss:  89.58140293685845\n",
            "initial val loss:  7.146910531180246 initial gdp val loss:  96.21834455217633\n",
            "Best Validation GDP Loss for fold 1: 0.6192\n",
            "Best best_epoch 78\n",
            "Fold 2/5\n",
            "initial train loss:  7.453555994504236 initial gdp train loss:  100.34667910588696\n",
            "initial val loss:  7.477860314505441 initial gdp val loss:  100.67389569963727\n",
            "Best Validation GDP Loss for fold 2: 0.5461\n",
            "Best best_epoch 97\n",
            "Fold 3/5\n",
            "initial train loss:  6.721804980205314 initial gdp train loss:  90.49517452770284\n",
            "initial val loss:  6.4017406191144675 initial gdp val loss:  86.18617030552456\n",
            "Best Validation GDP Loss for fold 3: 0.8545\n",
            "Best best_epoch 75\n",
            "Fold 4/5\n",
            "initial train loss:  6.306329797578338 initial gdp train loss:  84.9016601767316\n",
            "initial val loss:  5.963974815231186 initial gdp val loss:  80.29256253629117\n",
            "Best Validation GDP Loss for fold 4: 0.9037\n",
            "Best best_epoch 93\n",
            "Fold 5/5\n",
            "initial train loss:  6.168032066934061 initial gdp train loss:  83.03976827873213\n",
            "initial val loss:  6.328311056704135 initial gdp val loss:  85.19759355149827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  78%|███████▊  | 25/32 [10:20<05:10, 44.30s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.7556\n",
            "Best best_epoch 93\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 0.7358\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t10_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  19.141791638772048 initial gdp train loss:  85.90152124652948\n",
            "initial val loss:  20.582812990461075 initial gdp val loss:  92.36830575125558\n",
            "Best Validation GDP Loss for fold 1: 0.6304\n",
            "Best best_epoch 61\n",
            "Fold 2/5\n",
            "initial train loss:  21.529660528550767 initial gdp train loss:  96.61741730557429\n",
            "initial val loss:  21.597619192940847 initial gdp val loss:  96.92240033830915\n",
            "Best Validation GDP Loss for fold 2: 0.5566\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  20.05781239565178 initial gdp train loss:  90.01229054403946\n",
            "initial val loss:  19.10064779009138 initial gdp val loss:  85.71687752859933\n",
            "Best Validation GDP Loss for fold 3: 0.8628\n",
            "Best best_epoch 80\n",
            "Fold 4/5\n",
            "initial train loss:  19.455619521855773 initial gdp train loss:  87.30986347241156\n",
            "initial val loss:  18.411376746925146 initial gdp val loss:  82.62367626568219\n",
            "Best Validation GDP Loss for fold 4: 0.9130\n",
            "Best best_epoch 93\n",
            "Fold 5/5\n",
            "initial train loss:  22.865091067832587 initial gdp train loss:  102.61035782645479\n",
            "initial val loss:  23.405382740604985 initial gdp val loss:  105.03499245858407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  81%|████████▏ | 26/32 [11:42<05:33, 55.66s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.7503\n",
            "Best best_epoch 88\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 0.7426\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  7.42276927494682 initial gdp train loss:  99.93220520019531\n",
            "initial val loss:  7.948277473449707 initial gdp val loss:  107.00708770751953\n",
            "Best Validation GDP Loss for fold 1: 0.6245\n",
            "Best best_epoch 88\n",
            "Fold 2/5\n",
            "initial train loss:  7.177851768887097 initial gdp train loss:  96.63490141453764\n",
            "initial val loss:  7.200315475463867 initial gdp val loss:  96.93733978271484\n",
            "Best Validation GDP Loss for fold 2: 0.6403\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  6.697060711180683 initial gdp train loss:  90.16204122363719\n",
            "initial val loss:  6.377152442932129 initial gdp val loss:  85.85513305664062\n",
            "Best Validation GDP Loss for fold 3: 0.9101\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  6.7799934231461565 initial gdp train loss:  91.27855608980661\n",
            "initial val loss:  6.422528266906738 initial gdp val loss:  86.46602630615234\n",
            "Best Validation GDP Loss for fold 4: 1.0659\n",
            "Best best_epoch 98\n",
            "Fold 5/5\n",
            "initial train loss:  7.28942783193567 initial gdp train loss:  98.1370418642458\n",
            "initial val loss:  7.465087890625 initial gdp val loss:  100.50193786621094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  84%|████████▍ | 27/32 [12:54<05:02, 60.49s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.8315\n",
            "Best best_epoch 95\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 0.8145\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  18.86573003760368 initial gdp train loss:  84.66265253315058\n",
            "initial val loss:  20.292781829833984 initial gdp val loss:  91.0667495727539\n",
            "Best Validation GDP Loss for fold 1: 0.6409\n",
            "Best best_epoch 97\n",
            "Fold 2/5\n",
            "initial train loss:  19.208060670861215 initial gdp train loss:  86.19891326630596\n",
            "initial val loss:  19.261661529541016 initial gdp val loss:  86.43944549560547\n",
            "Best Validation GDP Loss for fold 2: 0.5842\n",
            "Best best_epoch 90\n",
            "Fold 3/5\n",
            "initial train loss:  19.361755473731346 initial gdp train loss:  86.88863427542785\n",
            "initial val loss:  18.42756462097168 initial gdp val loss:  82.69632720947266\n",
            "Best Validation GDP Loss for fold 3: 0.9950\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  21.579443976383082 initial gdp train loss:  96.84082766880658\n",
            "initial val loss:  20.4691104888916 initial gdp val loss:  91.8580551147461\n",
            "Best Validation GDP Loss for fold 4: 1.0958\n",
            "Best best_epoch 46\n",
            "Fold 5/5\n",
            "initial train loss:  22.201610680394523 initial gdp train loss:  99.63289046660898\n",
            "initial val loss:  22.73242950439453 initial gdp val loss:  102.01502227783203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  88%|████████▊ | 28/32 [14:06<04:15, 63.87s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 0.8517\n",
            "Best best_epoch 92\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 0.8335\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  6.890905839979916 initial gdp train loss:  92.77176437035804\n",
            "initial val loss:  7.393408502851214 initial gdp val loss:  99.53692844935826\n",
            "Best Validation GDP Loss for fold 1: 0.9700\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  6.8643387935621325 initial gdp train loss:  92.41409448871698\n",
            "initial val loss:  6.8848733220781595 initial gdp val loss:  92.6905517578125\n",
            "Best Validation GDP Loss for fold 2: 1.1433\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  6.464028798945816 initial gdp train loss:  87.02474643724382\n",
            "initial val loss:  6.151666504996164 initial gdp val loss:  82.81943838936942\n",
            "Best Validation GDP Loss for fold 3: 1.4849\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  6.697333079856514 initial gdp train loss:  90.16571200240645\n",
            "initial val loss:  6.342556167293239 initial gdp val loss:  85.38937804076049\n",
            "Best Validation GDP Loss for fold 4: 1.1310\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  6.551316015939051 initial gdp train loss:  88.19989339670612\n",
            "initial val loss:  6.716713729205432 initial gdp val loss:  90.42662742546013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  91%|█████████ | 29/32 [15:28<03:27, 69.32s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 1.2665\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 1.1992\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  21.16995808041149 initial gdp train loss:  95.00320191661339\n",
            "initial val loss:  22.700646809169225 initial gdp val loss:  101.87238420758929\n",
            "Best Validation GDP Loss for fold 1: 0.9951\n",
            "Best best_epoch 96\n",
            "Fold 2/5\n",
            "initial train loss:  19.02242117398523 initial gdp train loss:  85.3658227963298\n",
            "initial val loss:  19.073554175240652 initial gdp val loss:  85.59529440743583\n",
            "Best Validation GDP Loss for fold 2: 1.0636\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  22.918574730911597 initial gdp train loss:  102.85037125386465\n",
            "initial val loss:  21.86878068106515 initial gdp val loss:  98.13926478794643\n",
            "Best Validation GDP Loss for fold 3: 1.6251\n",
            "Best best_epoch 99\n",
            "Fold 4/5\n",
            "initial train loss:  22.361742719441185 initial gdp train loss:  100.35150825790645\n",
            "initial val loss:  21.228025711334503 initial gdp val loss:  95.26378342912004\n",
            "Best Validation GDP Loss for fold 4: 1.2347\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  21.04309674290736 initial gdp train loss:  94.43389650212572\n",
            "initial val loss:  21.55906397157961 initial gdp val loss:  96.74937342738247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  94%|█████████▍| 30/32 [16:50<02:26, 73.09s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 1.2437\n",
            "Best best_epoch 97\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 1.2325\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  5.943429350318396 initial gdp train loss:  80.01595905115786\n",
            "initial val loss:  6.404630661010742 initial gdp val loss:  86.22506713867188\n",
            "Best Validation GDP Loss for fold 1: 1.5909\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  6.416272471303897 initial gdp train loss:  86.38180524885922\n",
            "initial val loss:  6.434080123901367 initial gdp val loss:  86.62155151367188\n",
            "Best Validation GDP Loss for fold 2: 2.4381\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  7.367043890760619 initial gdp train loss:  99.18197703682253\n",
            "initial val loss:  7.026181697845459 initial gdp val loss:  94.59297943115234\n",
            "Best Validation GDP Loss for fold 3: 3.7147\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  6.825792867331963 initial gdp train loss:  91.89515431722005\n",
            "initial val loss:  6.4669718742370605 initial gdp val loss:  87.06437683105469\n",
            "Best Validation GDP Loss for fold 4: 2.8412\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  7.172436906187326 initial gdp train loss:  96.56200089764009\n",
            "initial val loss:  7.346621513366699 initial gdp val loss:  98.90702819824219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  97%|█████████▋| 31/32 [18:02<01:12, 72.74s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 2.5809\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 2.6332\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  20.19543923176992 initial gdp train loss:  90.6299105930756\n",
            "initial val loss:  21.681438446044922 initial gdp val loss:  97.29855346679688\n",
            "Best Validation GDP Loss for fold 1: 2.0005\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  20.513845743085238 initial gdp train loss:  92.0588089126108\n",
            "initial val loss:  20.5736083984375 initial gdp val loss:  92.32701110839844\n",
            "Best Validation GDP Loss for fold 2: 2.6554\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  21.207919159277672 initial gdp train loss:  95.17355832497636\n",
            "initial val loss:  20.21300506591797 initial gdp val loss:  90.70873260498047\n",
            "Best Validation GDP Loss for fold 3: 3.3139\n",
            "Best best_epoch 99\n",
            "Fold 4/5\n",
            "initial train loss:  21.764301364053814 initial gdp train loss:  97.67040329491532\n",
            "initial val loss:  20.648252487182617 initial gdp val loss:  92.66197204589844\n",
            "Best Validation GDP Loss for fold 4: 2.8526\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  22.937362064984555 initial gdp train loss:  102.93468115207067\n",
            "initial val loss:  23.478965759277344 initial gdp val loss:  105.3652114868164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search: 100%|██████████| 32/32 [19:13<00:00, 36.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 2.6577\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 2.6960\n",
            "\n",
            "Best Hyperparameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01, 'record_best_epoch': 97, 'record_best_val_gdp_loss': 0.5461233854293823, 'record_best_fold': 2}\n",
            "Best Average Validation Loss: 0.7358\n",
            "initial train loss:  7.282961571942948 initial gdp train loss:  98.04998418336274\n",
            "initial val loss:  7.449569188631498 initial gdp val loss:  100.29301393949069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [97/97], Train Loss: 0.0529, Test Loss: 0.0338, GDP Train Loss: 0.7128, GDP Test Loss: 0.4557\n",
            "mae, mse, rmse, mape:  tensor(0.4965) tensor(0.4557) tensor(0.6751) tensor(5520.0254)\n",
            "Training complete!\n",
            "\n",
            "Final model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_q_t10_95-19_lstm_best_final_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 2/6 [37:40<1:15:51, 1137.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0309, GDP Test Loss: 0.4161\n",
            "mae, mse, rmse, mape:  tensor(0.4522) tensor(0.4161) tensor(0.6450) tensor(4433.2261)\n",
            "cost time:  1173.9254162311554\n",
            "\n",
            "===================Next=====================\n",
            "LSTM_data_gdp_more_q_t10_95-19.pt\n",
            "device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  0.8632459810320844 initial gdp train loss:  313.46397979958004\n",
            "initial val loss:  0.9124321756824371 initial gdp val loss:  331.3245824013987\n",
            "Best Validation GDP Loss for fold 1: 2.4975\n",
            "Best best_epoch 80\n",
            "Fold 2/5\n",
            "initial train loss:  1.0406703566042428 initial gdp train loss:  377.8907450998474\n",
            "initial val loss:  1.0737270862825454 initial gdp val loss:  389.8943804340978\n",
            "Best Validation GDP Loss for fold 2: 5.4593\n",
            "Best best_epoch 28\n",
            "Fold 3/5\n",
            "initial train loss:  0.5052229582638006 initial gdp train loss:  183.4577844233355\n",
            "initial val loss:  0.4645601610983572 initial gdp val loss:  168.6922137844947\n",
            "Best Validation GDP Loss for fold 3: 2.0380\n",
            "Best best_epoch 70\n",
            "Fold 4/5\n",
            "initial train loss:  0.7666157625970387 initial gdp train loss:  278.3753883417236\n",
            "initial val loss:  0.7136415293139796 initial gdp val loss:  259.1392434397051\n",
            "Best Validation GDP Loss for fold 4: 1.8457\n",
            "Best best_epoch 95\n",
            "Fold 5/5\n",
            "initial train loss:  0.5026258195600202 initial gdp train loss:  182.51470671622985\n",
            "initial val loss:  0.516150325247385 initial gdp val loss:  187.42576480606226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:   3%|▎         | 1/32 [00:42<21:43, 42.05s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 13.9059\n",
            "Best best_epoch 90\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 5.1493\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_more_q_t10_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  1.5384010957844128 initial gdp train loss:  186.2093132333086\n",
            "initial val loss:  1.6536616256160122 initial gdp val loss:  200.16054992675782\n",
            "Best Validation GDP Loss for fold 1: 2.4364\n",
            "Best best_epoch 80\n",
            "Fold 2/5\n",
            "initial train loss:  1.4088991919864657 initial gdp train loss:  170.5342988636919\n",
            "initial val loss:  1.5241823604029994 initial gdp val loss:  184.48826165968373\n",
            "Best Validation GDP Loss for fold 2: 5.4811\n",
            "Best best_epoch 24\n",
            "Fold 3/5\n",
            "initial train loss:  3.2274886362970214 initial gdp train loss:  390.65783659386193\n",
            "initial val loss:  3.088040885617656 initial gdp val loss:  373.7789775233115\n",
            "Best Validation GDP Loss for fold 3: 2.0362\n",
            "Best best_epoch 81\n",
            "Fold 4/5\n",
            "initial train loss:  2.6454624144467163 initial gdp train loss:  320.20892122159376\n",
            "initial val loss:  2.481698114641251 initial gdp val loss:  300.38673646988406\n",
            "Best Validation GDP Loss for fold 4: 1.8400\n",
            "Best best_epoch 71\n",
            "Fold 5/5\n",
            "initial train loss:  1.252940845489502 initial gdp train loss:  151.6569793701172\n",
            "initial val loss:  1.2968078296161392 initial gdp val loss:  156.96667119986031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:   6%|▋         | 2/32 [01:24<21:04, 42.17s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 13.7712\n",
            "Best best_epoch 90\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 5.1130\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_more_q_t10_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  1.0271800087766363 initial gdp train loss:  372.9921057995911\n",
            "initial val loss:  1.080354166799976 initial gdp val loss:  392.30081098002773\n",
            "Best Validation GDP Loss for fold 1: 3.5442\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  0.6144073940362538 initial gdp train loss:  223.10510766227173\n",
            "initial val loss:  0.6527235204173673 initial gdp val loss:  237.01854543378275\n",
            "Best Validation GDP Loss for fold 2: 5.8756\n",
            "Best best_epoch 41\n",
            "Fold 3/5\n",
            "initial train loss:  0.920727205526646 initial gdp train loss:  334.336698739927\n",
            "initial val loss:  0.8756107176503828 initial gdp val loss:  317.95389581495715\n",
            "Best Validation GDP Loss for fold 3: 2.2263\n",
            "Best best_epoch 99\n",
            "Fold 4/5\n",
            "initial train loss:  0.7831405406521634 initial gdp train loss:  284.37590446810844\n",
            "initial val loss:  0.7300616733489498 initial gdp val loss:  265.10176509734123\n",
            "Best Validation GDP Loss for fold 4: 1.9611\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  0.6938310765451 initial gdp train loss:  251.9456314579133\n",
            "initial val loss:  0.7081649907198538 initial gdp val loss:  257.15060271722984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:   9%|▉         | 3/32 [01:53<17:31, 36.26s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 14.3326\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 5.5880\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  2.482165915433008 initial gdp train loss:  300.44336612384296\n",
            "initial val loss:  2.6268357846044723 initial gdp val loss:  317.9543149886593\n",
            "Best Validation GDP Loss for fold 1: 3.4455\n",
            "Best best_epoch 96\n",
            "Fold 2/5\n",
            "initial train loss:  2.0277504041562455 initial gdp train loss:  245.44055169623547\n",
            "initial val loss:  2.1380962917881625 initial gdp val loss:  258.7969055175781\n",
            "Best Validation GDP Loss for fold 2: 6.1664\n",
            "Best best_epoch 45\n",
            "Fold 3/5\n",
            "initial train loss:  3.1125460259850897 initial gdp train loss:  376.7450995025758\n",
            "initial val loss:  2.9771315666937057 initial gdp val loss:  360.35439846900204\n",
            "Best Validation GDP Loss for fold 3: 2.2642\n",
            "Best best_epoch 99\n",
            "Fold 4/5\n",
            "initial train loss:  4.061365220313884 initial gdp train loss:  491.5909471119287\n",
            "initial val loss:  3.8809990836728003 initial gdp val loss:  469.75928561302925\n",
            "Best Validation GDP Loss for fold 4: 1.9903\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  2.9744181017721854 initial gdp train loss:  360.02596553679433\n",
            "initial val loss:  3.017892400037895 initial gdp val loss:  365.2881259362674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  12%|█▎        | 4/32 [02:22<15:39, 33.56s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 14.6786\n",
            "Best best_epoch 63\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 5.7090\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  0.8271121844541074 initial gdp train loss:  300.34299009013694\n",
            "initial val loss:  0.8753178681096723 initial gdp val loss:  317.8475316201487\n",
            "Best Validation GDP Loss for fold 1: 9.0546\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  0.6754407278946852 initial gdp train loss:  245.26768477642315\n",
            "initial val loss:  0.7118273058245259 initial gdp val loss:  258.4804488643523\n",
            "Best Validation GDP Loss for fold 2: 10.1427\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  0.8477478466080118 initial gdp train loss:  307.83626361197287\n",
            "initial val loss:  0.803059499109945 initial gdp val loss:  291.60891979586694\n",
            "Best Validation GDP Loss for fold 3: 3.1825\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  0.8202088610408189 initial gdp train loss:  297.836236493447\n",
            "initial val loss:  0.7664977208260567 initial gdp val loss:  278.33252248456404\n",
            "Best Validation GDP Loss for fold 4: 3.4530\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  0.6529509778945677 initial gdp train loss:  237.1011518909085\n",
            "initial val loss:  0.6679419834636947 initial gdp val loss:  242.54470815319073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  16%|█▌        | 5/32 [03:05<16:35, 36.89s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 14.8267\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 8.1319\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  3.3851657340948 initial gdp train loss:  409.74320857038026\n",
            "initial val loss:  3.5525269877526067 initial gdp val loss:  430.00074955109625\n",
            "Best Validation GDP Loss for fold 1: 10.3825\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  2.9144229806171875 initial gdp train loss:  352.7641165597098\n",
            "initial val loss:  3.0187182580271075 initial gdp val loss:  365.3881243305822\n",
            "Best Validation GDP Loss for fold 2: 12.8293\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  2.0616861553900274 initial gdp train loss:  249.5481577358292\n",
            "initial val loss:  1.9331665631263486 initial gdp val loss:  233.9920421969506\n",
            "Best Validation GDP Loss for fold 3: 3.3137\n",
            "Best best_epoch 94\n",
            "Fold 4/5\n",
            "initial train loss:  2.6980126013767345 initial gdp train loss:  326.56963177820285\n",
            "initial val loss:  2.534772414545859 initial gdp val loss:  306.8109138734879\n",
            "Best Validation GDP Loss for fold 4: 3.5548\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  1.9905017975837953 initial gdp train loss:  240.93194560389364\n",
            "initial val loss:  2.033186581142512 initial gdp val loss:  246.09855528402483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  19%|█▉        | 6/32 [03:47<16:44, 38.65s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 15.2014\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 9.0563\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  0.7250843538306624 initial gdp train loss:  263.29438714003544\n",
            "initial val loss:  0.7703630516605993 initial gdp val loss:  279.73609422253026\n",
            "Best Validation GDP Loss for fold 1: 14.5319\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  0.9666585153009355 initial gdp train loss:  351.0153929038429\n",
            "initial val loss:  1.0018778627918612 initial gdp val loss:  363.80430868825607\n",
            "Best Validation GDP Loss for fold 2: 20.9280\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  0.5915442737867218 initial gdp train loss:  214.80299429166115\n",
            "initial val loss:  0.5499545397297029 initial gdp val loss:  199.70084336803805\n",
            "Best Validation GDP Loss for fold 3: 6.1848\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  0.5162196030916948 initial gdp train loss:  187.45091647809315\n",
            "initial val loss:  0.4668113043231349 initial gdp val loss:  169.50965202085433\n",
            "Best Validation GDP Loss for fold 4: 5.9956\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  0.8362420189765192 initial gdp train loss:  303.65823009860134\n",
            "initial val loss:  0.8514594672953041 initial gdp val loss:  309.1840285020353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  22%|██▏       | 7/32 [04:17<14:53, 35.73s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 20.9342\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 13.7149\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  2.1730164827311396 initial gdp train loss:  263.0236640049624\n",
            "initial val loss:  2.3081745916797267 initial gdp val loss:  279.3833206668977\n",
            "Best Validation GDP Loss for fold 1: 14.5532\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  1.7326580863310697 initial gdp train loss:  209.72233936226687\n",
            "initial val loss:  1.8441920988021359 initial gdp val loss:  223.22250425277218\n",
            "Best Validation GDP Loss for fold 2: 18.5055\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  1.8830313357352442 initial gdp train loss:  227.92363461301247\n",
            "initial val loss:  1.7557427298638129 initial gdp val loss:  212.51651443973665\n",
            "Best Validation GDP Loss for fold 3: 6.2846\n",
            "Best best_epoch 97\n",
            "Fold 4/5\n",
            "initial train loss:  2.3453239384344067 initial gdp train loss:  283.879904093523\n",
            "initial val loss:  2.186024413570281 initial gdp val loss:  264.59817957724295\n",
            "Best Validation GDP Loss for fold 4: 6.3038\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  3.0751719320974042 initial gdp train loss:  372.2213113107989\n",
            "initial val loss:  3.1194013322441325 initial gdp val loss:  377.574866828795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  25%|██▌       | 8/32 [04:46<13:27, 33.66s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 21.4290\n",
            "Best best_epoch 97\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 13.4152\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  0.5254462104925136 initial gdp train loss:  190.80130890360564\n",
            "initial val loss:  0.5642349585410087 initial gdp val loss:  204.88638295819683\n",
            "Best Validation GDP Loss for fold 1: 2.1538\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  0.6669934747486561 initial gdp train loss:  242.20029068301048\n",
            "initial val loss:  0.7033624891311892 initial gdp val loss:  255.40669073289442\n",
            "Best Validation GDP Loss for fold 2: 7.6603\n",
            "Best best_epoch 98\n",
            "Fold 3/5\n",
            "initial train loss:  0.8334273404416969 initial gdp train loss:  302.6361552462451\n",
            "initial val loss:  0.7896530239812789 initial gdp val loss:  286.74072757844004\n",
            "Best Validation GDP Loss for fold 3: 1.7064\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  0.520958919814751 initial gdp train loss:  189.17187358372823\n",
            "initial val loss:  0.4714858316606091 initial gdp val loss:  171.2070811610068\n",
            "Best Validation GDP Loss for fold 4: 1.7315\n",
            "Best best_epoch 98\n",
            "Fold 5/5\n",
            "initial train loss:  0.5379651800278694 initial gdp train loss:  195.34722319572202\n",
            "initial val loss:  0.5526426025578891 initial gdp val loss:  200.6769297578188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  28%|██▊       | 9/32 [06:03<18:03, 47.10s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 13.7208\n",
            "Best best_epoch 97\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 5.3946\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  2.690712736343741 initial gdp train loss:  325.6860544668079\n",
            "initial val loss:  2.8404283585086945 initial gdp val loss:  343.80774772397933\n",
            "Best Validation GDP Loss for fold 1: 2.3143\n",
            "Best best_epoch 85\n",
            "Fold 2/5\n",
            "initial train loss:  2.721623884082514 initial gdp train loss:  329.4275524271795\n",
            "initial val loss:  2.8257341338742163 initial gdp val loss:  342.02915964434226\n",
            "Best Validation GDP Loss for fold 2: 6.7689\n",
            "Best best_epoch 14\n",
            "Fold 3/5\n",
            "initial train loss:  2.4508658840927606 initial gdp train loss:  296.65479259475575\n",
            "initial val loss:  2.3205957781883977 initial gdp val loss:  280.8867988832535\n",
            "Best Validation GDP Loss for fold 3: 1.7078\n",
            "Best best_epoch 95\n",
            "Fold 4/5\n",
            "initial train loss:  2.9049670727047063 initial gdp train loss:  351.61956301882344\n",
            "initial val loss:  2.7367769179805634 initial gdp val loss:  331.26169906123994\n",
            "Best Validation GDP Loss for fold 4: 1.8150\n",
            "Best best_epoch 98\n",
            "Fold 5/5\n",
            "initial train loss:  2.3848289212872906 initial gdp train loss:  288.66162739415324\n",
            "initial val loss:  2.429565762238981 initial gdp val loss:  294.07660188644064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  31%|███▏      | 10/32 [07:20<20:37, 56.23s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 13.5708\n",
            "Best best_epoch 94\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 5.2354\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  1.160104936606659 initial gdp train loss:  421.2601226979056\n",
            "initial val loss:  1.2164478032819686 initial gdp val loss:  441.71947336504536\n",
            "Best Validation GDP Loss for fold 1: 2.4738\n",
            "Best best_epoch 97\n",
            "Fold 2/5\n",
            "initial train loss:  0.80701737917653 initial gdp train loss:  293.04611474530554\n",
            "initial val loss:  0.8426959049317144 initial gdp val loss:  306.0017875425277\n",
            "Best Validation GDP Loss for fold 2: 7.5597\n",
            "Best best_epoch 26\n",
            "Fold 3/5\n",
            "initial train loss:  0.5842469343742697 initial gdp train loss:  212.15316496595824\n",
            "initial val loss:  0.5425188033811508 initial gdp val loss:  197.00075122464088\n",
            "Best Validation GDP Loss for fold 3: 2.1241\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  1.0016482919334306 initial gdp train loss:  363.72095689627315\n",
            "initial val loss:  0.9453651655104852 initial gdp val loss:  343.283304719002\n",
            "Best Validation GDP Loss for fold 4: 1.9378\n",
            "Best best_epoch 90\n",
            "Fold 5/5\n",
            "initial train loss:  0.8829427253815436 initial gdp train loss:  320.61630662487397\n",
            "initial val loss:  0.8979169219057151 initial gdp val loss:  326.05377128131954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  34%|███▍      | 11/32 [08:18<19:56, 56.98s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 13.9632\n",
            "Best best_epoch 96\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 5.6117\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  1.984353925356276 initial gdp train loss:  240.1878043875952\n",
            "initial val loss:  2.1141076426352226 initial gdp val loss:  255.89330326203378\n",
            "Best Validation GDP Loss for fold 1: 2.6401\n",
            "Best best_epoch 96\n",
            "Fold 2/5\n",
            "initial train loss:  3.1921412342493336 initial gdp train loss:  386.37935677221265\n",
            "initial val loss:  3.2933732909540976 initial gdp val loss:  398.63257997574345\n",
            "Best Validation GDP Loss for fold 2: 6.7001\n",
            "Best best_epoch 26\n",
            "Fold 3/5\n",
            "initial train loss:  1.9779063724913455 initial gdp train loss:  239.40738666278878\n",
            "initial val loss:  1.850951273210587 initial gdp val loss:  224.0406450825353\n",
            "Best Validation GDP Loss for fold 3: 2.1541\n",
            "Best best_epoch 99\n",
            "Fold 4/5\n",
            "initial train loss:  2.443528081641455 initial gdp train loss:  295.76661636561903\n",
            "initial val loss:  2.2813326589522824 initial gdp val loss:  276.13436082409277\n",
            "Best Validation GDP Loss for fold 4: 1.9596\n",
            "Best best_epoch 70\n",
            "Fold 5/5\n",
            "initial train loss:  2.9587950967973278 initial gdp train loss:  358.1349558184224\n",
            "initial val loss:  3.0033316627675277 initial gdp val loss:  363.52568888741405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  38%|███▊      | 12/32 [09:17<19:10, 57.52s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 14.0141\n",
            "Best best_epoch 92\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 5.4936\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  0.9892832335683008 initial gdp train loss:  359.2309319817125\n",
            "initial val loss:  1.0414968206036475 initial gdp val loss:  378.1908445296749\n",
            "Best Validation GDP Loss for fold 1: 4.7018\n",
            "Best best_epoch 95\n",
            "Fold 2/5\n",
            "initial train loss:  0.5744828805026746 initial gdp train loss:  208.60762403240312\n",
            "initial val loss:  0.6115956083420784 initial gdp val loss:  222.08407366352696\n",
            "Best Validation GDP Loss for fold 2: 6.9014\n",
            "Best best_epoch 71\n",
            "Fold 3/5\n",
            "initial train loss:  0.7122175896042677 initial gdp train loss:  258.62218541229225\n",
            "initial val loss:  0.6694815089625697 initial gdp val loss:  243.10374854303174\n",
            "Best Validation GDP Loss for fold 3: 2.8374\n",
            "Best best_epoch 97\n",
            "Fold 4/5\n",
            "initial train loss:  0.5439138421615927 initial gdp train loss:  197.5073135782385\n",
            "initial val loss:  0.49397830866998244 initial gdp val loss:  179.37460090883317\n",
            "Best Validation GDP Loss for fold 4: 2.6201\n",
            "Best best_epoch 93\n",
            "Fold 5/5\n",
            "initial train loss:  0.886694880839317 initial gdp train loss:  321.9788042622228\n",
            "initial val loss:  0.9016982513724021 initial gdp val loss:  327.42687217934616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  41%|████      | 13/32 [10:34<20:03, 63.32s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 15.6055\n",
            "Best best_epoch 77\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 6.5332\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  2.518066662179548 initial gdp train loss:  304.78883327333267\n",
            "initial val loss:  2.6633889321357973 initial gdp val loss:  322.3787343671245\n",
            "Best Validation GDP Loss for fold 1: 4.4299\n",
            "Best best_epoch 95\n",
            "Fold 2/5\n",
            "initial train loss:  1.7736091194275987 initial gdp train loss:  214.67908732096353\n",
            "initial val loss:  1.8854345129382226 initial gdp val loss:  228.21451347104966\n",
            "Best Validation GDP Loss for fold 2: 6.8739\n",
            "Best best_epoch 68\n",
            "Fold 3/5\n",
            "initial train loss:  2.1972270793160478 initial gdp train loss:  265.9541431885751\n",
            "initial val loss:  2.0682309658296645 initial gdp val loss:  250.34035487021168\n",
            "Best Validation GDP Loss for fold 3: 2.8813\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  3.038628782159961 initial gdp train loss:  367.79808319067166\n",
            "initial val loss:  2.869175674069312 initial gdp val loss:  347.28734130859374\n",
            "Best Validation GDP Loss for fold 4: 2.7809\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  2.846250904760053 initial gdp train loss:  344.51251082881805\n",
            "initial val loss:  2.8908818254193056 initial gdp val loss:  349.9146904312677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  44%|████▍     | 14/32 [11:50<20:13, 67.39s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 15.7085\n",
            "Best best_epoch 84\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 6.5349\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  0.712572546809599 initial gdp train loss:  258.7510744453535\n",
            "initial val loss:  0.7574426031881764 initial gdp val loss:  275.0443871282762\n",
            "Best Validation GDP Loss for fold 1: 10.1332\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  0.5899086506545688 initial gdp train loss:  214.20906201132465\n",
            "initial val loss:  0.6273343051633528 initial gdp val loss:  227.79913586032006\n",
            "Best Validation GDP Loss for fold 2: 8.9078\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  0.9284204135891696 initial gdp train loss:  337.130281610004\n",
            "initial val loss:  0.883791853920106 initial gdp val loss:  320.9246432396673\n",
            "Best Validation GDP Loss for fold 3: 4.0109\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  0.5989137139408891 initial gdp train loss:  217.4790028348096\n",
            "initial val loss:  0.5480776321503424 initial gdp val loss:  199.019289078251\n",
            "Best Validation GDP Loss for fold 4: 3.5168\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  0.7368215899313649 initial gdp train loss:  267.55643704322074\n",
            "initial val loss:  0.7516733054975862 initial gdp val loss:  272.9494268423531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  47%|████▋     | 15/32 [12:49<18:21, 64.77s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 16.2856\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 8.5709\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  1.5528401334599393 initial gdp train loss:  187.95703299878778\n",
            "initial val loss:  1.668301163181182 initial gdp val loss:  201.93253232894406\n",
            "Best Validation GDP Loss for fold 1: 6.8116\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  2.4338978233599105 initial gdp train loss:  294.6009608431147\n",
            "initial val loss:  2.5408479167569067 initial gdp val loss:  307.54627646169354\n",
            "Best Validation GDP Loss for fold 2: 14.6960\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  2.002269429386961 initial gdp train loss:  242.35631470761058\n",
            "initial val loss:  1.8749068952375842 initial gdp val loss:  226.9402532762097\n",
            "Best Validation GDP Loss for fold 3: 3.6736\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  1.8775559591611997 initial gdp train loss:  227.26089716457955\n",
            "initial val loss:  1.7238814130906135 initial gdp val loss:  208.6600085842994\n",
            "Best Validation GDP Loss for fold 4: 3.6142\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  2.1859942897673577 initial gdp train loss:  264.5945217993952\n",
            "initial val loss:  2.230370844066336 initial gdp val loss:  269.96589626077696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  50%|█████     | 16/32 [13:48<16:47, 62.96s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 16.3393\n",
            "Best best_epoch 97\n",
            "Average Validation Loss for parameters {'hidden_dim': 512, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 9.0269\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  0.725348784954342 initial gdp train loss:  263.39041613070015\n",
            "initial val loss:  0.7705882710795249 initial gdp val loss:  279.8178738501764\n",
            "Best Validation GDP Loss for fold 1: 2.4310\n",
            "Best best_epoch 58\n",
            "Fold 2/5\n",
            "initial train loss:  0.9697275989665631 initial gdp train loss:  352.1298364819395\n",
            "initial val loss:  1.0039445477147255 initial gdp val loss:  364.55477432743197\n",
            "Best Validation GDP Loss for fold 2: 4.8312\n",
            "Best best_epoch 56\n",
            "Fold 3/5\n",
            "initial train loss:  0.6115954136348136 initial gdp train loss:  222.08401475710866\n",
            "initial val loss:  0.5694935510235448 initial gdp val loss:  206.79589302309097\n",
            "Best Validation GDP Loss for fold 3: 2.0453\n",
            "Best best_epoch 82\n",
            "Fold 4/5\n",
            "initial train loss:  1.1841379432932229 initial gdp train loss:  429.98704276342755\n",
            "initial val loss:  1.1256818286834225 initial gdp val loss:  408.7603285266507\n",
            "Best Validation GDP Loss for fold 4: 1.8408\n",
            "Best best_epoch 97\n",
            "Fold 5/5\n",
            "initial train loss:  0.6884287749567339 initial gdp train loss:  249.98393082157259\n",
            "initial val loss:  0.7030511120376464 initial gdp val loss:  255.29362956914315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  53%|█████▎    | 17/32 [15:17<17:41, 70.75s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 13.8223\n",
            "Best best_epoch 95\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 4.9941\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_more_q_t10_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  2.8355115121944574 initial gdp train loss:  343.2126093903696\n",
            "initial val loss:  2.9883119721566476 initial gdp val loss:  361.7077122842112\n",
            "Best Validation GDP Loss for fold 1: 2.5093\n",
            "Best best_epoch 61\n",
            "Fold 2/5\n",
            "initial train loss:  2.5890819222047696 initial gdp train loss:  313.38457419431626\n",
            "initial val loss:  2.695737384980725 initial gdp val loss:  326.29422764931957\n",
            "Best Validation GDP Loss for fold 2: 4.2108\n",
            "Best best_epoch 41\n",
            "Fold 3/5\n",
            "initial train loss:  2.7464657335920233 initial gdp train loss:  332.43444001549574\n",
            "initial val loss:  2.6137641399137435 initial gdp val loss:  316.37213666362146\n",
            "Best Validation GDP Loss for fold 3: 2.0238\n",
            "Best best_epoch 92\n",
            "Fold 4/5\n",
            "initial train loss:  2.2109379087175642 initial gdp train loss:  267.6137145060123\n",
            "initial val loss:  2.052605676651001 initial gdp val loss:  248.44905897571195\n",
            "Best Validation GDP Loss for fold 4: 1.8093\n",
            "Best best_epoch 68\n",
            "Fold 5/5\n",
            "initial train loss:  2.5648299555624683 initial gdp train loss:  310.44909234816026\n",
            "initial val loss:  2.609153428895574 initial gdp val loss:  315.8140313108376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  56%|█████▋    | 18/32 [16:46<17:46, 76.15s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 13.8145\n",
            "Best best_epoch 89\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 4.8735\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_more_q_t10_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  0.7066162776042609 initial gdp train loss:  256.5882263553056\n",
            "initial val loss:  0.7512945321298414 initial gdp val loss:  272.8118996897051\n",
            "Best Validation GDP Loss for fold 1: 2.5323\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  0.8996911012327796 initial gdp train loss:  326.6980110519446\n",
            "initial val loss:  0.9354965452224978 initial gdp val loss:  339.6997916929183\n",
            "Best Validation GDP Loss for fold 2: 4.5957\n",
            "Best best_epoch 89\n",
            "Fold 3/5\n",
            "initial train loss:  0.8587670789022808 initial gdp train loss:  311.83758870048615\n",
            "initial val loss:  0.8144458136250896 initial gdp val loss:  295.7435409053679\n",
            "Best Validation GDP Loss for fold 3: 2.0805\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  0.6517707124845552 initial gdp train loss:  236.67256562338423\n",
            "initial val loss:  0.6002656809745296 initial gdp val loss:  217.96994717505672\n",
            "Best Validation GDP Loss for fold 4: 1.8201\n",
            "Best best_epoch 84\n",
            "Fold 5/5\n",
            "initial train loss:  0.583516320490068 initial gdp train loss:  211.8878661124937\n",
            "initial val loss:  0.5984005279911374 initial gdp val loss:  217.29263641456185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  59%|█████▉    | 19/32 [17:57<16:13, 74.87s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 13.8993\n",
            "Best best_epoch 97\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 4.9856\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  2.491727453167156 initial gdp train loss:  301.6006991899812\n",
            "initial val loss:  2.636615893148607 initial gdp val loss:  319.1381154706401\n",
            "Best Validation GDP Loss for fold 1: 2.5654\n",
            "Best best_epoch 98\n",
            "Fold 2/5\n",
            "initial train loss:  2.071229493358233 initial gdp train loss:  250.70329351171165\n",
            "initial val loss:  2.1775172556600264 initial gdp val loss:  263.568463922316\n",
            "Best Validation GDP Loss for fold 2: 4.7403\n",
            "Best best_epoch 37\n",
            "Fold 3/5\n",
            "initial train loss:  2.131437413628973 initial gdp train loss:  257.9909236436895\n",
            "initial val loss:  2.0031762346144646 initial gdp val loss:  242.4660921158329\n",
            "Best Validation GDP Loss for fold 3: 2.0554\n",
            "Best best_epoch 98\n",
            "Fold 4/5\n",
            "initial train loss:  2.583076105664294 initial gdp train loss:  312.65761937471626\n",
            "initial val loss:  2.4187305773458174 initial gdp val loss:  292.7651142735635\n",
            "Best Validation GDP Loss for fold 4: 1.8401\n",
            "Best best_epoch 97\n",
            "Fold 5/5\n",
            "initial train loss:  2.6490033380446896 initial gdp train loss:  320.63750905682963\n",
            "initial val loss:  2.6931735196159883 initial gdp val loss:  325.9838974838504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  62%|██████▎   | 20/32 [19:09<14:47, 73.94s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 13.8946\n",
            "Best best_epoch 93\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 5.0192\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  0.5975774288466132 initial gdp train loss:  216.99377101501022\n",
            "initial val loss:  0.6389645518795136 initial gdp val loss:  232.0223646594632\n",
            "Best Validation GDP Loss for fold 1: 6.1009\n",
            "Best best_epoch 98\n",
            "Fold 2/5\n",
            "initial train loss:  1.0668155257984744 initial gdp train loss:  387.38464729857117\n",
            "initial val loss:  1.1016156846477139 initial gdp val loss:  400.0213670299899\n",
            "Best Validation GDP Loss for fold 2: 6.6888\n",
            "Best best_epoch 98\n",
            "Fold 3/5\n",
            "initial train loss:  0.798432683684924 initial gdp train loss:  289.928819916535\n",
            "initial val loss:  0.7547220164729703 initial gdp val loss:  274.05649689705143\n",
            "Best Validation GDP Loss for fold 3: 3.1301\n",
            "Best best_epoch 96\n",
            "Fold 4/5\n",
            "initial train loss:  1.0447742385764196 initial gdp train loss:  379.38095646966747\n",
            "initial val loss:  0.9877687934906252 initial gdp val loss:  358.6810040873866\n",
            "Best Validation GDP Loss for fold 4: 2.9655\n",
            "Best best_epoch 95\n",
            "Fold 5/5\n",
            "initial train loss:  0.9711298796438401 initial gdp train loss:  352.6390459614415\n",
            "initial val loss:  0.9858399785838081 initial gdp val loss:  357.98059111659967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  66%|██████▌   | 21/32 [20:38<14:22, 78.39s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 14.7785\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 6.7328\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  1.5943490852743893 initial gdp train loss:  192.98130572967898\n",
            "initial val loss:  1.7117881874884329 initial gdp val loss:  207.19622507402974\n",
            "Best Validation GDP Loss for fold 1: 6.0449\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  2.9264208164014964 initial gdp train loss:  354.21633642656946\n",
            "initial val loss:  3.0309479605767033 initial gdp val loss:  366.86839501165576\n",
            "Best Validation GDP Loss for fold 2: 6.0436\n",
            "Best best_epoch 100\n",
            "Fold 3/5\n",
            "initial train loss:  2.152848658300004 initial gdp train loss:  260.5825486325563\n",
            "initial val loss:  2.0247244496499337 initial gdp val loss:  245.0742921890751\n",
            "Best Validation GDP Loss for fold 3: 3.0640\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  2.681628293044342 initial gdp train loss:  324.58645844170894\n",
            "initial val loss:  2.5176056585004254 initial gdp val loss:  304.7330306514617\n",
            "Best Validation GDP Loss for fold 4: 2.7081\n",
            "Best best_epoch 100\n",
            "Fold 5/5\n",
            "initial train loss:  2.07585976200719 initial gdp train loss:  251.26375269736013\n",
            "initial val loss:  2.120030879202784 initial gdp val loss:  256.6102630220185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  69%|██████▉   | 22/32 [22:07<13:34, 81.44s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 14.5316\n",
            "Best best_epoch 100\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 6.4784\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  0.9197119840024651 initial gdp train loss:  333.9680527016653\n",
            "initial val loss:  0.9703315504135624 initial gdp val loss:  352.34913940429686\n",
            "Best Validation GDP Loss for fold 1: 12.7677\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  0.6900986264654472 initial gdp train loss:  250.59028680907613\n",
            "initial val loss:  0.7267507599246117 initial gdp val loss:  263.89950689500375\n",
            "Best Validation GDP Loss for fold 2: 15.4444\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  0.8471569433820354 initial gdp train loss:  307.6216952098388\n",
            "initial val loss:  0.8034940419658538 initial gdp val loss:  291.76671241021927\n",
            "Best Validation GDP Loss for fold 3: 4.9999\n",
            "Best best_epoch 100\n",
            "Fold 4/5\n",
            "initial train loss:  0.701008441709914 initial gdp train loss:  254.55188572031534\n",
            "initial val loss:  0.6483838315932982 initial gdp val loss:  235.44271112257434\n",
            "Best Validation GDP Loss for fold 4: 4.9071\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  0.5542680974929564 initial gdp train loss:  201.26718169181578\n",
            "initial val loss:  0.5686543529859253 initial gdp val loss:  206.49114935915063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  72%|███████▏  | 23/32 [23:18<11:46, 78.52s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 17.0152\n",
            "Best best_epoch 98\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 11.0268\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  2.1791490694512468 initial gdp train loss:  263.7659658904611\n",
            "initial val loss:  2.3139733006877283 initial gdp val loss:  280.0851985808342\n",
            "Best Validation GDP Loss for fold 1: 12.2223\n",
            "Best best_epoch 100\n",
            "Fold 2/5\n",
            "initial train loss:  2.386466104047158 initial gdp train loss:  288.85978909323927\n",
            "initial val loss:  2.4935969583449826 initial gdp val loss:  301.8269976215978\n",
            "Best Validation GDP Loss for fold 2: 16.7814\n",
            "Best best_epoch 99\n",
            "Fold 3/5\n",
            "initial train loss:  2.744764161360081 initial gdp train loss:  332.2284784324714\n",
            "initial val loss:  2.612205131592289 initial gdp val loss:  316.1834214733493\n",
            "Best Validation GDP Loss for fold 3: 5.5699\n",
            "Best best_epoch 99\n",
            "Fold 4/5\n",
            "initial train loss:  2.4278867390965915 initial gdp train loss:  293.87338897237095\n",
            "initial val loss:  2.2656402957054875 initial gdp val loss:  274.2349414456275\n",
            "Best Validation GDP Loss for fold 4: 5.1253\n",
            "Best best_epoch 99\n",
            "Fold 5/5\n",
            "initial train loss:  2.0151085945867724 initial gdp train loss:  243.91037922520792\n",
            "initial val loss:  2.060745961843571 initial gdp val loss:  249.43436019551794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  75%|███████▌  | 24/32 [24:30<10:11, 76.50s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 17.3059\n",
            "Best best_epoch 99\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.0001, 'batch_size': 128, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}: 11.4010\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  0.7399411194260992 initial gdp train loss:  268.68922775305504\n",
            "initial val loss:  0.7855525820486007 initial gdp val loss:  285.2517534809728\n",
            "Best Validation GDP Loss for fold 1: 2.2333\n",
            "Best best_epoch 99\n",
            "Fold 2/5\n",
            "initial train loss:  0.9875060723037659 initial gdp train loss:  358.58561210232074\n",
            "initial val loss:  1.0219054460525512 initial gdp val loss:  371.07678517987654\n",
            "Best Validation GDP Loss for fold 2: 5.0591\n",
            "Best best_epoch 83\n",
            "Fold 3/5\n",
            "initial train loss:  0.7290852540822833 initial gdp train loss:  264.74720702583124\n",
            "initial val loss:  0.6862009575290065 initial gdp val loss:  249.17495914582284\n",
            "Best Validation GDP Loss for fold 3: 1.7383\n",
            "Best best_epoch 92\n",
            "Fold 4/5\n",
            "initial train loss:  0.5902748868001672 initial gdp train loss:  214.34204866349265\n",
            "initial val loss:  0.539459264662958 initial gdp val loss:  195.88974865328882\n",
            "Best Validation GDP Loss for fold 4: 1.7398\n",
            "Best best_epoch 90\n",
            "Fold 5/5\n",
            "initial train loss:  0.5740095788432705 initial gdp train loss:  208.43574819257182\n",
            "initial val loss:  0.588815806560146 initial gdp val loss:  213.81221902100398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Hyperparameter Search:  78%|███████▊  | 25/32 [28:14<14:06, 120.87s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation GDP Loss for fold 5: 13.5052\n",
            "Best best_epoch 58\n",
            "Average Validation Loss for parameters {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 20, 'weight_decay': 0.01}: 4.8552\n",
            "\n",
            "Best valid model saved to /content/Multi_Country_GDP_Prediction/checkpoint_lstmLSTM_data_gdp_more_q_t10_95-19_lstm_best_valid_model.pth\n",
            "\n",
            "Evaluating parameters: {'hidden_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 100, 'weight': 60, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "initial train loss:  1.9686562769638136 initial gdp train loss:  238.2877538156086\n",
            "initial val loss:  2.0979038869180986 initial gdp val loss:  253.93198970671622\n",
            "Best Validation GDP Loss for fold 1: 2.2694\n",
            "Best best_epoch 93\n",
            "Fold 2/5\n",
            "initial train loss:  2.665206804113873 initial gdp train loss:  322.5987927403731\n",
            "initial val loss:  2.7703213445601924 initial gdp val loss:  335.3219315067414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.run_lstm_q"
      ],
      "metadata": {
        "id": "hUHDLc_Ko5Mk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5435a766-a2ed-4bf5-ec73-109c34f972c6",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file item list length:  6\n",
            "\r  0% 0/6 [00:00<?, ?it/s]LSTM_data_gdp_q_t8_95-19.pt\n",
            "device: cuda\n",
            "/content/Multi_Country_GDP_Prediction/scripts/run_lstm_q.py:258: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  dataset = TensorDataset(torch.tensor(X, dtype=torch.float32).to(device),\n",
            "/content/Multi_Country_GDP_Prediction/scripts/run_lstm_q.py:259: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(y, dtype=torch.float32).to(device))\n",
            "\n",
            "\rHyperparameter Search:   0% 0/54 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating parameters: {'hidden_dim': 512, 'num_layers': 1, 'dropout_rate': 0.1, 'lr': 0.001, 'batch_size': 64, 'num_epochs': 1000, 'weight': 20, 'weight_decay': 0.01}\n",
            "Fold 1/5\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "initial train loss:  7.129329778175273 initial gdp train loss:  95.98164516069924\n",
            "initial val loss:  7.501234471297064 initial gdp val loss:  100.98857655244716\n",
            "Best Validation GDP Loss for fold 1: 0.7196\n",
            "Best best_epoch 137\n",
            "Fold 2/5\n",
            "initial train loss:  7.240161596342575 initial gdp train loss:  97.47376956092883\n",
            "initial val loss:  7.530119915970233 initial gdp val loss:  101.37746217871914\n",
            "Best Validation GDP Loss for fold 2: 0.8092\n",
            "Best best_epoch 192\n",
            "Fold 3/5\n",
            "initial train loss:  6.936738195298593 initial gdp train loss:  93.38880411783855\n",
            "initial val loss:  6.870341793965485 initial gdp val loss:  92.49491196971829\n",
            "Hyperparameter Search:   0% 0/54 [01:15<?, ?it/s]\n",
            "  0% 0/6 [01:15<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/Multi_Country_GDP_Prediction/scripts/run_lstm_q.py\", line 588, in <module>\n",
            "    best_params, best_overall_loss = hyperparameter_search(train_data, train_targets, param_grid, k_folds=5, device=device)\n",
            "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Multi_Country_GDP_Prediction/scripts/run_lstm_q.py\", line 303, in hyperparameter_search\n",
            "    best_model_wts, best_val_gdp_loss, best_epoch = train_and_evaluate(model, train_loader, val_loader, \n",
            "                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Multi_Country_GDP_Prediction/scripts/run_lstm_q.py\", line 208, in train_and_evaluate\n",
            "    loss = criterion(outputs, targets, weight)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Multi_Country_GDP_Prediction/scripts/run_lstm_q.py\", line 166, in loss_weight\n",
            "    loss_temp = criterion_(outputs, targets)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\", line 536, in forward\n",
            "    return F.mse_loss(input, target, reduction=self.reduction)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 3295, in mse_loss\n",
            "    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.run_mlp_q"
      ],
      "metadata": {
        "id": "LWP9Puo-R9L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.run_mlp_y"
      ],
      "metadata": {
        "id": "LLlx8jcebvxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.run_transformer_y"
      ],
      "metadata": {
        "id": "ch2Bd7YTcENt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}